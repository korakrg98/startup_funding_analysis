{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9db0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e66f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f30a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No</th>\n",
       "      <th>Date dd/mm/yyyy</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry Vertical</th>\n",
       "      <th>SubVertical</th>\n",
       "      <th>City  Location</th>\n",
       "      <th>Investors Name</th>\n",
       "      <th>InvestmentnType</th>\n",
       "      <th>Amount in USD</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>Private Equity Round</td>\n",
       "      <td>20,00,00,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13/01/2020</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Susquehanna Growth Equity</td>\n",
       "      <td>Series C</td>\n",
       "      <td>80,48,394</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Series B</td>\n",
       "      <td>1,83,58,860</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>Pre-series A</td>\n",
       "      <td>30,00,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>18,00,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      #
      "text/plain": [
       "   Sr No Date dd/mm/yyyy     Startup Name    Industry Vertical  \\\n",
       "0      1      2020-09-01           Byju's              Ed-Tech   \n",
       "1      2      13/01/2020           Shuttl       Transportation   \n",
       "2      3      2020-09-01        MamaEarth            eCommerce   \n",
       "3      4      02/01/2020  wealthbucket.in              FinTech   \n",
       "4      5      02/01/2020           Fashor  Fashion and Apparel   \n",
       "\n",
       "                             SubVertical City  Location  \\\n",
       "0                             E-learning      Bengaluru   \n",
       "1              App based shuttle service        Gurgaon   \n",
       "2  Retailer of baby and toddler products      Bengaluru   \n",
       "3                      Online Investment      New Delhi   \n",
       "4            Embroiled Clothes For Women         Mumbai   \n",
       "\n",
       "              Investors Name       InvestmentnType Amount in USD Remarks  \n",
       "0    Tiger Global Management  Private Equity Round  20,00,00,000     NaN  \n",
       "1  Susquehanna Growth Equity              Series C     80,48,394     NaN  \n",
       "2            Sequoia Capital              Series B   1,83,58,860     NaN  \n",
       "3             Vinod Khatumal          Pre-series A     30,00,000     NaN  \n",
       "4    Sprout Venture Partners            Seed Round     18,00,000     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b116606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3044 entries, 0 to 3043\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Sr No              3044 non-null   int64 \n",
      " 1   Date dd/mm/yyyy    3044 non-null   object\n",
      " 2   Startup Name       3044 non-null   object\n",
      " 3   Industry Vertical  2873 non-null   object\n",
      " 4   SubVertical        2108 non-null   object\n",
      " 5   City  Location     2864 non-null   object\n",
      " 6   Investors Name     3020 non-null   object\n",
      " 7   InvestmentnType    3040 non-null   object\n",
      " 8   Amount in USD      2084 non-null   object\n",
      " 9   Remarks            419 non-null    object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 237.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d86a28e",
   "metadata": {},
   "source": [
    "# Column droping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a166ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Sr No','Remarks'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29dd34fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date dd/mm/yyyy</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry Vertical</th>\n",
       "      <th>SubVertical</th>\n",
       "      <th>City  Location</th>\n",
       "      <th>Investors Name</th>\n",
       "      <th>InvestmentnType</th>\n",
       "      <th>Amount in USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>Private Equity Round</td>\n",
       "      <td>20,00,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13/01/2020</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Susquehanna Growth Equity</td>\n",
       "      <td>Series C</td>\n",
       "      <td>80,48,394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Series B</td>\n",
       "      <td>1,83,58,860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>Pre-series A</td>\n",
       "      <td>30,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>18,00,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date dd/mm/yyyy     Startup Name    Industry Vertical  \\\n",
       "0      2020-09-01           Byju's              Ed-Tech   \n",
       "1      13/01/2020           Shuttl       Transportation   \n",
       "2      2020-09-01        MamaEarth            eCommerce   \n",
       "3      02/01/2020  wealthbucket.in              FinTech   \n",
       "4      02/01/2020           Fashor  Fashion and Apparel   \n",
       "\n",
       "                             SubVertical City  Location  \\\n",
       "0                             E-learning      Bengaluru   \n",
       "1              App based shuttle service        Gurgaon   \n",
       "2  Retailer of baby and toddler products      Bengaluru   \n",
       "3                      Online Investment      New Delhi   \n",
       "4            Embroiled Clothes For Women         Mumbai   \n",
       "\n",
       "              Investors Name       InvestmentnType Amount in USD  \n",
       "0    Tiger Global Management  Private Equity Round  20,00,00,000  \n",
       "1  Susquehanna Growth Equity              Series C     80,48,394  \n",
       "2            Sequoia Capital              Series B   1,83,58,860  \n",
       "3             Vinod Khatumal          Pre-series A     30,00,000  \n",
       "4    Sprout Venture Partners            Seed Round     18,00,000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1b1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'Date dd/mm/yyyy':'date',\n",
    "    'Startup Name':'startup',\n",
    "    'Industry Vertical':'vertical',\n",
    "    'SubVertical':'subvertical',\n",
    "    'City  Location':'location',\n",
    "    'Investors Name':'investor',\n",
    "    'InvestmentnType':'investment_type',\n",
    "    'Amount in USD':'amount'\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31dd754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>startup</th>\n",
       "      <th>vertical</th>\n",
       "      <th>subvertical</th>\n",
       "      <th>location</th>\n",
       "      <th>investor</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>Private Equity Round</td>\n",
       "      <td>20,00,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13/01/2020</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Susquehanna Growth Equity</td>\n",
       "      <td>Series C</td>\n",
       "      <td>80,48,394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Series B</td>\n",
       "      <td>1,83,58,860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>Pre-series A</td>\n",
       "      <td>30,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>18,00,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date          startup             vertical  \\\n",
       "0  2020-09-01           Byju's              Ed-Tech   \n",
       "1  13/01/2020           Shuttl       Transportation   \n",
       "2  2020-09-01        MamaEarth            eCommerce   \n",
       "3  02/01/2020  wealthbucket.in              FinTech   \n",
       "4  02/01/2020           Fashor  Fashion and Apparel   \n",
       "\n",
       "                             subvertical   location  \\\n",
       "0                             E-learning  Bengaluru   \n",
       "1              App based shuttle service    Gurgaon   \n",
       "2  Retailer of baby and toddler products  Bengaluru   \n",
       "3                      Online Investment  New Delhi   \n",
       "4            Embroiled Clothes For Women     Mumbai   \n",
       "\n",
       "                    investor       investment_type        amount  \n",
       "0    Tiger Global Management  Private Equity Round  20,00,00,000  \n",
       "1  Susquehanna Growth Equity              Series C     80,48,394  \n",
       "2            Sequoia Capital              Series B   1,83,58,860  \n",
       "3             Vinod Khatumal          Pre-series A     30,00,000  \n",
       "4    Sprout Venture Partners            Seed Round     18,00,000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec5f7110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3044 entries, 0 to 3043\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   date             3044 non-null   object\n",
      " 1   startup          3044 non-null   object\n",
      " 2   vertical         2873 non-null   object\n",
      " 3   subvertical      2108 non-null   object\n",
      " 4   location         2864 non-null   object\n",
      " 5   investor         3020 non-null   object\n",
      " 6   investment_type  3040 non-null   object\n",
      " 7   amount           2084 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 190.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "695bf13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 0\n",
       "startup              0\n",
       "vertical           171\n",
       "subvertical        936\n",
       "location           180\n",
       "investor            24\n",
       "investment_type      4\n",
       "amount             960\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55c51db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vertical']=df['vertical'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d2b8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subvertical']=df['subvertical'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08027e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location']=df['location'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc7797bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['investor']=df['investor'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6926d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['investment_type']=df['investment_type'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a47a159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 0\n",
       "startup              0\n",
       "vertical             0\n",
       "subvertical          0\n",
       "location             0\n",
       "investor             0\n",
       "investment_type      0\n",
       "amount             960\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14a02e",
   "metadata": {},
   "source": [
    "# amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9c040a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount']=df['amount'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa3514df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount']=df['amount'].str.replace(',','')\n",
    "df['amount']=df['amount'].str.replace('undisclosed','0')\n",
    "df['amount']=df['amount'].str.replace('unknown','0')\n",
    "df['amount']=df['amount'].str.replace('Undisclosed','0')\n",
    "df['amount']=df['amount'].replace('14342000+','14342000')\n",
    "df['amount']=df['amount'].replace(to_replace=r'\\\\+',value='',regex=True)\n",
    "df['amount']=df['amount'].str.replace(\"xc2xa0\",'')\n",
    "df['amount']=df['amount'].str.replace('N/A','0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d8c528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount']=df['amount'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a2f8cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3044 entries, 0 to 3043\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   date             3044 non-null   object \n",
      " 1   startup          3044 non-null   object \n",
      " 2   vertical         3044 non-null   object \n",
      " 3   subvertical      3044 non-null   object \n",
      " 4   location         3044 non-null   object \n",
      " 5   investor         3044 non-null   object \n",
      " 6   investment_type  3044 non-null   object \n",
      " 7   amount           3044 non-null   float64\n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 190.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40c8d89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       200000000.0\n",
       "1         8048394.0\n",
       "2        18358860.0\n",
       "3         3000000.0\n",
       "4         1800000.0\n",
       "           ...     \n",
       "3039      4500000.0\n",
       "3040       825000.0\n",
       "3041      1500000.0\n",
       "3042            0.0\n",
       "3043       140000.0\n",
       "Name: amount, Length: 3044, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3915c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doll_inr(dollar):\n",
    "    inr=dollar*81.52\n",
    "    return inr/10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f779c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount']=round(df['amount'].apply(doll_inr),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbe1bc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1630.400\n",
       "1         65.611\n",
       "2        149.661\n",
       "3         24.456\n",
       "4         14.674\n",
       "          ...   \n",
       "3039      36.684\n",
       "3040       6.725\n",
       "3041      12.228\n",
       "3042       0.000\n",
       "3043       1.141\n",
       "Name: amount, Length: 3044, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f28c2",
   "metadata": {},
   "source": [
    "# datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['date'].str.len()>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5ab0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=df['date'].str.replace('05/072018','05/07/2018')\n",
    "df['date']=df['date'].replace('\\\\\\\\xc2\\\\\\\\xa010/7/2015','10/7/2015')\n",
    "df['date']=df['date'].str.replace('22/01//2015','22/01/2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d942b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/01/2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/10/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/02/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04.2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/01.2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
     ]
    }
   ],
   "source": [
    "df['date']=pd.to_datetime(df['date'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f82d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77ba8344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3044 entries, 0 to 3043\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             3043 non-null   datetime64[ns]\n",
      " 1   startup          3044 non-null   object        \n",
      " 2   vertical         3044 non-null   object        \n",
      " 3   subvertical      3044 non-null   object        \n",
      " 4   location         3044 non-null   object        \n",
      " 5   investor         3044 non-null   object        \n",
      " 6   investment_type  3044 non-null   object        \n",
      " 7   amount           3044 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(6)\n",
      "memory usage: 190.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5a7e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=df['date'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1fdc6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               1\n",
       "startup            0\n",
       "vertical           0\n",
       "subvertical        0\n",
       "location           0\n",
       "investor           0\n",
       "investment_type    0\n",
       "amount             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650dfdc2",
   "metadata": {},
   "source": [
    "# startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2358551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Byju's\",\n",
       " 'Shuttl',\n",
       " 'MamaEarth',\n",
       " 'wealthbucket.in',\n",
       " 'Fashor',\n",
       " 'Pando',\n",
       " 'Zomato',\n",
       " 'Ecozen',\n",
       " 'CarDekho',\n",
       " 'Dhruva Space',\n",
       " 'Rivigo',\n",
       " 'Healthians',\n",
       " 'Licious',\n",
       " 'InCred',\n",
       " 'Trell',\n",
       " 'Rein Games',\n",
       " 'Lenskart.com',\n",
       " 'Freshworks',\n",
       " 'Misters',\n",
       " 'Sunstone Eduversity Pvt. Ltd',\n",
       " 'Burger Singh',\n",
       " 'Ninjacart',\n",
       " 'Aye Finance',\n",
       " 'SuperGaming',\n",
       " 'Clumio',\n",
       " 'eBikeGo',\n",
       " 'Digital Mall Asia',\n",
       " 'Medikabazaar',\n",
       " 'Vogo Automotive',\n",
       " 'Furtados School of Music',\n",
       " 'Paytm',\n",
       " 'Dunzo',\n",
       " 'Udaan',\n",
       " 'The Man Company',\n",
       " 'FPL Technologies',\n",
       " 'Cashflo',\n",
       " 'Digital F5',\n",
       " '3rdFlix',\n",
       " '75F',\n",
       " 'Myelin Foundry',\n",
       " 'Atomberg Technology',\n",
       " 'GOQii',\n",
       " 'Vyapar App',\n",
       " 'Progcap',\n",
       " 'MyPetrolPump',\n",
       " 'Alteria Capital',\n",
       " 'Pine Labs',\n",
       " 'Meesho',\n",
       " 'Cars24',\n",
       " 'Uniphore',\n",
       " 'ZenDrive',\n",
       " 'Lo! Foods',\n",
       " 'Tala',\n",
       " 'INDwealth',\n",
       " 'HungerBox',\n",
       " 'AdmitKard',\n",
       " 'Mishry Reviews',\n",
       " 'Grofers',\n",
       " 'Rapido Bike Taxi',\n",
       " 'RenewBuy',\n",
       " 'Atlan',\n",
       " 'WizCounsel',\n",
       " 'Ola Cabs',\n",
       " 'Daalchini Technologies',\n",
       " 'Moglix',\n",
       " 'Ezyhaul',\n",
       " 'Indus OS',\n",
       " 'HealthAssure',\n",
       " 'House of Msasaba',\n",
       " 'Board Infinity',\n",
       " 'NoBroker',\n",
       " 'Bira91',\n",
       " 'FabHotels',\n",
       " 'Avail Finance',\n",
       " 'BharatPe',\n",
       " 'Recykal',\n",
       " 'Agara Labs',\n",
       " 'Sistema.bio',\n",
       " 'Chakr Innovation',\n",
       " 'Pratilipi',\n",
       " 'Bolo App',\n",
       " 'OkCredit',\n",
       " 'Biz2Credit',\n",
       " 'Vogo Automotive Pvt. Ltd.',\n",
       " 'Leegality',\n",
       " 'Ola Electric',\n",
       " 'Saahas Zero Waste',\n",
       " 'StyleDotMe',\n",
       " 'BlackBuck',\n",
       " 'Zenoti',\n",
       " 'Ather Energy',\n",
       " 'FreshVnF',\n",
       " 'GlowRoad',\n",
       " 'Kuvera',\n",
       " 'Medlife',\n",
       " 'Kabadiwala',\n",
       " 'Tripoto',\n",
       " 'Azah',\n",
       " 'Setu',\n",
       " 'Toppr',\n",
       " 'CraftsVilla',\n",
       " 'Unacademy',\n",
       " 'CleverTap',\n",
       " 'My Healthcare',\n",
       " 'KrazyBee',\n",
       " 'Increff',\n",
       " 'FleetX',\n",
       " 'Zilingo',\n",
       " 'NanoClean Global',\n",
       " 'OyoRooms',\n",
       " 'Vyome Therapeutics Inc.',\n",
       " 'Samunnati Financial Intermediation & Services Pvt. Ltd',\n",
       " 'Manch',\n",
       " 'UrbanClap Technologies Pvt. Ltd',\n",
       " 'Guiddoo',\n",
       " 'Career Anna',\n",
       " 'Nagpur Wholesale',\n",
       " 'ShopKirana',\n",
       " 'BuildSupply',\n",
       " 'GoDesi',\n",
       " 'Veritas Finance',\n",
       " 'Mobile Premier League',\n",
       " 'A&R Bon Vivants',\n",
       " 'MilkBasket',\n",
       " 'DriveU',\n",
       " 'CleanseCar',\n",
       " 'Automation Anywhere',\n",
       " 'HealthifyMe',\n",
       " 'Genius Corner',\n",
       " 'Aavishkaar-Intellecap Group',\n",
       " 'Skillbox',\n",
       " 'Signzy',\n",
       " 'Engineer.ai',\n",
       " 'InCred Finance',\n",
       " 'Roposo',\n",
       " 'Northmist',\n",
       " 'Origo Commodities India Pvt. Ltd',\n",
       " 'Grover Zampa',\n",
       " 'Droom',\n",
       " 'Innov8',\n",
       " 'LetsTransport',\n",
       " 'NetMeds',\n",
       " 'Daily hunt',\n",
       " '3HCare',\n",
       " 'HappyGoEasy',\n",
       " 'Nykaa',\n",
       " 'Mad Street Den',\n",
       " 'Dream11',\n",
       " 'AutoGrid',\n",
       " 'PharmEasy',\n",
       " 'Upwards',\n",
       " 'Kissht',\n",
       " 'dishq',\n",
       " 'HealthFin',\n",
       " 'Samosa Labs',\n",
       " 'ZiffyHomes',\n",
       " 'My OmNamo',\n",
       " 'ShopX',\n",
       " 'MakeMyTrip',\n",
       " 'Hansel.io',\n",
       " 'Metro Bikes',\n",
       " 'Phone Pe',\n",
       " 'quizizz',\n",
       " 'Happy EMI',\n",
       " 'Inthree',\n",
       " 'Observe AI',\n",
       " 'Enakshi',\n",
       " 'EazyDiner',\n",
       " 'Finzy',\n",
       " 'RAW Pressery',\n",
       " 'Pi Ventures',\n",
       " 'Revv',\n",
       " 'ZestMoney',\n",
       " 'Shubh Loans',\n",
       " 'MyUpchar',\n",
       " 'Narvar',\n",
       " 'True North',\n",
       " 'Leena AI',\n",
       " 'Biryani By Kilo',\n",
       " 'Anchanto',\n",
       " 'LoanTap',\n",
       " 'PolicyBazaar',\n",
       " 'ZippServe',\n",
       " 'Groww',\n",
       " 'Avenue Growth',\n",
       " 'iNICU',\n",
       " 'Kinara Capital',\n",
       " 'Shop 101',\n",
       " 'Sambandh',\n",
       " '19th mile',\n",
       " '5th Vital',\n",
       " 'MoEngage',\n",
       " 'OfBusiness',\n",
       " 'The Ken',\n",
       " 'Book My Show',\n",
       " 'HousingMan',\n",
       " 'PaySense',\n",
       " 'Yulu Bikes',\n",
       " 'VTION',\n",
       " 'Log 9 Materials',\n",
       " 'kidovators',\n",
       " 'Digit',\n",
       " 'Black Soil',\n",
       " 'IQlect',\n",
       " 'Entropik',\n",
       " 'Bitla Software',\n",
       " 'TheCapitalNet',\n",
       " 'CureFit',\n",
       " 'Five Star Group',\n",
       " 'Healthsignz',\n",
       " 'CoinTribe',\n",
       " 'Digiconectt',\n",
       " 'Kashmir Box',\n",
       " 'Crowdera',\n",
       " 'Zoctr',\n",
       " 'Annapurna Finance',\n",
       " 'Theranosis',\n",
       " 'Alpha Capital',\n",
       " 'eShakti',\n",
       " 'Daily Ninja',\n",
       " 'NirogStreet',\n",
       " 'Nivesh',\n",
       " 'What\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s Up Life',\n",
       " 'HomeLane',\n",
       " 'Network Intelligence',\n",
       " 'Tynor Othontics',\n",
       " 'Elucidata',\n",
       " 'Chrysalis',\n",
       " 'RentSher',\n",
       " 'Drip capital',\n",
       " 'WickedRide',\n",
       " 'HipBar',\n",
       " 'Sqqrl',\n",
       " 'Sigtuple',\n",
       " 'WoW Express',\n",
       " 'Front Desk AI',\n",
       " 'Edureka',\n",
       " 'Numeroseven',\n",
       " 'OpenTap',\n",
       " 'Bizongo',\n",
       " 'Disprz',\n",
       " 'PaisaDukan',\n",
       " 'i3sysytems',\n",
       " 'Earth Food',\n",
       " 'MFine',\n",
       " 'Rocketium',\n",
       " 'Vola',\n",
       " 'Cashkumar',\n",
       " 'Edyoo',\n",
       " 'Aashiyaan',\n",
       " 'Smartivity',\n",
       " 'Bonphulapl',\n",
       " 'Acko',\n",
       " 'HWell24',\n",
       " 'Toffee',\n",
       " 'ToneTag',\n",
       " 'Events High',\n",
       " 'Stellaps',\n",
       " 'Credright',\n",
       " 'Fitternity',\n",
       " 'Synctag',\n",
       " 'Benepik',\n",
       " 'Varthana',\n",
       " 'IndigoLearn',\n",
       " 'Vedantu',\n",
       " 'Kaleidofin',\n",
       " 'Pipa Bella',\n",
       " 'Elemential',\n",
       " 'Kriger Campus',\n",
       " 'LoanZen',\n",
       " 'Travel Triangle',\n",
       " 'LetsMD',\n",
       " 'mintifi',\n",
       " 'I Can Stay',\n",
       " 'Pregbuddy',\n",
       " 'Coverfox',\n",
       " 'LensKart',\n",
       " 'Fyle Technologies',\n",
       " 'True Balance',\n",
       " 'Visit',\n",
       " 'Doxper',\n",
       " 'Mihuru',\n",
       " 'Capital Float',\n",
       " 'TripShelf',\n",
       " 'POPxo',\n",
       " 'RailYatri',\n",
       " '1mg',\n",
       " 'Rubique',\n",
       " 'Samco',\n",
       " 'MyLoanCare',\n",
       " 'Buddy4studdy',\n",
       " 'Urban Ladder',\n",
       " 'Gramophone',\n",
       " 'Wellthy',\n",
       " 'MedGenome',\n",
       " 'Finova Capital',\n",
       " 'Hotelogix',\n",
       " 'Livehealth',\n",
       " 'Ad2pro',\n",
       " 'Pepperfry',\n",
       " 'Magicpin',\n",
       " 'HealthCare',\n",
       " 'Stumagz',\n",
       " 'Fingerlix',\n",
       " 'Karma Healthcare',\n",
       " 'Zappfresh',\n",
       " 'CustomerSucessBox',\n",
       " 'One Labs',\n",
       " 'GigIndia',\n",
       " 'ChargeBee',\n",
       " 'i2i Funding',\n",
       " 'Slang Labs',\n",
       " 'UrbanPiper',\n",
       " 'Cash Suvidha',\n",
       " 'Roadcast',\n",
       " 'SmartCoin',\n",
       " 'The Print',\n",
       " 'Fynd',\n",
       " 'BigBasket',\n",
       " 'Asia Institute Of Medical Science',\n",
       " 'CollegeDekho',\n",
       " 'Foodmemories',\n",
       " 'Swiggy',\n",
       " 'Shape',\n",
       " 'Icertis',\n",
       " 'MedTel',\n",
       " 'Rupeek',\n",
       " 'WebEngage',\n",
       " 'LendingKart',\n",
       " 'Wydr',\n",
       " 'Cashify',\n",
       " 'HolaChef',\n",
       " 'Awaaz De',\n",
       " 'IMAX Program',\n",
       " 'Littlemore',\n",
       " 'Shirsa Labs',\n",
       " 'MoneyOnMobile',\n",
       " 'PetSutra',\n",
       " 'Infibeam',\n",
       " 'happay',\n",
       " 'Fincash',\n",
       " 'Agricxlab',\n",
       " 'Capillary',\n",
       " 'The Healthy Billions',\n",
       " 'High Radius',\n",
       " 'Avishkaar Box',\n",
       " 'Planys Technologies',\n",
       " 'Lollypop',\n",
       " 'Trilyo',\n",
       " 'Gaana',\n",
       " 'Credy',\n",
       " 'Predible Health',\n",
       " 'Early Salary',\n",
       " 'WOTU',\n",
       " 'DAAKI',\n",
       " 'Kinsane Entertainment Inc',\n",
       " 'Tapzo',\n",
       " 'Appario Retail Pvt Ltd.',\n",
       " 'Samunnati',\n",
       " 'Sahajanand Medical Technologies',\n",
       " 'Kuants',\n",
       " 'Razorpay',\n",
       " 'Streak',\n",
       " 'Newgen Software',\n",
       " 'Rubix',\n",
       " 'ShareChat',\n",
       " 'Paperflite',\n",
       " 'Skillate',\n",
       " 'OptaCredit',\n",
       " 'AEON Learning',\n",
       " 'NeoGrowth Credit',\n",
       " 'Rao IIT Academy',\n",
       " 'Glassic',\n",
       " 'GreyAtom',\n",
       " 'Axio',\n",
       " 'eKincare',\n",
       " 'The Wedding Brigade',\n",
       " 'PeeSafe',\n",
       " 'BrowserStack',\n",
       " 'Scapic',\n",
       " 'iNurture',\n",
       " 'Strata Enviro',\n",
       " 'Tata Housing',\n",
       " 'HandyTrain',\n",
       " 'Mobycy',\n",
       " 'Greenlight Planet',\n",
       " 'Fintobox',\n",
       " 'Mswipe',\n",
       " 'The Label Life',\n",
       " 'Cygnus Hospitals',\n",
       " 'Inshorts',\n",
       " 'Vahdam Tea',\n",
       " 'Logic Roots',\n",
       " 'Project Mudra',\n",
       " 'Furlenco',\n",
       " 'Fracktal Works',\n",
       " 'Simility',\n",
       " 'Shopholix',\n",
       " 'MindTickle',\n",
       " 'Nazara Technologies',\n",
       " 'DocsApp',\n",
       " 'Capita World',\n",
       " 'Teabox',\n",
       " 'Transversal Technologies',\n",
       " 'Curofy',\n",
       " 'WeDoSky',\n",
       " 'Purplle',\n",
       " 'Sky Met Weather',\n",
       " 'Springboard',\n",
       " 'Peel Works',\n",
       " '9Stacks',\n",
       " 'Your Quote',\n",
       " 'Spandana Sphoorty',\n",
       " 'EasyEcom',\n",
       " 'IGP.com',\n",
       " 'Specsmakers',\n",
       " 'Garage On Road',\n",
       " 'Foyr.com',\n",
       " 'Prest Loans',\n",
       " 'AadharAPI.com',\n",
       " 'FreshBoxx',\n",
       " 'Vagupu',\n",
       " 'HalaPlay',\n",
       " 'Kalpnik Technologies',\n",
       " 'Hevo Data',\n",
       " 'Smart Karma',\n",
       " 'Leverage Edu',\n",
       " 'Crayon Data',\n",
       " 'DocTalk',\n",
       " 'CoveIoT',\n",
       " 'TalentEdge',\n",
       " 'Fisdom',\n",
       " 'FarmLink',\n",
       " 'OpenApp',\n",
       " 'NoPaperForms',\n",
       " 'Tilite Technologies Pvt. Ltd',\n",
       " 'Mobiliz AR',\n",
       " 'Qubole',\n",
       " 'Happily Unmarried',\n",
       " 'Universal Sportsbiz Pvt. Ltd',\n",
       " 'Hungry Foal',\n",
       " 'Active.ai',\n",
       " 'Sumeru',\n",
       " 'ElderAid Wellness',\n",
       " 'Omnia Information',\n",
       " 'Josh Talks',\n",
       " 'Reniso',\n",
       " 'Kanhaiya',\n",
       " 'Perspectico',\n",
       " 'ONN Bikes',\n",
       " 'Rapido',\n",
       " 'Heckyl',\n",
       " 'Nuvepro',\n",
       " 'RedBook',\n",
       " 'Portea',\n",
       " 'Credit Mate',\n",
       " 'Epiq Capital',\n",
       " 'MiStay',\n",
       " 'WittyFeed',\n",
       " 'IDG Ventures',\n",
       " 'TempGo',\n",
       " 'Edelweiss',\n",
       " 'ERA',\n",
       " 'Smaaash',\n",
       " 'Chumbak',\n",
       " 'FR8',\n",
       " 'MobieFit',\n",
       " 'Stanza Living',\n",
       " 'ChqBook',\n",
       " 'HomeCapital',\n",
       " 'Elanic',\n",
       " 'CollPoll',\n",
       " 'Little Black Book',\n",
       " 'Oorjan',\n",
       " 'Zefo',\n",
       " 'Yaantra',\n",
       " 'Farm Taaza',\n",
       " 'Drivezy',\n",
       " 'Slice Pay',\n",
       " 'Agrowave',\n",
       " 'MyGubbi',\n",
       " 'IBSFintech',\n",
       " 'Letsservice',\n",
       " 'OneStepUp',\n",
       " 'ThirdWatch',\n",
       " 'Parallel Dots',\n",
       " 'Easy Diner',\n",
       " 'StanPlus',\n",
       " 'UCLID',\n",
       " 'Gapoon',\n",
       " 'Chaayos',\n",
       " 'Bank Bazaar',\n",
       " 'Hasura',\n",
       " 'LenDen Club',\n",
       " 'Cashe',\n",
       " 'Park Easy',\n",
       " 'TagBox',\n",
       " 'FYRE',\n",
       " 'ZipLoan',\n",
       " 'Skillenza',\n",
       " 'Chevon',\n",
       " 'PropStory',\n",
       " 'SpotDraft',\n",
       " 'Olly Credit',\n",
       " 'CashFree',\n",
       " 'GoldFarm',\n",
       " 'MSE',\n",
       " 'Aahaa Stores',\n",
       " 'Canvera',\n",
       " 'PrimaryIO',\n",
       " 'Nest Education',\n",
       " 'GoFro',\n",
       " 'OncoStem',\n",
       " 'Power2SME',\n",
       " 'Credit Vidya',\n",
       " 'Tails Life',\n",
       " 'Seniority',\n",
       " 'Farmizen',\n",
       " 'Ecom Express',\n",
       " 'Call Health',\n",
       " 'Sattviko',\n",
       " 'Tonbo Imaging',\n",
       " 'Get My Parking',\n",
       " 'Heterogenous',\n",
       " 'Gurukul',\n",
       " 'WheelStreet',\n",
       " 'Xprep',\n",
       " 'The Moms Co',\n",
       " 'Noticeboard',\n",
       " 'HWell24 Plus',\n",
       " 'SaveBC',\n",
       " 'Gaming Monk',\n",
       " '91SpringBoard',\n",
       " 'Homergize',\n",
       " 'Yatra.com',\n",
       " 'Ace Turtle',\n",
       " 'Vogo',\n",
       " 'Synup',\n",
       " 'Tinmen',\n",
       " 'CropIn',\n",
       " 'Sportobuddy',\n",
       " 'Credifiable',\n",
       " 'Inclov',\n",
       " 'Multibhashi',\n",
       " 'Transerv',\n",
       " 'Fashalot',\n",
       " 'Pitstop',\n",
       " 'GoChoppers',\n",
       " 'Aadyah',\n",
       " 'TouchKin',\n",
       " 'Ethinos',\n",
       " 'Zepo',\n",
       " 'Click2Clinic',\n",
       " 'SpeedBox',\n",
       " 'Skill Connect',\n",
       " 'Chai Point',\n",
       " 'Lime Tray',\n",
       " 'CoutLoot',\n",
       " 'Box My Space',\n",
       " 'Curatio',\n",
       " 'New Castle Technologies',\n",
       " 'My Forex Eye',\n",
       " 'TruxApp',\n",
       " 'CroFarm',\n",
       " 'DoodhWala',\n",
       " 'Stayabode',\n",
       " 'Flipkart',\n",
       " 'Moong Labs',\n",
       " 'Sports Flashes',\n",
       " 'Digilend',\n",
       " 'KNAB Finance',\n",
       " 'Get Simpl',\n",
       " 'Rootefy',\n",
       " 'Cerebroz',\n",
       " 'Flochat',\n",
       " 'EasyGov',\n",
       " 'Druva',\n",
       " 'Bombay Shaving Company',\n",
       " 'Awign',\n",
       " 'Indiez',\n",
       " 'Ezetap',\n",
       " 'Ink Monk',\n",
       " 'Medinfi',\n",
       " 'Mobikon',\n",
       " 'Fieldassist',\n",
       " 'Treebo',\n",
       " 'Billion Loans',\n",
       " 'Ecolibriumenergy',\n",
       " 'Jumbotail',\n",
       " 'TimeSaverz',\n",
       " 'Minjar',\n",
       " 'MyCity4Kids',\n",
       " 'Clip App',\n",
       " 'Upwardly.in',\n",
       " 'Autorox.co',\n",
       " 'Fabogo',\n",
       " 'Flickstree',\n",
       " 'Design Cafe',\n",
       " 'Innoviti',\n",
       " 'VDeliver',\n",
       " 'Bottr.me',\n",
       " 'Arcatron',\n",
       " 'QwikSpec',\n",
       " 'Vayana',\n",
       " 'MObiquest',\n",
       " 'Ambee',\n",
       " 'Ideal Insurance',\n",
       " 'Hypernova Interactive',\n",
       " 'RentoMojo',\n",
       " 'AirCTO',\n",
       " 'Playablo',\n",
       " 'Trupay',\n",
       " 'Brick2Wall',\n",
       " 'FableStreet',\n",
       " 'Monsoon Fintech',\n",
       " 'MonkeyBox',\n",
       " 'Creator\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s Gurukul',\n",
       " 'ThinkerBell',\n",
       " 'Jhakaas',\n",
       " 'BigStylist',\n",
       " 'Gympik.com',\n",
       " 'Tripeur',\n",
       " 'RentOnGo',\n",
       " 'Goomo',\n",
       " 'MaxMyWealth',\n",
       " 'Spinny',\n",
       " 'Healthbuds',\n",
       " 'FTCash',\n",
       " 'BHIVE Workspace',\n",
       " 'wayForward',\n",
       " 'GyanDhan',\n",
       " 'GrowFitter',\n",
       " 'Stratfit',\n",
       " 'Multiplier Solutions',\n",
       " 'ABI Health',\n",
       " 'Stockal',\n",
       " 'eSahai.in',\n",
       " 'Loanmeet',\n",
       " 'Boxx.ai',\n",
       " 'PeeSafe.in',\n",
       " 'Vista Rooms',\n",
       " 'HyperTrack',\n",
       " 'Goodera',\n",
       " 'Ola',\n",
       " 'Vanitycask',\n",
       " 'MrNeeds',\n",
       " 'MoneyTap',\n",
       " 'Goodbox',\n",
       " 'PortDesk',\n",
       " 'EdgeFx',\n",
       " 'HealthIntel',\n",
       " 'Unbxd',\n",
       " 'DarwinBox',\n",
       " 'ForeverShop',\n",
       " 'Insider.in',\n",
       " 'Grow Fit',\n",
       " 'Fabulyst',\n",
       " 'OneAssist',\n",
       " 'Julia Computing',\n",
       " 'Explore Life traveling',\n",
       " 'Voxweb',\n",
       " 'HUG Innovations',\n",
       " 'V Resorts',\n",
       " 'Stashfin',\n",
       " 'Formcept',\n",
       " 'Spares Hub',\n",
       " 'FiTraQ',\n",
       " 'Niki.ai',\n",
       " 'Fitpass',\n",
       " 'ZingHR',\n",
       " 'Tagos Design',\n",
       " 'UrbanClap',\n",
       " 'Ace2three',\n",
       " 'Innovapptive',\n",
       " '4tigo',\n",
       " 'SMECorner',\n",
       " 'HealthMir',\n",
       " 'Uactive',\n",
       " 'i-lend',\n",
       " 'Good Methods Global',\n",
       " 'Balance App',\n",
       " 'YepMe',\n",
       " 'NightStay',\n",
       " 'Devourin',\n",
       " 'MyGreens',\n",
       " 'Curie Labs',\n",
       " 'Uncanny Vision',\n",
       " 'Sequretek',\n",
       " 'Lucideus',\n",
       " 'Vidooly',\n",
       " 'Shopclues',\n",
       " 'Fourth Ambit',\n",
       " 'Chymera VR',\n",
       " 'Book My Diamond',\n",
       " 'ION Energy',\n",
       " 'Legal Raasta',\n",
       " 'Remit Guru',\n",
       " 'Aequm',\n",
       " 'Zapty',\n",
       " 'Vernacular.ai',\n",
       " 'Telr',\n",
       " 'Genie',\n",
       " 'The Good Life',\n",
       " 'PumpKart',\n",
       " 'EzCred',\n",
       " 'HealthSutra',\n",
       " 'Delhivery',\n",
       " 'ZipGrid',\n",
       " 'TravelSpice',\n",
       " 'Box8',\n",
       " 'GenNext Students',\n",
       " 'WhatsLoan',\n",
       " 'Cube Consumer Services',\n",
       " 'Wowflux',\n",
       " 'Collateral Medical',\n",
       " 'Loadshare',\n",
       " 'SimpliLend',\n",
       " 'Supr Daily',\n",
       " 'SastaSundar',\n",
       " 'Eruditus',\n",
       " 'TestBook',\n",
       " 'Healthcare at Home',\n",
       " 'Tyre Express',\n",
       " 'WayCool',\n",
       " 'Perfios',\n",
       " 'Whatfix',\n",
       " 'ElastiRun',\n",
       " 'Trukky',\n",
       " 'Konsult App',\n",
       " 'Credit Sudhaar',\n",
       " 'DataWeave',\n",
       " 'Medwell Ventures',\n",
       " 'Mech Mocha',\n",
       " 'Startup Buddy',\n",
       " 'QorQI',\n",
       " 'Twenty Two Motors',\n",
       " 'WonderChef',\n",
       " 'FastFox',\n",
       " 'Omnify',\n",
       " 'MergerWare',\n",
       " 'Clovia',\n",
       " 'Emiza',\n",
       " 'HackerEarth',\n",
       " 'SquadRun',\n",
       " 'ScoutMyTrip',\n",
       " 'SafetyKart',\n",
       " 'WeAreHolidays',\n",
       " 'Myly',\n",
       " 'CrediHealth',\n",
       " 'Navia Life Care',\n",
       " 'Snackible',\n",
       " 'Be U Salons',\n",
       " 'Simulanis',\n",
       " 'Innefu Security Consulting',\n",
       " 'Whodat',\n",
       " 'Absentia VR',\n",
       " 'IOTrek',\n",
       " 'Wooplr',\n",
       " 'Video Ken',\n",
       " 'Faasos',\n",
       " 'Niramai',\n",
       " 'The Office Pass',\n",
       " 'Awfis',\n",
       " 'Myra',\n",
       " 'Flytxt',\n",
       " 'Howdy Ventures',\n",
       " 'StalkBuyLove',\n",
       " 'ZipGo',\n",
       " 'Scootsy',\n",
       " 'Autobix',\n",
       " 'eShiksha',\n",
       " 'Sepalika',\n",
       " 'Mintwalk',\n",
       " 'Qriyo',\n",
       " 'Belong',\n",
       " 'Seenit',\n",
       " 'Paalak',\n",
       " 'Celes Care',\n",
       " 'Karomi',\n",
       " 'Red Carpet',\n",
       " 'Kreate Konnect',\n",
       " 'CreditMantri',\n",
       " 'Lets Endorse',\n",
       " 'Tydy',\n",
       " 'Nactus',\n",
       " 'Oho Shop',\n",
       " 'Emojifi',\n",
       " 'Paytm Marketplace',\n",
       " 'iGenetics',\n",
       " 'Juno Clinic',\n",
       " 'Summerlabel',\n",
       " 'PickMe',\n",
       " 'Agrostar',\n",
       " 'Zapr',\n",
       " 'Data Resolve',\n",
       " 'Book Servicing',\n",
       " 'Blowhorn',\n",
       " 'PipeCandy',\n",
       " 'Parentune',\n",
       " 'AppBrowzer',\n",
       " 'MagicBricks',\n",
       " 'PeeBuddy',\n",
       " 'iOrderFresh',\n",
       " 'Lavelle Networks',\n",
       " 'PropertyShare',\n",
       " 'MyDermacy',\n",
       " 'LatestOne',\n",
       " 'Frapperz',\n",
       " 'm.paani',\n",
       " 'ShilpMIS',\n",
       " 'Fitso',\n",
       " 'FarMart',\n",
       " 'Airpay',\n",
       " 'MyGlamm',\n",
       " 'Haqdarshak',\n",
       " 'Ixigo',\n",
       " 'Markets and Markets',\n",
       " 'Bizom',\n",
       " 'BabyonBoard',\n",
       " 'Wigzo',\n",
       " 'DoneThing',\n",
       " 'Zapyle',\n",
       " 'Ithaka',\n",
       " 'perpule',\n",
       " 'Emflux Motors',\n",
       " 'Klinic App',\n",
       " 'Oriano Solar',\n",
       " 'Rooter',\n",
       " 'FalconBrick',\n",
       " 'Clodura',\n",
       " 'Stockroom.io',\n",
       " 'iManageMyHotel',\n",
       " 'Inner Hour',\n",
       " 'Wandertrails',\n",
       " 'Zenatix',\n",
       " 'CarTrade',\n",
       " 'MInd Your Fleet',\n",
       " 'EduRev',\n",
       " 'Voonik',\n",
       " '1Crowd',\n",
       " '48East',\n",
       " 'Redesyn',\n",
       " 'Flutura',\n",
       " 'Wassup',\n",
       " 'Better Mortgage',\n",
       " 'Nurturey',\n",
       " 'Fyle',\n",
       " 'GoBumpr',\n",
       " 'CCAvenue',\n",
       " 'Connaizen',\n",
       " 'AirZaar',\n",
       " 'Truebil',\n",
       " 'YourStory',\n",
       " 'Imaginate',\n",
       " 'Aisle',\n",
       " 'TownScript',\n",
       " 'Leopetra',\n",
       " 'Blood n Care',\n",
       " 'Vebbler',\n",
       " 'Lets Reap',\n",
       " 'Oglas',\n",
       " 'Staydobe',\n",
       " 'Johari Shop',\n",
       " 'NeoStencil',\n",
       " 'TaxSutra',\n",
       " 'TempoGo',\n",
       " 'GoFynd',\n",
       " 'Vow Car Clinic',\n",
       " 'LearnTron',\n",
       " 'MobiDent',\n",
       " 'Yostra',\n",
       " 'LEAP India',\n",
       " 'FreeCharge',\n",
       " 'TicketNew',\n",
       " 'Intelligence Node',\n",
       " 'Securens',\n",
       " 'Loan Frame',\n",
       " 'DriveSkool',\n",
       " 'InstaOffice',\n",
       " 'Square Yards',\n",
       " 'Roambee',\n",
       " 'PaisaWapas',\n",
       " 'iService',\n",
       " 'SecururAX',\n",
       " 'Leadburg',\n",
       " 'ZoloStays',\n",
       " 'Oi Media',\n",
       " 'HipCouch',\n",
       " 'Curiositi',\n",
       " 'TinyStep',\n",
       " 'Practo',\n",
       " 'Ketchupp',\n",
       " 'Hoopy',\n",
       " 'Ezytruk',\n",
       " 'Kratikal',\n",
       " 'Direct Create',\n",
       " 'PParke',\n",
       " 'Weddingz.in',\n",
       " 'Native Special',\n",
       " 'Fitnapp',\n",
       " 'Ethosh',\n",
       " 'MessaGif',\n",
       " 'SmartHi',\n",
       " 'CRON Systems',\n",
       " 'CueMath',\n",
       " 'ChipperSage',\n",
       " 'SelectJobs',\n",
       " 'Khel Now',\n",
       " 'NowFloats',\n",
       " 'BetaOut',\n",
       " 'Wishberry',\n",
       " 'RML Agtech',\n",
       " 'LoyaltyPrime',\n",
       " 'InstaSafe',\n",
       " '99Games',\n",
       " 'AirMed Labs',\n",
       " '99PerHour',\n",
       " 'Kochi Post',\n",
       " 'Intuit Things',\n",
       " 'Cloudrino',\n",
       " 'FabX',\n",
       " 'Maptags',\n",
       " 'YOLO Health',\n",
       " 'Heads Up For Tails',\n",
       " 'Register My Marriage',\n",
       " 'SidQam',\n",
       " 'IndiaLends',\n",
       " 'Slide App',\n",
       " 'Badiyajobs',\n",
       " 'Streo',\n",
       " 'TYGR',\n",
       " 'Mr Hot Foods',\n",
       " 'UrDoorStep',\n",
       " 'Diro Labs',\n",
       " 'THB',\n",
       " 'LookAtMe',\n",
       " 'Netree',\n",
       " 'BookEventz',\n",
       " 'WealthApp',\n",
       " 'Vehico',\n",
       " 'GoMechanic',\n",
       " 'Wittyparot',\n",
       " 'NeuroEquilibrium',\n",
       " 'Xseed Education',\n",
       " 'Rupaiya Exchange',\n",
       " 'Doctor Insta',\n",
       " 'Fresh Food Concepts',\n",
       " 'Indifi',\n",
       " 'GoComet',\n",
       " 'FitMeIn',\n",
       " 'Qacco',\n",
       " 'Ten3t Health',\n",
       " 'Trading Bells',\n",
       " 'SERV\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99D',\n",
       " 'IdeaForge',\n",
       " 'Amagi Media Labs',\n",
       " 'Pocket Aces',\n",
       " 'Pi Data Centers',\n",
       " 'VivoCarat',\n",
       " 'Tiyo',\n",
       " 'Zoomcar',\n",
       " 'The BlueBook',\n",
       " 'Vegetall',\n",
       " 'Innoplexus',\n",
       " 'Mindler',\n",
       " 'MCaffeine',\n",
       " 'enKast',\n",
       " 'MyAdvo',\n",
       " 'Asocon',\n",
       " 'LexComply',\n",
       " 'The Postbox',\n",
       " 'Pandorum Technologies',\n",
       " 'Dekkho',\n",
       " 'ShadowFax',\n",
       " 'Justbooks',\n",
       " 'InstantPay',\n",
       " 'PickMyLaundry',\n",
       " 'FreshDesk',\n",
       " 'LaundryAnna',\n",
       " 'Zarget',\n",
       " 'DoSelect',\n",
       " 'EasyPolicy',\n",
       " 'Browntape',\n",
       " 'Connect India',\n",
       " 'Corseco',\n",
       " 'vImmune',\n",
       " 'The Gourmet Jar',\n",
       " 'Medzin',\n",
       " 'JustRide',\n",
       " 'IIM Jobs',\n",
       " 'GolfLAN',\n",
       " 'Yottaasys',\n",
       " 'Life in Control',\n",
       " 'PlaySimple',\n",
       " 'Stasis Labs',\n",
       " 'Scienaptic',\n",
       " 'Koovs',\n",
       " 'Lawrato',\n",
       " 'Trip Tap Toe',\n",
       " 'Pictor Imaging',\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['startup'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15a60b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['startup']=df['startup'].apply(lambda x: str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5167867f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Byju's\n",
       "1                 Shuttl\n",
       "2              MamaEarth\n",
       "3        wealthbucket.in\n",
       "4                 Fashor\n",
       "              ...       \n",
       "3039          Printvenue\n",
       "3040            Graphene\n",
       "3041      Mad Street Den\n",
       "3042           Simplotel\n",
       "3043    couponmachine.in\n",
       "Name: startup, Length: 3044, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['startup']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4ac3a",
   "metadata": {},
   "source": [
    "# vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "778cb75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ed-Tech',\n",
       " 'Transportation',\n",
       " 'eCommerce',\n",
       " 'FinTech',\n",
       " 'Fashion and Apparel',\n",
       " 'Logistics',\n",
       " 'Hospitality',\n",
       " 'Technology',\n",
       " 'Aerospace',\n",
       " 'B2B-focused foodtech startup',\n",
       " 'Finance',\n",
       " 'Video',\n",
       " 'Gaming',\n",
       " 'Software',\n",
       " 'Health and Wellness',\n",
       " 'Education',\n",
       " 'Food and Beverage',\n",
       " 'B2B Marketing',\n",
       " 'Video Games',\n",
       " 'SaaS',\n",
       " 'Last Mile Transportation',\n",
       " 'Healthcare',\n",
       " 'Customer Service',\n",
       " 'B2B',\n",
       " 'Consumer Goods',\n",
       " 'Advertising\\xa0&\\xa0Marketing\\xa0Community\\xa0Networking\\xa0platform',\n",
       " 'IoT',\n",
       " 'Information Technology',\n",
       " 'Consumer Technology',\n",
       " 'Accounting',\n",
       " 'Retail',\n",
       " 'Automotive',\n",
       " 'Services',\n",
       " 'Compliance',\n",
       " 'Artificial Intelligence',\n",
       " 'Tech',\n",
       " 'Luxury Label',\n",
       " 'Waste Management Service',\n",
       " 'Deep-Tech',\n",
       " 'Agriculture',\n",
       " 'Energy',\n",
       " 'Digital Media',\n",
       " 'Automobile',\n",
       " 'Agtech',\n",
       " 'Social Media',\n",
       " 'AI',\n",
       " 'Nanotechnology',\n",
       " 'Services Platform',\n",
       " 'Travel Tech',\n",
       " 'Online Education Platform',\n",
       " 'Online Marketplace',\n",
       " 'SaaS, Ecommerce',\n",
       " 'NBFC',\n",
       " 'Food',\n",
       " 'Food Tech',\n",
       " 'Automation',\n",
       " 'Investment',\n",
       " 'Social Network',\n",
       " 'Financial Tech',\n",
       " 'Fashion',\n",
       " 'Real Estate',\n",
       " 'Logistics Tech',\n",
       " 'Consumer Internet',\n",
       " 'B2B Platform',\n",
       " 'IT',\n",
       " 'Clean Tech',\n",
       " 'Food & Beverage',\n",
       " 'Media',\n",
       " 'Publishing',\n",
       " 'Entertainment',\n",
       " 'Inspiration',\n",
       " 'Storytelling',\n",
       " 'Lifestyle',\n",
       " 'Consumer Portal',\n",
       " 'Others',\n",
       " 'FMCG',\n",
       " 'Reality',\n",
       " 'Auto',\n",
       " 'BFSI',\n",
       " 'Brand Licensing Startup',\n",
       " 'Gourmet Food Discovery & Delivery platform',\n",
       " 'Enterprise Marketing Automation platform',\n",
       " 'Health, Wellness & Beauty Services App',\n",
       " 'Digital Healthcare',\n",
       " 'Last Minute Hotel Booking App',\n",
       " 'Womens Fashion Wear Portal',\n",
       " 'Product Learning platform',\n",
       " 'Online Food Ordering & Delivery platform',\n",
       " 'App based Bus Pooling Services',\n",
       " 'Social Learning Platform',\n",
       " 'Social Fitness platform',\n",
       " 'On Demand Mobile app developer',\n",
       " 'Car Maintenance & Management mobile app',\n",
       " 'Online Wedding Marketplace',\n",
       " 'Splitting Bills Mobile App',\n",
       " 'IOT Energy Management Analytics platform',\n",
       " 'Custom Made furniture e-tailer',\n",
       " 'QSR Chain',\n",
       " 'E-Learning Service Provider',\n",
       " 'Smart Safety Wearable Devices',\n",
       " 'Cab Sharing service Mobile app',\n",
       " 'Cloud Enterprise Mobility Platform',\n",
       " 'Online Shopping Assistant Mobile app',\n",
       " 'Home Cooked Food Order & Delivery platform',\n",
       " 'Online School for Analytics learning',\n",
       " 'Chat based personal Assistant App',\n",
       " 'Picture creation & Social mobile app',\n",
       " 'Nonbanking finance company',\n",
       " 'eCommerce returns etailer',\n",
       " 'Online Freight Services Aggregator',\n",
       " 'Online Branded Furniture etailer',\n",
       " 'Digital Analytics Platform',\n",
       " 'Internet Network Infrastructure Services',\n",
       " 'Supply Chain & Logistics Solutions',\n",
       " 'Holiday Resort Chain',\n",
       " 'Mobile\\xa0Point\\xa0of\\xa0Sale\\xa0solutions',\n",
       " 'Peer-to-Peer Money Transfer & Recharge App',\n",
       " 'Test Automation SAAS platform',\n",
       " 'Citizens Engagement Platform',\n",
       " 'Indoor Navigation & Analytics Solutions',\n",
       " 'Hyperlocal On-Demand Household Services platform',\n",
       " 'Online RTI application services',\n",
       " 'ECommerce Website Creation SAAS platform',\n",
       " 'Wedding Venues & Vendors Marketplace',\n",
       " 'Interface development platform for Government officials',\n",
       " 'Modular Furnishings Marketplace',\n",
       " 'Private\\xa0Jet/\\xa0Helicopter\\xa0Marketplace',\n",
       " 'Cab search Comparison & Booking platform',\n",
       " 'Performance Optimization Platform for athletes',\n",
       " 'Event Venue Booking Platform',\n",
       " 'Digital Media Platform',\n",
       " 'visual search and discovery platform',\n",
       " 'Home services marketplace',\n",
       " 'End to End reverse logistics Solution platform',\n",
       " 'Virtual Health consultation app',\n",
       " 'Online Renting platform',\n",
       " 'Logistics\\xa0Services\\xa0Provider',\n",
       " 'Data Science & UX design Learning platform',\n",
       " 'Online marketplace for Chef Meals',\n",
       " 'Electric Bike & Scooter Manufacturer',\n",
       " 'eCommerce\\xa0platform',\n",
       " 'Online Media Publication',\n",
       " 'International Hiring Platform',\n",
       " 'Hyperlocal\\\\\\\\xc2\\\\\\\\xa0 Grocery Delivery Service',\n",
       " 'Sports Education Platform',\n",
       " 'Bike, Appliances Renting marketplace',\n",
       " 'Online Marketplace for Industrial Goods',\n",
       " 'Reward points mobile app',\n",
       " 'Mobile accessories online store',\n",
       " 'Content Discovery & reward points platform',\n",
       " 'Medical Consultation & Doctor appointment booking platform',\n",
       " 'Mobile Fitness App',\n",
       " 'Digital Coupons, Deal & Cashback aggregator app',\n",
       " 'Mobile Game development & Design platform',\n",
       " 'B2B eCommerce Marketplace',\n",
       " 'Furniture and appliances rental platform',\n",
       " 'B2B Merchandize platform',\n",
       " 'Real Estate focused Tech platform',\n",
       " 'Photographer Online search & booking platform',\n",
       " 'Grocery Delivery platform',\n",
       " 'Mobile Car Servicing appointment app',\n",
       " 'New Curation Mobile App',\n",
       " 'Mobile Wallet',\n",
       " 'Bus Aggregation and rental mobile app',\n",
       " 'hyperlocal online Services platform',\n",
       " 'WiFi \\\\xe2\\\\x80\\\\x93 first Cloud communication platform',\n",
       " 'Alternate Mobile Monetization platform',\n",
       " 'Quick Service Restaurant & Online Delivery',\n",
       " 'Online Loans Marketplace',\n",
       " 'Budget Hotels Aggregator',\n",
       " 'Efficient Energy Management platform',\n",
       " 'Digital Intelligent learning platform',\n",
       " 'Voice Call incentivization mobile app',\n",
       " 'Online Counselling and psychological support platform',\n",
       " 'Domestic Help Aggregation platform',\n",
       " 'Home Stay & room rentals platform',\n",
       " 'Selfie Mobile App',\n",
       " 'Online Reputation Management Platform',\n",
       " 'Online Grocer',\n",
       " 'Online content platform for women',\n",
       " 'Online Vehicle Spare Parts etailer',\n",
       " 'Event Ticketing platform',\n",
       " 'affordable Personal Healthcare Products',\n",
       " 'Premium dining Lounges & restaurants',\n",
       " 'Mobile Growth Hacking\\\\\\\\nPlatform',\n",
       " 'Skill Training & Placement Platform',\n",
       " 'Beauty and Wellness Platform',\n",
       " 'Marketplace App for Bangkok',\n",
       " 'On-demand Maids Service Provider',\n",
       " 'Ecommerce Product recommendation platform',\n",
       " 'Ready to cook packaged Foods',\n",
       " 'Product Customization Platform',\n",
       " 'Branded Food products online sales',\n",
       " 'Talent platform for Fashion professionals',\n",
       " 'Auto Insurance Online platform',\n",
       " 'Hyperlocal Logistics Service',\n",
       " 'Cricket Management Mobile Game',\n",
       " 'On-Demand\\xa0Laundry\\xa0&\\xa0Dry\\xa0cleaning\\xa0App',\n",
       " 'Ecommerce Discount & Cashback coupons platform',\n",
       " 'virtual\\xa0reality,\\xa03d\\xa0simulation\\xa0and\\xa0stereoscopic\\xa0products',\n",
       " 'Home Improvement Service platform',\n",
       " 'mobile-only tasks marketplace',\n",
       " 'Women Ethnic Wear\\\\\\\\xc2\\\\\\\\xa0 Online Marketplace',\n",
       " 'Numerical Computing & Data Science Platform',\n",
       " 'Designer fashion Jewellery Marketplace',\n",
       " 'Online Product Comparison',\n",
       " 'Kids Tool kit for Innovation platform',\n",
       " 'Mobile Learning Solutions',\n",
       " 'Car Aggregator & Retail Mobile App',\n",
       " 'conversational commerce mobile app',\n",
       " 'Viral Content web Platform',\n",
       " 'Express local delivery platform',\n",
       " 'On-Demand Local Logistics provider',\n",
       " 'Curated Freelancer Marketplace',\n",
       " 'Online Taxi Rental Platform',\n",
       " 'Mobile Services Marketplace',\n",
       " 'Smartwatch Maker',\n",
       " 'Online Gourmet Food Marketplace',\n",
       " 'Online Jewellery etailer',\n",
       " 'Sales & Productivity Software',\n",
       " 'ecommerce related software product platform',\n",
       " 'Health-Tech platform',\n",
       " 'Nightlife Discovery Mobile App',\n",
       " 'Online Real Estate Marketplace',\n",
       " 'Home Healthcare Services platform,',\n",
       " 'Indian Ethnic Crafts Etailer',\n",
       " 'Social platform for traders and investors',\n",
       " 'Online\\xa0Furniture,\\xa0Home\\xa0Appliances\\xa0Rental\\xa0Platform',\n",
       " 'Healthcare Services Discovery platform',\n",
       " 'Automotive Services platform',\n",
       " 'Online and TV Shopping Marketplace',\n",
       " 'Big Data & Analytics platform',\n",
       " 'Mobile App based Loan disbursement platform',\n",
       " 'Education Content Provider',\n",
       " 'Content Management Software Solutions',\n",
       " 'Fitness Tracking Management Solutions',\n",
       " 'Hyperlocal Grocery Delivery',\n",
       " 'Hyperlocal healthcare product Delivery Service provider',\n",
       " 'Online Lending Marketplace',\n",
       " 'On-Demand Beauty Service',\n",
       " 'Self Driven Rental Car Platform',\n",
       " 'Clud based Learning platform',\n",
       " 'Talent Exchange & Talent Services Marketplace',\n",
       " 'Two-Wheeler Taxi Service',\n",
       " 'character merchandize sales platform',\n",
       " 'Mobile Application Developer',\n",
       " 'Ecommerce Delivery locker services',\n",
       " 'extra curricular activities marketplace app',\n",
       " 'Hyperlocal Online Home services provider',\n",
       " 'Easy Business Loans platform',\n",
       " 'Performance based Wholesale Marketplace',\n",
       " 'Professional Service Appointment booking service',\n",
       " 'Movie-on-demand platform',\n",
       " 'us ticketing and fleet management platform',\n",
       " 'Online Income Tax Filing platform',\n",
       " 'Product\\xa0discovery\\xa0, Comparison &\\xa0recommendation\\xa0platform',\n",
       " 'Mobile Payments App',\n",
       " 'Beauty & Wellness Products e-tailer',\n",
       " 'Fashion jewelry and accessories e-tailer',\n",
       " 'Online Consumer Lending platform',\n",
       " 'Premium Apparel shopping portal',\n",
       " 'Exclusive Platform for Doctors & Healthcare professionals',\n",
       " 'Job Board',\n",
       " 'Sports Management & Physical Education Business',\n",
       " 'multi-sport program for preschoolers',\n",
       " 'QSR & Online delivery portal',\n",
       " 'Online Homeopathy Clinic',\n",
       " 'Organic Food ecommerce',\n",
       " 'Delivery & Logistics Service provider',\n",
       " 'Online Apparels Fashion brand',\n",
       " 'Home Cooked Food marketplace & Delivery',\n",
       " 'Gesture based Mobile Development',\n",
       " 'Hotel Mobile CRM Software platform',\n",
       " 'Rental Accommodation Search platform',\n",
       " 'Developer Portfolio Showcase platform',\n",
       " 'Doctors Network Mobile App',\n",
       " 'End-to-End Lending platform',\n",
       " 'on-demand healthcare marketplace',\n",
       " '360-degree view creating platform',\n",
       " 'Food Ordering & Delivery App',\n",
       " 'Ride Sharing platform',\n",
       " 'Online P2P lending marketplace',\n",
       " 'B2B marketplace for industrial goods',\n",
       " 'Cloud Based Collaboration platform',\n",
       " 'global community for travellers',\n",
       " 'Prepaid Bill manager App',\n",
       " 'Mobile Only Shopping Assistant',\n",
       " 'Mobile Messaging Assistant App',\n",
       " 'Personalized Wish List creator app',\n",
       " 'Music Streaming App',\n",
       " 'Raw Meat & Ready to eat food etailer',\n",
       " 'Gym Discovery platform',\n",
       " 'Online Purchase rewards app',\n",
       " 'Home rental platform',\n",
       " 'Crowdsourced Delivery platform',\n",
       " 'Real Estate Insights platform',\n",
       " 'Structural & Civil Engg Service Automation',\n",
       " 'Startup Funding Marketplace',\n",
       " 'Payment Solutions platform',\n",
       " 'Travel Destination Discovery platform',\n",
       " 'Order Fulfillment SAAS platform',\n",
       " 'Last Mile Delivery Service',\n",
       " 'Healthcare IT Solutions & services',\n",
       " 'Gourmet Meals Delivery',\n",
       " 'Healthy Meals Food delivery platform',\n",
       " 'Real Estate Mobile CRM',\n",
       " 'Micro-Brewery',\n",
       " 'Home Made Food Marketplace',\n",
       " 'Residential Rental management platform',\n",
       " 'Personalized Stock Intelligence Platform',\n",
       " 'Personal Diagnostic Mobile App',\n",
       " 'Hotel Aggregator & booking platform',\n",
       " 'Online Logistics Platform',\n",
       " 'Online Student & Campus Social Networking platform',\n",
       " 'Professionals & Project Search Marketplace',\n",
       " 'Online\\xa0Pharmacy\\xa0&\\xa0Drug\\xa0DB',\n",
       " 'Online Payment Gateway',\n",
       " 'Psychometric Test Online Software',\n",
       " 'Location based Nightlife recommendation\\\\\\\\xc2\\\\\\\\xa0 Platform',\n",
       " 'Professional Health Services Platform',\n",
       " 'Online user engagement platform',\n",
       " 'Asset Financing platform',\n",
       " 'Virtual Reality activity based learning platform',\n",
       " 'Industrial Tools Marketplace',\n",
       " 'Public Commute helper App',\n",
       " 'Truck Aggregator & Logistics service',\n",
       " 'Food Discovery,Delivery & Table Booking Mobile app',\n",
       " 'Competitive exam learning platform',\n",
       " 'Document Digitization platform',\n",
       " 'proximity marketing & Mobile Advertising platform',\n",
       " 'Auto Rickshaw Based Services',\n",
       " 'FinTech Startup Incubation platform',\n",
       " 'Payment Services platform',\n",
       " 'Personalized Styling platform',\n",
       " 'Luxury goods\\\\\\\\xc2\\\\\\\\xa0 Shopping Platform',\n",
       " 'Food Delivery Platform',\n",
       " 'Online Lingerie Marketplace',\n",
       " 'Cloud software solutions',\n",
       " 'Job Search Platform',\n",
       " 'Doctor consultancy Mobile App',\n",
       " 'Small Business Financing (NBFC)',\n",
       " 'Beauty & Wellness Services Marketplace',\n",
       " 'Online Movie Review Platform',\n",
       " 'ECommerce Brands\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99 Full Service Agency',\n",
       " 'Cloud-based\\xa0Hotel\\xa0Booking\\xa0Platform',\n",
       " 'Community Driven News/Views Platform',\n",
       " 'Study Material Marketplace',\n",
       " 'Restaurant Ratings & Reviews platform',\n",
       " 'Dairy Based Product Manufacturer',\n",
       " 'Government Test Preparation platform',\n",
       " 'Smart Report Cards for Schools',\n",
       " 'Teacher empowerment platform',\n",
       " 'Multilingual Test Preparation Platform',\n",
       " 'Non Profit Organization to alleviate poverty',\n",
       " 'Gym & Fitness Studios Subscription platform',\n",
       " 'pre-used luxury item Marketplace',\n",
       " 'pre-used apparel shopping mobile app',\n",
       " 'Home Design & platform',\n",
       " 'Used Vehicle Marketplace',\n",
       " 'Online Bus & Cab ticketing platform',\n",
       " 'Mobile App testing platform',\n",
       " 'Hyperlocal Delivery Services',\n",
       " 'Early Cancer Detection Solutions',\n",
       " 'Cab rental Mobile app',\n",
       " 'Online Insurance Aggregator',\n",
       " 'Mobile Marketing Automation Platform',\n",
       " 'Prepaid Mobile Bill Manager App',\n",
       " 'Chain of Tea Caf\\\\\\\\xc3\\\\\\\\xa9\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s',\n",
       " 'Branded Budget Hotel Marketplace',\n",
       " 'Home Fitting & Fixtures Marketplace',\n",
       " 'Food Subscription platform',\n",
       " 'Wedding Planning Platform',\n",
       " 'B2B Mobile Auction Marketplace',\n",
       " 'ECommerce Data Analytics Platform',\n",
       " 'Designer Merchandize Marketplace',\n",
       " 'Private label Fashion eTailer',\n",
       " 'Real Estate Broker Platform App',\n",
       " 'Online Health & Wellness platform',\n",
       " 'Internet of Things platform',\n",
       " 'Diagnostic Labs aggregator platform',\n",
       " 'Hyperlocal Delivery Platform',\n",
       " 'Home Medical Care Services',\n",
       " 'Real-Time stock data platform',\n",
       " 'coupons and cashback aggregator app',\n",
       " 'Financial Products lead generation platform',\n",
       " 'Sustainable Agri-inputs Firm',\n",
       " 'Financial Services Platform',\n",
       " 'Pre-owned games Marketplace',\n",
       " 'Content-based Subscription eCommerce platform',\n",
       " 'Online Interior Designing platform',\n",
       " 'End-to-end Logistics platform',\n",
       " 'Private Label Apparel sales',\n",
       " 'Healthcare Consulting platform',\n",
       " 'Stock Market Portal',\n",
       " 'Cross-device retargeting platform',\n",
       " 'Digital & Physical Publishing platform',\n",
       " 'Data Driven Publishing platform',\n",
       " 'Employee OnBoarding & Orientation platform',\n",
       " 'Solar Power Solutions company',\n",
       " 'Online Meat Ordering platform',\n",
       " 'online meal-booking platform for train travelers',\n",
       " 'Cab Booking app platform',\n",
       " 'E-Commerce & M-Commerce platform',\n",
       " 'Mobile Advertising platform',\n",
       " 'Activity Based Social Network',\n",
       " 'Fashion Discovery platform',\n",
       " 'Consumer lending marketplace',\n",
       " 'Big Data Management Platform',\n",
       " 'Budget Accommodation Platform',\n",
       " 'Local Mobile OS',\n",
       " 'Digital Signal processing platform',\n",
       " 'Ecommerce Marketplace',\n",
       " 'Restaurant Discount app',\n",
       " 'Tech-enabled learning',\n",
       " 'ECommerce Logistics provider',\n",
       " 'on-demand home beauty and wellness portal',\n",
       " 'Self Driven Car rental',\n",
       " 'Budget Hotel Accommodation',\n",
       " 'Energy & Environment Online Marketplace',\n",
       " 'User Engagment & Analytics platform',\n",
       " 'On-Demand Delivery Logistics',\n",
       " 'fund raising platform for startups',\n",
       " 'Online budget hotel chain',\n",
       " 'Hyperlocal Handyman Services',\n",
       " 'hotel booking app',\n",
       " 'Tech Platform for property brokers',\n",
       " 'Luxury Apparel rental',\n",
       " 'App security\\\\\\\\xc2\\\\\\\\xa0 testing platform',\n",
       " 'Doctor Appointment booking app',\n",
       " 'anonymous bulletin board app',\n",
       " 'Travel community platform',\n",
       " 'Crowd Funding Platform',\n",
       " 'Mobile based PoS solution',\n",
       " 'Car & Bike ecommerce platform',\n",
       " 'Fast food Chain Franchisee',\n",
       " 'Loyalty Programs & Reward Points',\n",
       " 'Energy saving solutions provider',\n",
       " 'Self-Storage Spaces',\n",
       " 'Grocery retail Mobile app',\n",
       " 'Taxi Rental platform',\n",
       " 'Machine Learning Platform',\n",
       " 'mobile social network',\n",
       " 'Hyper-Local Ecommerce',\n",
       " 'Online printing marketplace',\n",
       " 'Automated Storage & Warehousing Solution',\n",
       " 'Subscription based Online Grocery platform',\n",
       " 'engineering services company',\n",
       " 'Business and IT consulting',\n",
       " 'Credit Card Fraud protection solutions',\n",
       " 'Online & mobile Grocery store',\n",
       " 'Career Community for Women',\n",
       " 'Mutual Fund Investing platform',\n",
       " 'Ecommerce Marketing Software Platform',\n",
       " 'Financial Inclusion platform',\n",
       " 'Digital Marketing Services',\n",
       " 'Mobile Commerce for Farmers',\n",
       " 'Picture based Social App',\n",
       " 'Exam Preparation Platform',\n",
       " 'Startup Focused Online Publisher',\n",
       " 'App based Fitness coaching',\n",
       " 'On demand cleaning & fixing services',\n",
       " 'Beauty & Lifestyle platform',\n",
       " 'Data Analytics Platform',\n",
       " 'Deep Learning Cloud Algorithms',\n",
       " 'Location based engagement & rewards platform',\n",
       " 'Online Identity Verification Services platform',\n",
       " 'Corporate Wellness App',\n",
       " 'Fashion Search & Review Platform',\n",
       " 'Hyperlocal Maintenance, Repair & Cleaning services',\n",
       " 'pre-owned Luxury online apparel seller',\n",
       " 'Online Diagnostic Tests Marketplace',\n",
       " 'Online marketplace for Photographers',\n",
       " 'Visual Blogging platform',\n",
       " 'Food Customer analytics platform',\n",
       " 'Scientific Horoscope Online Assistance platform',\n",
       " 'Tech enabled AC bus service',\n",
       " 'On-Demand App based Professional service provider',\n",
       " 'Restaurant Reservation Platform',\n",
       " 'Cross-channel CRM platform',\n",
       " 'Professional Custom creators Marketplace',\n",
       " 'on-Demand Washing & Dry-Cleaning',\n",
       " 'solar products and services marketplace',\n",
       " 'Online Food Community Platform',\n",
       " 'Private Cloud Networks SAAS platform',\n",
       " 'Education Marketplace',\n",
       " 'online recipe sharing platform',\n",
       " 'Beauty & Lifestyle Mobile Marketplace',\n",
       " 'QSR Restaurant Chain',\n",
       " 'Digital Media publishing platform',\n",
       " 'Online Coffee Delivery platform',\n",
       " 'Language Localization Cloud platform',\n",
       " 'Big Data & predictive Analysis Platform',\n",
       " 'Business IT Intelligence Services',\n",
       " 'CRM / Analytics platform',\n",
       " 'Hyperlocal Electronics repair Service',\n",
       " 'Ed-Tech Platform',\n",
       " 'IT infrastructure & Data Center services',\n",
       " 'Online Financial Services',\n",
       " 'Used Car Marketplace',\n",
       " 'Language Learning App',\n",
       " 'Mobile Fitness Marketplace',\n",
       " 'Custom Merchandize platform',\n",
       " 'P2P Pre-owned goods marketplace',\n",
       " 'Custom Furniture Marketplace',\n",
       " 'Online Tailoring Services',\n",
       " 'Rail Ticket Confirmation predictor',\n",
       " 'Ethnic Beverages manufacturer',\n",
       " 'Hyperlocal Goods marketplace',\n",
       " 'Real Estate Rating & Analysis',\n",
       " 'Food Discovery App',\n",
       " 'Coupon Aggregator Platform',\n",
       " 'Online Food-Tech Platform',\n",
       " 'Celebrity Fashion Brand',\n",
       " 'Online Finance lending platform',\n",
       " 'Healthcare Mobile App',\n",
       " 'Self-driven vehicle rental',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0News Aggregator mobile app',\n",
       " 'Online Grocery Delivery',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Fashion Info Aggregator App',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Warranty Programs Service Administration',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Pre-School Chain',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Premium Loyalty Rewards Point Management',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Contact Center Software Platform',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Casual Dining restaurant Chain',\n",
       " 'Online comparison engine',\n",
       " 'Physical Storage warehouses',\n",
       " 'Tech Recruitment platform',\n",
       " 'Bike Rental Platform',\n",
       " 'Tech enabled logistics platform',\n",
       " 'Restaurant customer engagement platform',\n",
       " 'Live video streaming app',\n",
       " 'F&B sector Mobile Payment platform',\n",
       " 'Industrial Supplies B2B ecommerce',\n",
       " 'Online Hiring Platform',\n",
       " 'Fine Dining Restaurant Chain',\n",
       " 'Luxury Rental Homes',\n",
       " 'Casual Dating App',\n",
       " 'Clinical Genomics Provider',\n",
       " 'Travel information portal',\n",
       " 'Fitness Marketplace',\n",
       " 'Online & Mobile classified listings',\n",
       " 'Ethnic/ Traditional Fashion Store',\n",
       " 'Spa & Salon Management Software',\n",
       " 'B2B logistics delivery platform',\n",
       " 'Logistics Automation Platform',\n",
       " 'Online Home ',\n",
       " 'Hyperlocal food & grocery store',\n",
       " 'Medical Tech Instruments',\n",
       " 'Hyperlocal Deals Marketplace',\n",
       " 'Innovative Water Solutions',\n",
       " 'Online Jewelry Store',\n",
       " 'Business intelligence & Analytics',\n",
       " 'Educational Board Games',\n",
       " 'Chinese food delivery',\n",
       " 'On-Demand Car services App',\n",
       " 'Online Curated Holiday package bookings',\n",
       " 'Hasbro Toy Manufacturer',\n",
       " 'Healthy Food Manufacturer',\n",
       " 'Online Learning Platform',\n",
       " 'Healthy Food Online Community',\n",
       " 'Used two-wheeler Marketplace',\n",
       " 'Online Fashion Video Portal',\n",
       " 'Probiotic Technology Products Manufacturer',\n",
       " 'Architectural Design & Consulting',\n",
       " 'Preventive Healthcare Services',\n",
       " 'Tech-enabled Rural Healthcare Services',\n",
       " 'Engineering Innovations',\n",
       " 'Real Estate Intelligence Platform',\n",
       " 'Online Car Rental Affiliates',\n",
       " 'Data Center Software platform',\n",
       " 'Online City & Lifestyle Guide',\n",
       " 'P2P Payments platform',\n",
       " 'Bespoke Merchandize Marketplace',\n",
       " 'Women Lifestyle Marketplace',\n",
       " 'Logistics Solution Provider',\n",
       " 'Video Intelligence Platform',\n",
       " 'Hyperlocal Shopping App',\n",
       " 'Renewable energy solutions',\n",
       " 'Artist / Designer Marketplace',\n",
       " 'Off-grid Solar Power',\n",
       " 'Private Label lingerie Ecommerce',\n",
       " 'Mobile Commerce Platform',\n",
       " 'Online Printing Services',\n",
       " 'Travel Guide Mobile App',\n",
       " 'Fashion ECommerce',\n",
       " 'Mobile Compression Software',\n",
       " 'Peer to Peer Lending platform',\n",
       " 'Global Healthcare products',\n",
       " 'Home Furnishing Solutions',\n",
       " 'Intra-City Logistics service',\n",
       " 'online tiffin service aggregator',\n",
       " 'Electronic Goods recycling service',\n",
       " 'Online Coupon & comparison platform',\n",
       " 'Parents & Kids Online platform',\n",
       " 'Dental Clinic chain',\n",
       " 'On-Demand Logistics Service',\n",
       " '3D Printer Manufacturer',\n",
       " 'IT / Customer Engagement Consulting',\n",
       " 'Health & Fitness App',\n",
       " 'Social Network for Artists',\n",
       " 'Data Driven recruitment recommendation',\n",
       " 'Travel Search Engine',\n",
       " 'Brain Games Platform',\n",
       " 'Video Advertisement Platform',\n",
       " 'Algorithmic Match Making Platform',\n",
       " 'Mobile Chat based concierge service',\n",
       " 'Science Learning App',\n",
       " 'SaaS product intelligence platform',\n",
       " 'App Analytics platform',\n",
       " 'Micro Finance Platform',\n",
       " 'Freight logistics platform',\n",
       " 'Credit Management Services',\n",
       " 'Hyperlocal services marketplace',\n",
       " 'Beauty services Mobile Marketplace',\n",
       " 'Marketing / Advertising Automation platform',\n",
       " 'Railways Information Mobile app',\n",
       " 'Flat rental Mobile App',\n",
       " 'Wealth Management Platform',\n",
       " 'Online Food Delivery',\n",
       " 'Fund Raising Platform',\n",
       " 'Workforce Management Software',\n",
       " 'Online Art Marketplace',\n",
       " 'Affordable Education',\n",
       " 'Career Development',\n",
       " 'Real Estate Advisory',\n",
       " 'Banking Analytics Platform',\n",
       " 'Customer Engagement Platform',\n",
       " 'Speech Recognition Solutions',\n",
       " 'Online Security Platform',\n",
       " 'Online Medical Diagnostic',\n",
       " 'Cloud Data Integration Platform',\n",
       " 'Mobile Laundry Cleaning Service',\n",
       " 'Service-On-Demand Mobile App',\n",
       " 'Intelligent Data Analytics',\n",
       " 'Online Office Rental',\n",
       " 'Lifestyle Ecommerce Portal',\n",
       " 'Online Fashion Aggregator',\n",
       " 'Online Job skills Showcase',\n",
       " 'Online News Media',\n",
       " 'Enterprise Communication Platform',\n",
       " 'Offline Tea Chain',\n",
       " 'Business Messaging App',\n",
       " 'Health Mobile App',\n",
       " 'Online Ed-Tech Platform',\n",
       " 'Online Travel Marketplace',\n",
       " 'Hyperlocal Mobile Marketplace',\n",
       " 'Trucking Logistic Operations',\n",
       " 'B2C Messaging App',\n",
       " 'Rooftop Solar Plants',\n",
       " 'Online Car Portal',\n",
       " 'Online Table Reservation',\n",
       " 'Parents focused Web Content',\n",
       " 'Payments Solution Provider',\n",
       " 'On-demand Service marketplace',\n",
       " 'On-Demand Business messaging',\n",
       " 'API Workflow platform',\n",
       " 'Affordable Hotel Booking Online',\n",
       " 'Logistics Intelligence',\n",
       " 'Last Mile Logistics',\n",
       " 'Weight Management Service',\n",
       " 'Web Content Publishing',\n",
       " 'Location Based App',\n",
       " 'Video Streaming',\n",
       " 'Price Comparison',\n",
       " 'Online\\xa0Classifieds\\xa0&\\xa0Listings',\n",
       " 'Travel Entertainment',\n",
       " 'Digital / Mobile Wallet',\n",
       " 'Cab Aggregator',\n",
       " 'Device Repair Svcs',\n",
       " 'Premium Beverages',\n",
       " 'Interactive\\\\\\\\xc2\\\\\\\\xa0 How-To Guides',\n",
       " 'Mobile Health Tech',\n",
       " 'Restaurant Reviews',\n",
       " 'Online Hotel Booking',\n",
       " 'Online Kitchen Furniture',\n",
       " 'Hyper-local Online Services',\n",
       " 'Hyper-Local Online/Mobile Grocery',\n",
       " 'Online Policy Aggregator',\n",
       " 'OnDemand\\\\\\\\nMobile Handyman Services',\n",
       " 'Mobile App Development',\n",
       " 'On-Demand Handyman Services',\n",
       " 'Beauty & Wellness Mobile App',\n",
       " 'Material Collection & Recycling',\n",
       " 'Online / Mobile Customer Support',\n",
       " 'Private Coaching Centers',\n",
       " 'Online Certification Courses',\n",
       " 'Ethnic Product eCommerce',\n",
       " 'Last Minute Travel Deals mobile marketplace',\n",
       " 'usiness expense management',\n",
       " 'Spam Call block App',\n",
       " 'Restaurant Management Platform',\n",
       " 'Food Logistics & Delivery',\n",
       " 'Interactive Educational Games',\n",
       " 'Grey collar Job Board',\n",
       " 'Robotic Program learning',\n",
       " 'Tele-Shopping / eCommerce',\n",
       " 'Used Gadgets Buy / Refurbishing',\n",
       " 'Startup Analytics platform',\n",
       " 'Mobile Food Ordering app',\n",
       " 'Financial Markets Software',\n",
       " 'Hiring Analytics platform',\n",
       " 0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vertical'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcf0a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace('\\xa0',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a8f4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace('\\\\\\\\xc2\\\\\\\\xa0',''))\n",
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace(' \\\\xe2\\\\x80\\\\x93',''))\n",
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace('\\\\\\\\n',' '))\n",
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99',''))\n",
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace('Chain of Tea Caf\\\\\\\\xc3\\\\\\\\xa9\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s','Chain of Tea Cafes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d2e79a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   Ed-Tech\n",
       "1            Transportation\n",
       "2                 eCommerce\n",
       "3                   FinTech\n",
       "4       Fashion and Apparel\n",
       "               ...         \n",
       "3039                      0\n",
       "3040                      0\n",
       "3041                      0\n",
       "3042                      0\n",
       "3043                      0\n",
       "Name: vertical, Length: 3044, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vertical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2992e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               1\n",
       "startup            0\n",
       "vertical           0\n",
       "subvertical        0\n",
       "location           0\n",
       "investor           0\n",
       "investment_type    0\n",
       "amount             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abe735",
   "metadata": {},
   "source": [
    "# subvertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6b2fd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E-learning',\n",
       " 'App based shuttle service',\n",
       " 'Retailer of baby and toddler products',\n",
       " 'Online Investment',\n",
       " 'Embroiled Clothes For Women',\n",
       " 'Open-market, freight management platform',\n",
       " 'Online Food Delivery Platform',\n",
       " 'Agri-tech',\n",
       " 'Automobile',\n",
       " 'Satellite Communication',\n",
       " 'Logistics Services and Solutions',\n",
       " 'Food Solutions For Corporate',\n",
       " 'Online Meat And Seafood Ordering Startup',\n",
       " 'Non-Banking Financial Company',\n",
       " 'Experience Discovery Platform',\n",
       " 'Real money based gaming startup',\n",
       " 'Online Eyewear Shopping Portal',\n",
       " 'Business and customer engagement tools',\n",
       " \"Men's Health and Wellness brand\",\n",
       " 'Indian Burger Brand',\n",
       " 'Healthcare services',\n",
       " 'Financial Services To MSMEs',\n",
       " 'Social gaming platform',\n",
       " 'Recovery software',\n",
       " 'Electric bike rental',\n",
       " 'Virtual e-commerce platform',\n",
       " 'B2B platform for medical supplies',\n",
       " 'Scooter sharing app',\n",
       " 'Music Education',\n",
       " 'Mobile Wallet',\n",
       " 'Delivery Service',\n",
       " 'Business development',\n",
       " 'Beauty and Grooming',\n",
       " 'Financial Services',\n",
       " 'Invoice discounting platform and SME lending marketplace',\n",
       " 'Digital marketing firm',\n",
       " 'Education Technology',\n",
       " 'Building automation system',\n",
       " 'Deep-technology',\n",
       " 'Consumer Electronics, Home Appliances',\n",
       " 'Wearable Fitness Bands',\n",
       " 'Mobile-based Accounting Software',\n",
       " 'Automotive',\n",
       " 'Supply Chain Management',\n",
       " 'Fuel Delivery',\n",
       " 'VC Funds',\n",
       " 'Last-mile retail transaction technology',\n",
       " 'Social Commerce',\n",
       " 'Car Retail',\n",
       " 'Conversational AI',\n",
       " 'Road Safety Analytics',\n",
       " 'Low carb food for Diabetics',\n",
       " 'Digital Lending Platform',\n",
       " 'Wealth Management',\n",
       " 'B2B Foodtech',\n",
       " 'University Admissions',\n",
       " 'Product Review',\n",
       " 'Grocery Delivery',\n",
       " 'Bike Taxi',\n",
       " 'Auto Insurance',\n",
       " 'Big Data',\n",
       " 'Consulting',\n",
       " 'Cabs',\n",
       " 'Speech Recognition',\n",
       " 'Digital Vending Machine',\n",
       " 'Education',\n",
       " 'Industrial Tools and Equipments',\n",
       " 'Logistics',\n",
       " 'Smartphone Operating System',\n",
       " 'Primary care medical network',\n",
       " 'Clothes and Apparel',\n",
       " 'Full-stack career platform',\n",
       " 'Real Estate',\n",
       " 'Brewery',\n",
       " 'Hospitality',\n",
       " 'FinTech',\n",
       " 'Optimization',\n",
       " 'Artificial Intelligence',\n",
       " 'Hybrid Reactor Biodigestor',\n",
       " 'Renewable Energy',\n",
       " 'E-Books',\n",
       " 'Video Platform',\n",
       " 'Online Lending Platform',\n",
       " 'Dockless Scooter Rental Company',\n",
       " 'Digital Documentation',\n",
       " 'Fashion and Shopping',\n",
       " 'Beauty and Wellness Industry',\n",
       " 'Electric Vehicle',\n",
       " 'Fresh Agriculture Produces',\n",
       " 'Retail',\n",
       " 'Online Medicine',\n",
       " 'Waste Management',\n",
       " 'Travel',\n",
       " 'Organic wellness',\n",
       " 'Banking',\n",
       " 'Fashion and Apparel',\n",
       " 'Mobile analytics and marketing',\n",
       " 'Software Solutions',\n",
       " 'Lending Platform',\n",
       " 'Bus Aggregation',\n",
       " 'Supply-chain technology solutions',\n",
       " 'Fashion & Apparel',\n",
       " 'Anti-Pollution',\n",
       " 'Budget Rooms',\n",
       " 'Online Marketplace',\n",
       " 'Specialty pharmaceutical',\n",
       " 'Hyperlocal Content',\n",
       " 'Home services marketplace',\n",
       " 'Platform for travel agents',\n",
       " 'Video-based certification, trainings',\n",
       " 'eCommerce',\n",
       " 'Real Estate, ERP',\n",
       " 'Regional Flavours',\n",
       " 'MSME Finance',\n",
       " 'Mobile e-Sports',\n",
       " 'Meat Retail Chain',\n",
       " 'POS For Online Ordering',\n",
       " 'Micro-delivery grocery service',\n",
       " 'On-Demand Drivers',\n",
       " 'Car Wash',\n",
       " 'Robotics',\n",
       " 'Wellness Coach',\n",
       " 'Personalized Learning',\n",
       " 'SME Funding',\n",
       " 'Art',\n",
       " 'Digital Onboarding Solution',\n",
       " 'AI Platform',\n",
       " 'SME Lending',\n",
       " 'Video Sharing',\n",
       " 'Mens Wear',\n",
       " 'Supply Chain',\n",
       " 'Wine',\n",
       " 'New and Used Cars Platform',\n",
       " 'Co-Working',\n",
       " 'Largest Trucking Platform',\n",
       " 'Book Trucks Online',\n",
       " 'Online Pharmacy Chain',\n",
       " 'Logistics and Shipping',\n",
       " 'News and ebooks Mobile App\\\\\\\\xc2\\\\\\\\xa0',\n",
       " 'Healthcare Service Provider',\n",
       " 'Online Travel Agecy',\n",
       " 'Online Marketplace For Multi-brand Beauty Cosmetic and Wellness Products',\n",
       " 'Computer Vision And Artificial Intelligence (Ai) Platform',\n",
       " 'Online Gaming Platform',\n",
       " 'Online Marketplace For Mother and Babycare Products',\n",
       " 'AI-Based Energy Optimisation and Control Provider',\n",
       " 'Online Marketplace For Pharmaceutical Products',\n",
       " 'Online Micro Lending Marketplace',\n",
       " 'Personalisation Technology Firm Focusing On The Food And Beverage Industry',\n",
       " 'Patient Financing Platform',\n",
       " 'Social Media and Chat Entertainment Platform',\n",
       " 'Online Home Rental Marketplace',\n",
       " 'Holy Platform Offering Customised Puja Packages To Individuals and Corporates',\n",
       " 'Assisted E-commerce Platform',\n",
       " 'Online Travel Aggregator',\n",
       " 'Real-time Mobile App Management',\n",
       " 'Online Bike Rental Marketplace',\n",
       " 'UPI Payments App',\n",
       " 'e-learning Platform',\n",
       " 'Consumer Financing Platform',\n",
       " 'Rural E-commerce Platform',\n",
       " 'AI Based Solutions Platform',\n",
       " 'Online Restaurant Table Reservation Platform',\n",
       " 'Online Loan Matchmaking Platform',\n",
       " 'Online Organic Juice Delivery Service',\n",
       " 'Applied Artificial Intelligence and IoT focused\\\\\\\\xc2\\\\\\\\xa0Platform',\n",
       " 'Online Indian Car Rental Platform',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Customer Sourcing Platform\\\\\\\\xc2\\\\\\\\xa0',\n",
       " 'Local Language Health Content App',\n",
       " 'Post-Purchase Customer Engagement Platform\\\\\\\\xc2\\\\\\\\xa0',\n",
       " 'Private Equity Firm',\n",
       " 'HR Virtual Agent For Employees',\n",
       " 'Online Food Delivery',\n",
       " 'E-commerce Fulfilment Platform',\n",
       " 'Online Lending Platform For Salaried Professionals',\n",
       " 'Online Insurance Selling Platform',\n",
       " 'Online Platform For Risk-Assessment Services For Real Estate Investments',\n",
       " 'Online Platform That Sells Direct Plans Of Mutual Funds',\n",
       " 'Online Platform That Connects Brands With Freelance Sales Professionals',\n",
       " 'Med-tech Platform Providing Care For Newborns',\n",
       " 'Lending Platform For Micro and Small Enterprises',\n",
       " 'Mobile Storefront And Commerce Platform For Sellers',\n",
       " 'Online Micro Lending Platform',\n",
       " 'Artificial intelligence-based sales acceleration software platform',\n",
       " 'Home diagnostics services provider',\n",
       " 'A Doctor-Patient Engagement Platform',\n",
       " 'Online Lending Platform For SME',\n",
       " 'Online Used Car Marketplace',\n",
       " 'Subscription-Only News Website',\n",
       " 'Online Ticketing Platform',\n",
       " 'Property Discovery Platform',\n",
       " 'Online Consumer Lending platform',\n",
       " 'Bicycle sharing Platform',\n",
       " 'Media Analytics',\n",
       " 'Nanotechnology Company Specializing In Graphene',\n",
       " 'Skill Learning Platform',\n",
       " 'Online Insurance Startup',\n",
       " 'Mobile-First Video Blogging App',\n",
       " 'Data Analytics Firm',\n",
       " 'Software-As-A-Service Platform',\n",
       " 'Travel-Focused Tech Startup',\n",
       " 'Unified Global Investments Ecosystem',\n",
       " 'Bus Aggregation Platform',\n",
       " 'Health and fitness Platform',\n",
       " 'Non-Bank Lending Platform For SME',\n",
       " 'Health and Well being Platform',\n",
       " 'Credit-Based Lending Marketplace For Small And Medium Enterprises',\n",
       " 'Sales Analytics and Enablement Platform',\n",
       " 'Online Marketplace For Handicrafts, Handlooms And Local Produce',\n",
       " 'Online Crowdfunding Platform',\n",
       " 'Online Healthcare Aggregator',\n",
       " 'Online Marketplace For Resellers',\n",
       " 'Specialised diagnostics Platform',\n",
       " 'Supplychain Finance',\n",
       " 'Fashion eTailer',\n",
       " 'Hyperlocal Delivery Platform',\n",
       " 'An Online Platform That Connects Ayurveda Doctors With Patients',\n",
       " 'Mass Market Mutual Fund Investment Platform',\n",
       " 'A Local Discovery App For Dining-Out, Party, Leisure and Events',\n",
       " 'Online Home Furnishing Solutions',\n",
       " 'Cybersecurity Specialist',\n",
       " 'Prosthetics Manufacturers',\n",
       " 'Data Analytics (SaaS)',\n",
       " 'Education Services Provider',\n",
       " 'Online Rental Marketplace',\n",
       " 'Trade Finance Firm',\n",
       " 'Online Motorbike And Scooter Rental Platforms',\n",
       " 'Digital Payment Platform For Beverage Delivery',\n",
       " 'App-based investment platform',\n",
       " 'Digital Payment Platform',\n",
       " 'Data Driven Intelligence Solutions Platform',\n",
       " 'E-commerce Logistics Platform',\n",
       " 'An AI Platform Offering Automated Customer Service Software',\n",
       " 'Online Education Platform',\n",
       " 'An Artificial Intelligence-Based Recruitment Platform',\n",
       " 'Aggregator For Packaging Material',\n",
       " 'SaaS',\n",
       " 'P2P Lending Platform',\n",
       " 'AI product company For Health and Life Insurane Companies',\n",
       " 'Beauty e-tailer',\n",
       " 'Doctor-Consultation App',\n",
       " 'Online Video Creation Platform',\n",
       " 'Micro-Delivery Grocery Startup',\n",
       " 'Micro Lending Platform',\n",
       " 'Products For Shoolgoing Children',\n",
       " 'Housing Finance For Low-Income Families',\n",
       " 'Designer Of Toys and Learning Projects For Kids',\n",
       " 'Oxygen Optimiser Manufacturer',\n",
       " 'Online Insurance Platform',\n",
       " 'Home Healthcare Aggregator',\n",
       " 'Mobile Payments Technology Platform',\n",
       " 'Events and Activities Discovery Platform',\n",
       " 'Iot Application Platform In Agriculture',\n",
       " 'Lending Platform For SMEs',\n",
       " 'Online Fitness Discovey Platform',\n",
       " 'Social Media Anlaytics Platform',\n",
       " 'Enhanced Employee Engagement Platform',\n",
       " 'Loans and Services To Affordable Private Schools in India',\n",
       " 'Interactive Online Tutoring Platform',\n",
       " 'Digital Financial Services Platform',\n",
       " 'Fashion Accessories Etailer',\n",
       " 'Blockchain Platform',\n",
       " 'Mobile-Based Education Network',\n",
       " 'Digital Lending Platform In Logistics',\n",
       " 'Online Travel Marketplace',\n",
       " 'Platform To Discover Healthcare Financing Options',\n",
       " 'Online Platform For Luxury Hotel Stay For Business Travelers',\n",
       " 'Connected Care App For Pregnant Women',\n",
       " 'Online Insurance Aggregator',\n",
       " 'Online Eyewear Retailer',\n",
       " 'Online Baby care Products',\n",
       " 'AI Based Expense Management Platform',\n",
       " 'Mobile Balance Checking App',\n",
       " 'AI Driven Health tech Platform',\n",
       " 'Digitized Health-Tech Solutions For Practitioners',\n",
       " 'Online Platform Providing Micro Loans For Air Travel',\n",
       " 'Women Focussed Digital Media Platform',\n",
       " 'Online Travel Ticketing Platform',\n",
       " 'Online Pharmacy Store',\n",
       " 'Online Lending MarketPlace',\n",
       " 'Online Stock Broker',\n",
       " 'B2C Online Loans Marketplace',\n",
       " 'Online Scholarship Portal',\n",
       " 'Online Furniture Store',\n",
       " 'Online Financial Planning',\n",
       " 'Therapeutics',\n",
       " 'Genetic Screening, DNA Diagnostics Labs & Research Centers',\n",
       " 'Online Lending',\n",
       " 'Cloud based Online Hotel Management Software',\n",
       " 'Health Service Aggregator Platform',\n",
       " 'Creative Design, Brand, Media and Technology Platform Solutions',\n",
       " 'Online Furniture Shopping Store',\n",
       " 'Hyperlocal Discovery',\n",
       " 'Healthcare Aggregator',\n",
       " 'Online Communication and Collaboration Platform For Educational Institutions',\n",
       " 'Online Grocery Shop',\n",
       " 'Ready To cook Food Solution',\n",
       " 'Technology enabled equitable healthcare for India',\n",
       " 'Online Raw Meat E-tailer',\n",
       " 'Customer Success Software for B2B SaaS',\n",
       " 'Consumer Technology and Artificial Intelligence Based Aggregator App',\n",
       " 'Micro Jobs Provider For Students',\n",
       " 'Subscription Billing & Recurring Payments Software',\n",
       " 'Online loan platform',\n",
       " 'Voice-based assistant platform',\n",
       " 'Online ordering solution for restaurants and food chains',\n",
       " 'Fleet management and asset monitoring platform',\n",
       " 'Micro lending company',\n",
       " 'News Portal',\n",
       " 'Professional Car Drivers Hiring App',\n",
       " 'O2O fashion ecommerce platform',\n",
       " 'Online Grocery & Food Store',\n",
       " 'Food Ordering and Restaurant Discovery',\n",
       " 'E-Publishing',\n",
       " 'Super-specialty Hospital',\n",
       " 'Online platform for Higher Education Services',\n",
       " 'Online Food Marketplace',\n",
       " 'Preventive Health Checkup',\n",
       " 'Online Portal for Diet,fitness and Beauty',\n",
       " 'Enterprise Contract Management Platform',\n",
       " 'Mobile Weight Loss Coach',\n",
       " 'Virtual health clinics',\n",
       " 'Online Gold Loan',\n",
       " 'Marketing Cloud for consumer businesses',\n",
       " 'B2B Marketplace',\n",
       " 'Online Selling',\n",
       " 'Mobile Solutions for Social Impact',\n",
       " 'Individualised Progressive Learning Program',\n",
       " 'Integrated Kids Engagement Company',\n",
       " 'Mobile Payment Platform',\n",
       " 'Online Pet Care Products',\n",
       " 'Online Retailing',\n",
       " 'Expense Management',\n",
       " 'Analytics',\n",
       " 'Cloud-based Software',\n",
       " 'Robotic InspectionStartup',\n",
       " 'Digital Design',\n",
       " 'AI platform for hospitality industry',\n",
       " 'Online Music Streaming',\n",
       " 'Cancer radiology',\n",
       " 'Mobile App Analytics',\n",
       " 'Food and Beverages',\n",
       " 'Sports Nutrition Supplement etailer',\n",
       " 'Digital Entertainment for Children',\n",
       " 'Personal Assistant',\n",
       " 'Agricultural Loan',\n",
       " 'Medical Devices',\n",
       " 'Algorithmic Trading',\n",
       " 'Payment Gateway',\n",
       " 'Venture Capital',\n",
       " 'IT',\n",
       " 'Social',\n",
       " 'Alternative Lending',\n",
       " 'Online\\xa0Grocery',\n",
       " 'Digital Lending',\n",
       " 'Coaching Services',\n",
       " 'Eyewear',\n",
       " 'Hemostatic Dressing Solutions',\n",
       " 'Technology',\n",
       " 'Online Services',\n",
       " 'Hygiene',\n",
       " 'Browser Testing',\n",
       " 'Virtual Reality',\n",
       " 'Fitness',\n",
       " 'Education Solutions',\n",
       " 'IoT based air pollution controller',\n",
       " 'Daily Task Management Mobile App',\n",
       " 'Residential Project',\n",
       " 'Mobile Learning Management Platform',\n",
       " 'Off-grid solar products platform',\n",
       " 'Child Learning & Development Platform',\n",
       " 'Mobile point of sale services provider',\n",
       " 'Home Decor and Online Fashion Portal',\n",
       " 'Super speciality Hospitals',\n",
       " '\"Women\\\\\\\\\\'s Fashion Clothing Online Platform\"',\n",
       " 'Mobile News Curation App',\n",
       " 'Online Platform Selling Indian Tea Globally',\n",
       " 'Educational Platform to Learn Mathematics',\n",
       " 'Assisting Visually Impaired to learn through Braille',\n",
       " 'Furniture Rental Platform',\n",
       " 'Hotel Aggregator Platform',\n",
       " 'Platform based on 3D printing and Digital Manufacturing',\n",
       " 'Adaptive Fraud Intelligence Platform',\n",
       " 'Fashion and Lifestyle Coupon Platform',\n",
       " 'Gamification Platform to train Sales People',\n",
       " 'Mobile Games Development Firm',\n",
       " 'Mobile Application for Doctor Consultation',\n",
       " 'Artificial Intelligence Platform to Raise Funds',\n",
       " 'Fresh Indian Tea Selling Platform across 112 countries',\n",
       " 'Hyperlocal Video Information Sharing Platform',\n",
       " 'Mobile App for Network of Doctors',\n",
       " 'Online Furniture Marketplace',\n",
       " 'Provides Business Insights using Drone Imaginary',\n",
       " 'Beauty Products Online Marketplace',\n",
       " 'Weather Forecast Platform',\n",
       " 'Online Courses and Mentoring from Experts',\n",
       " 'SaaS based Big Data Analytics Platform',\n",
       " 'Online Poker Platform',\n",
       " 'Vernacular and Video Content Platform',\n",
       " 'Micro finance institution providing small ticket unsecured loans to women',\n",
       " 'Regional Operating System for Smartphones',\n",
       " 'Ecommerce enabler platform',\n",
       " 'Online Gifting platform',\n",
       " 'Online Spects Platform for Men and Women',\n",
       " 'Online vehicle service booking platform',\n",
       " 'Realty Tech Startup solving real life Interior Designing problems',\n",
       " 'Business & SME Loans provider',\n",
       " 'Aadhaar-based API provider',\n",
       " 'Online Grocery Store',\n",
       " 'Online Tutorial Marketplace',\n",
       " 'Online Fantasy Games',\n",
       " 'VR based Spiritual platform',\n",
       " 'Real time data analytics & reporting',\n",
       " 'Financial Technology Research Platform',\n",
       " 'Customer Engagement Platform',\n",
       " 'Doctor Patient Communication platform',\n",
       " 'Wearable tech and Internet of Things platform',\n",
       " 'Distance Education Learning Platform',\n",
       " 'Mutual Fund Investment App',\n",
       " 'Online platform for Agricultural products',\n",
       " 'IoT based Tech Startup',\n",
       " 'Enrolment Management Platform',\n",
       " 'Saas based Corporate Travel Management Solution',\n",
       " 'Augmented Reality based Tech platform',\n",
       " 'Big Data based analytics platform',\n",
       " 'Celebrity fashion accessories and merchandise',\n",
       " 'Healthy & Nutrition based snacks online platform',\n",
       " 'AI based FinTech platform',\n",
       " 'Banking Software License Platform',\n",
       " 'Social Healthcare Enterprise',\n",
       " 'WiFi Analytics Platform',\n",
       " 'Storytelling platform',\n",
       " 'End-to-End property management for landlords living away',\n",
       " 'Placement preparation and career growth training platform',\n",
       " 'Self riding bike rental program',\n",
       " 'Bike and Taxi pooling online platform',\n",
       " 'Big Data Analytics Platform',\n",
       " 'Managed Cloud Environment Solutions',\n",
       " 'AI based pharmacy drugs insights platform',\n",
       " 'Healthcare facilities at doorstep',\n",
       " 'Vehicle loan approval platform',\n",
       " 'Tech based investor firm',\n",
       " 'Online Hotel Reservation Platform',\n",
       " 'Viral Content and storytelling platform',\n",
       " 'Venture Capitalist',\n",
       " 'IoT and SaaS based transportation platform',\n",
       " 'Diversified Financial',\n",
       " 'Identity management platform',\n",
       " 'Virtual Reality based gaming platform',\n",
       " 'Designer-led consumer products',\n",
       " 'Online Truck aggregator platform',\n",
       " 'Health and fitness based mobile App',\n",
       " 'Student accommodation platform',\n",
       " 'Home Loans Aggregation platform',\n",
       " 'Home Loan Down payment assistance program',\n",
       " 'App based cab hailing services',\n",
       " 'P2P platform for Fashion sales',\n",
       " 'Education collaboration platform',\n",
       " 'Digital Wallet',\n",
       " 'Local Recommendations and Discoveries Platform',\n",
       " 'rooftop solar platform',\n",
       " 'Ecommerce Portal for Used Goods',\n",
       " 'Mobile repair and Refurbishment platform',\n",
       " 'Fresh Produce SCM company',\n",
       " 'Self Drive car and bike rental platform',\n",
       " 'Student Micro-financing platform',\n",
       " 'Agriculture Supply Chain management solutions',\n",
       " 'Home Interior Designing Seller',\n",
       " 'Treasury Risk Management Solution',\n",
       " 'Auto Service Logistics & SAAS platform',\n",
       " 'Education Technology platform',\n",
       " 'AI-powered anti-fraud solutions',\n",
       " 'AI-powered deep learning solutions',\n",
       " 'Online Restaurant Reservation Platform',\n",
       " 'Online Reseller Network',\n",
       " 'Medical Transportation Services',\n",
       " 'Education Network for Institutions, teachers & Students',\n",
       " 'Online insurance policy aggregator',\n",
       " 'home maintenance services platform',\n",
       " 'Online Chai ordering platform',\n",
       " 'Food Ordering Portal',\n",
       " 'Online Financial Marketplace',\n",
       " 'App building platform',\n",
       " 'B2B Logistics provider',\n",
       " 'Online peer-to-peer lending platform',\n",
       " 'Mobile based learning app',\n",
       " 'Cold pressed Juice maker',\n",
       " 'app-only lending platform',\n",
       " 'Machine learning based parking discovery',\n",
       " 'Cold Chain monitoring solution',\n",
       " 'Herbal energy shot maker',\n",
       " 'SME Lending platform',\n",
       " 'Online Learning Platform',\n",
       " 'Frozen Meat provider',\n",
       " 'Real Estate content portal',\n",
       " 'Contract Automation',\n",
       " 'Online Grocery portal',\n",
       " 'B2B Finance & Fulfilment Network',\n",
       " 'Credit + payment mobile app',\n",
       " 'Payments Platform for Marketplaces and Fintechs',\n",
       " 'Agriculture Technology',\n",
       " 'Online Pharmacy',\n",
       " 'Equity Stock Exchange',\n",
       " 'Online B2B store for office supplies',\n",
       " 'Online Doctor Discovery Platform',\n",
       " 'Online Photography platform',\n",
       " 'Application Performance Acceleration',\n",
       " 'EduTech Platform',\n",
       " 'Online travel booking platform',\n",
       " 'Medical Diagnostic Solutions',\n",
       " 'Buying Club for Small Businesses',\n",
       " 'Online Credit scoring platform',\n",
       " 'Pet care portal & mobile app',\n",
       " 'Branded budget hotels marketplace',\n",
       " 'Online Unsecured Lending platform',\n",
       " 'online babycare products marketplace',\n",
       " 'Ecommerce portal for senior citizens',\n",
       " 'Agre-Tech Mobile app',\n",
       " 'Logistics Solutions provider',\n",
       " 'Healthcare Services Aggregator',\n",
       " 'Health Food etailer',\n",
       " 'Healthcare services portal',\n",
       " 'Imaging Technology for Armed Forces',\n",
       " 'Smart Parking Enabler',\n",
       " 'Content marketing platform',\n",
       " 'women focussed customer-to-customer reseller network',\n",
       " 'udget hotel marketplace',\n",
       " 'Telecom & IoT platform',\n",
       " 'Co-Working Space Provider',\n",
       " 'Virtual Reality gaming and entertainment platform',\n",
       " 'Bike Rental Platform',\n",
       " 'Online Tutoring Platform',\n",
       " 'Pregnancy & Baby Care product etailer',\n",
       " 'mobile-first communication platform for on-field staff,',\n",
       " 'Integrated receivables software solutions',\n",
       " 'Technology-Empowered Healthcare Solutions',\n",
       " 'financial services firm',\n",
       " 'E-sports platform',\n",
       " 'Co-Working Spaces',\n",
       " 'Home Furnishing & Building material marketplace',\n",
       " 'Online Travel Agency',\n",
       " 'Omni-channel web commerce solutions provider',\n",
       " 'Scooter Rental Platform',\n",
       " 'SME Marketing Management Solution',\n",
       " 'Food Delivery Platform',\n",
       " 'Crop Technology Solutions',\n",
       " 'Bike Aggregator Mobile App',\n",
       " 'Sports & Sport related equipment portal',\n",
       " 'Matchmaking app for the differently abled',\n",
       " 'Language learning Mobile App',\n",
       " 'Geospatial Technology-based SaaS solutions',\n",
       " 'O2O fashion discovery platform',\n",
       " 'Car repair and Servicing Platform',\n",
       " 'Luxury Helicopter Tourism Services portal',\n",
       " 'Local Language Health Information portal',\n",
       " 'Defense Tech & Aerospace startup',\n",
       " 'Predictive Care Platform',\n",
       " 'Digital Marketing Agency',\n",
       " 'DIY Ecommerce platform',\n",
       " 'healthcare service aggregator',\n",
       " 'On-Demand Logistics Service provider',\n",
       " 'Recruitment Portal',\n",
       " 'Tea Delivery Portal & offline stores',\n",
       " 'Health Products & Services Aggregator',\n",
       " 'Restaurant Management Solutions',\n",
       " 'Fashion Resale Marketplace',\n",
       " 'Warehouse Aggregator',\n",
       " 'Skincare Speciality services',\n",
       " 'Hospital Management Software',\n",
       " 'foreign exchange services',\n",
       " 'Mobile based Logistics Service',\n",
       " 'Agriculture Supply Chain solutions',\n",
       " 'Online milk delivery',\n",
       " 'Co-Living space aggregator',\n",
       " 'Mobile games developer',\n",
       " 'App based cab aggregation Service',\n",
       " 'Sports Content Mobile App',\n",
       " 'Personal Loans & EMI solutions platform',\n",
       " 'Unsecured Small Business Loans',\n",
       " 'Payment Solution Mobile app',\n",
       " 'Building material online store',\n",
       " 'speech recognition startup',\n",
       " 'E-Tech platform',\n",
       " 'instant messaging platform',\n",
       " 'Govt service application portal',\n",
       " 'Online Grocery platform',\n",
       " 'Cloud data protection and management solutions',\n",
       " 'Men Grooming product etailer',\n",
       " 'Operations and manpower outsourcing',\n",
       " 'Software & Mobile app development platform',\n",
       " 'mPOS solutions provider',\n",
       " 'Online printing marketplace',\n",
       " 'Restaurant & Hotel CRM platform',\n",
       " 'End to End health and wellness platform.',\n",
       " 'Healthtech IoT platform',\n",
       " 'SAAS based sales force automation services',\n",
       " 'Budget Hotel Aggregator platform',\n",
       " 'Genomics Research and Diagnostics Solutions',\n",
       " 'Peer-to-Peer Lending Platform',\n",
       " 'Energy management solutions provider',\n",
       " 'Online marketplace for automobiles',\n",
       " 'online marketplace for food and grocery',\n",
       " 'B2B marketplace for Industrial products',\n",
       " 'Hyperlocal Home Services Provider',\n",
       " 'Cloud Solutions provider',\n",
       " 'parenting blog and kids\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99 events discovery platform',\n",
       " 'Digital Media Video platform',\n",
       " 'MF investment platform',\n",
       " 'Workshop Management Software Platform',\n",
       " 'Salon & Spa Aggregation & Discovery platform',\n",
       " 'Video Content Discovery Platform',\n",
       " 'Online Interior Design platform',\n",
       " 'Digital Payments solutions',\n",
       " 'Door Step Delivery platform',\n",
       " 'Chatbot creation tool',\n",
       " 'Next Gen Mobility device manufacturer',\n",
       " 'Construction site operations and analytics platform',\n",
       " 'Designer consumer products Marketplace',\n",
       " 'Sales Solutions for Fashion Brands',\n",
       " 'Enterprise Banking Solutions',\n",
       " 'Mobile Services & Solutions',\n",
       " 'Ambulance Aggregation Services',\n",
       " 'Mobile games creator',\n",
       " 'Consumer Leasing Platform',\n",
       " 'AI powered recruitment platform',\n",
       " 'Gamified Learning App',\n",
       " 'Online payments platform',\n",
       " 'Online Marketplace for Construction Material',\n",
       " 'Women Work wear etailer',\n",
       " 'Machine Learning Access platform',\n",
       " 'Healthy Food Delivery platform',\n",
       " 'Mobile-first Enterprise communication platform',\n",
       " 'Mobile Learning App',\n",
       " 'Budget hotels brand & Aggregator Platform',\n",
       " 'Assisted Learning Startup',\n",
       " 'App-based Aggregator of Offline Businesses',\n",
       " 'Beauty Services Marketplace',\n",
       " 'online marketplace for discovering fitness centres',\n",
       " 'Mobile based travel ERP platform',\n",
       " 'Online Marketplace for Renting Bikes, Electronics & Appliances',\n",
       " 'Online Travel & Holiday Booking platform',\n",
       " 'Online Wealth Management & Savings platform',\n",
       " 'Healthcare Discovery & booking platform',\n",
       " 'Mobile Payments Platform',\n",
       " 'Mobile app for Mental Health',\n",
       " 'Education Marketplace',\n",
       " 'For profit Social Venture',\n",
       " 'health and fitness discovery platform',\n",
       " 'Health coaching programs',\n",
       " 'CRM Software for Healthcare space',\n",
       " 'Unified Digital Health Platform',\n",
       " 'App-based Investment advisory Services',\n",
       " 'Travel & adventure planning platform',\n",
       " 'ambulance aggregator and medical taxi provider',\n",
       " 'Hygiene care product manufacturer',\n",
       " 'Online rooms aggregation platform',\n",
       " 'Online insurance brokerage platform',\n",
       " 'Location tracking solutions',\n",
       " 'CSR and sustainability management platform',\n",
       " 'Tech driven Insurance platform',\n",
       " 'Cab Aggregation App',\n",
       " 'Beauty products discovery platform',\n",
       " 'Micro Food Delivery platform',\n",
       " 'Money Lending platform',\n",
       " 'Mobile SAAS\\\\\\\\xc2\\\\\\\\xa0 ECommerce platform for SMEs',\n",
       " 'Personal Finance platform',\n",
       " 'Maritime Solutions',\n",
       " 'DIY project Kits seller',\n",
       " 'Cloud-based product discovery platform',\n",
       " 'Enterprise human resources management platform',\n",
       " 'Mobile based ecommerce platform',\n",
       " 'Events Ticketing platform',\n",
       " 'Health-Tech platform',\n",
       " 'Artificial Intelligence based platform',\n",
       " 'Point-of-Sale services',\n",
       " 'Credit card fraud protection',\n",
       " 'Open Source Language for Data Science and Machine Learning',\n",
       " 'Consumer Lending Platform',\n",
       " 'Local homes booking platform',\n",
       " 'Lending platform for Salaried professionals',\n",
       " 'Mobile based social networking platform',\n",
       " 'Gesture based\\\\\\\\xc2\\\\\\\\xa0 Smartwatch manufacturer',\n",
       " 'Holiday & Vacation resort aggregator',\n",
       " 'Personal Finance App',\n",
       " 'Unified Data Analysis platform',\n",
       " 'Automobile parts marketplace',\n",
       " 'Fitness Centre Discovery Platform',\n",
       " 'Online Marketplace for financial products',\n",
       " 'AI Based Personal Assistant',\n",
       " 'Online Fitness Marketplace',\n",
       " 'digital employee solutions,',\n",
       " 'in-video discovery platform',\n",
       " 'Mobile Services Marketplace',\n",
       " 'Online Rummy playing Website',\n",
       " 'Buying portal for SMEs',\n",
       " 'Enterprise Mobility Solutions',\n",
       " 'Truck Network company',\n",
       " 'Online Platform for small business loans',\n",
       " 'Real estate risk assessment platform',\n",
       " 'Software & Mobile development services',\n",
       " 'Online Diagnostics and wellness platform',\n",
       " 'AI-based health content platform',\n",
       " 'Health-based social networking & discovery App',\n",
       " 'Cloud Based Practice Management Software',\n",
       " 'Money Savings & Management App',\n",
       " 'Private Label Fashion etailer',\n",
       " 'Last minute hotel booking mobile app',\n",
       " 'Restaurant Automation Solution',\n",
       " 'Cold-press Juices manufacturer',\n",
       " 'Omni-Channel Platform',\n",
       " 'Energy Analytics startup',\n",
       " 'Computer Vision on Embedded Systems',\n",
       " 'Ecommerce Fulfilment and Technology Platform',\n",
       " 'IT Security & Data Management Services',\n",
       " 'Cyber Security Startup',\n",
       " 'Video Intelligence platform',\n",
       " 'Community Building platform',\n",
       " 'Advertising Platform for Virtual Reality',\n",
       " 'Diamond B2B eTailer',\n",
       " 'Clean Tech Startup',\n",
       " 'Legal Services to SMEs & Individuals',\n",
       " 'NanoTech product developer',\n",
       " 'Digital money transfer platform',\n",
       " 'Cloud ECommerce platform',\n",
       " 'Project Management tool',\n",
       " 'Multi-lingual AI Platform for Businesses',\n",
       " 'AI-based chatbot',\n",
       " 'Online Payment Gateway',\n",
       " 'Fashion ECommerce Portal',\n",
       " 'hyperlocal delivery and logistics mobile app',\n",
       " 'Online Luxury Tea etailer',\n",
       " 'Online Water Pumps etailer',\n",
       " 'Mobile Wallet & ECommerce platform',\n",
       " 'Health Food Maker',\n",
       " 'Private Fashion Brand etailer',\n",
       " 'ECommerce Logistics provider',\n",
       " 'Cashless, paperless solutions for Housing societies',\n",
       " 'Travel ECommerce portal',\n",
       " 'Hyperlocal discovery platform',\n",
       " 'Online Tutoring Services',\n",
       " 'Online Lending mobile app',\n",
       " 'Finance management Mobile app',\n",
       " 'Online MF investment platform',\n",
       " 'image Processing solution',\n",
       " 'Online Medical equipment supplier',\n",
       " 'Express Logistics Network',\n",
       " 'Subscription based delivery platform',\n",
       " 'Hyperlocal Discovery\\\\\\\\xc2\\\\\\\\xa0 & Rewards platform',\n",
       " 'Online & Mobile based Lending platform',\n",
       " 'Executive Education Provider',\n",
       " 'Online Test Preparation Platform',\n",
       " 'Home Healthcare Provider',\n",
       " 'Enterprise IoT solutions For Tyre Performance',\n",
       " 'Fresh-Produce Distribution Platform',\n",
       " 'Fin-Tech Solutions',\n",
       " 'Interactive Tech-Support Guides',\n",
       " 'App based Logistics & Distribution platform',\n",
       " 'Online Truck Aggregator & Booking platform',\n",
       " 'App based Doctor Consulting platform',\n",
       " 'Credit Score Improvement platform',\n",
       " 'Business Intelligence Solutions',\n",
       " 'Home-Based Healthcare provider',\n",
       " 'Mobile gaming startup',\n",
       " 'Startup Support Platform',\n",
       " 'Online Healthcare provider',\n",
       " 'Smart Scooter manufacturer',\n",
       " 'Online marketplace for kitchen products',\n",
       " 'Online rental discovery platform',\n",
       " 'SaaS platform for SMEs',\n",
       " 'B2B agri-marketing platform',\n",
       " 'Software solutions for M&As',\n",
       " 'Online Sports portal & Mobile app',\n",
       " 'Online lingerie & Sleepwear etailer',\n",
       " 'Third Party Logistics provider',\n",
       " 'Online Skill Assessment Platform',\n",
       " 'Online Travel planner',\n",
       " 'Safety & Hygiene Products etailer',\n",
       " 'Travel Packages & Planner marketplace',\n",
       " 'Cab Aggregator App',\n",
       " 'Mobile App for Schools',\n",
       " 'Online Medical Assistance platform',\n",
       " 'Health Technology platform',\n",
       " 'Raw Pressed Juices manufacturer',\n",
       " 'Healthy Snacks manufacturer',\n",
       " 'Online Salon discovery & Booking Services',\n",
       " 'eLearning & Skills Development plat',\n",
       " 'Lending platform for small businesses',\n",
       " 'Cyber Security solutions using AI',\n",
       " 'Markerless AR platform',\n",
       " 'Virtual Reality Startup',\n",
       " 'IoT Platform for Bus',\n",
       " 'Social Commerce\\\\\\\\xc2\\\\\\\\xa0 Fashion platform',\n",
       " 'Video Based Collaborative Learning',\n",
       " 'QSR chain and online food delivery',\n",
       " 'Branded Budget Hotels Aggregator',\n",
       " 'Learning mobile app for students',\n",
       " 'Breast Cancer Screening Solutions',\n",
       " 'CoWorking Spaces booking platform',\n",
       " 'Collaborative co-Working Spaces',\n",
       " 'Customer data analytics software',\n",
       " 'Public and Private Events creation app',\n",
       " 'Online fashion marketplace',\n",
       " 'Bus Pooling services platform',\n",
       " 'On-Demand Food Delivery',\n",
       " 'Software Solutions for Auto Dealership',\n",
       " 'Education Institution Management Solutions',\n",
       " 'Online Educational courses',\n",
       " 'Healthcare related content platform',\n",
       " 'Financial advisory mobile app',\n",
       " 'Tutor Discovery & Booking platform',\n",
       " 'App based cab aggregator',\n",
       " 'Online Jon Portal',\n",
       " 'AI based Fashion Search Portal',\n",
       " 'Fresh Produce Selling portal',\n",
       " 'Women Healthcare & Information portal',\n",
       " 'Packaging Artwork Management software',\n",
       " 'End-to-End Seller e-commerce solutions Provider',\n",
       " 'Online Credit score & lending platform',\n",
       " 'Online Ecosystem of social innovators',\n",
       " 'Employee Onboarding and Engagement platform',\n",
       " 'Professional Tutors discovery & booking mobile app',\n",
       " 'eCommerce Mobile App Builder',\n",
       " 'Mobile App for live emoji',\n",
       " 'eCommerce\\xa0Marketplace',\n",
       " 'Health Diagnostic Solutions',\n",
       " 'Online Counseling Platform',\n",
       " 'Fashion and Lifestyle discovery platform',\n",
       " 'Gadget Insurance & Repair Services platform',\n",
       " 'Direct-to-Farmer Mobile-Based Retail platform',\n",
       " 'DSP, TV Analytics & Cross-Platform advertising',\n",
       " 'Cyber Security Solutions',\n",
       " 'Online Vehicle Services Booking platform',\n",
       " 'Intra-City Logistics provider',\n",
       " 'Technology Enabled Logistics Company',\n",
       " 'Intelligent Sales Prospecting Platform',\n",
       " 'Subscription based Home Delivery Platform',\n",
       " 'Online Community for Parents',\n",
       " 'Instant Mobile Apps Store',\n",
       " 'Online Real Estate Portal',\n",
       " 'Female Hygiene product manufacturer',\n",
       " 'Online fresh fruits and grocery store',\n",
       " 'SDN Solutions',\n",
       " 'Fractional Proerty Ownership & Rental platform',\n",
       " 'Online Dermatology consultation platform',\n",
       " 'Tech Accessories e-tailer',\n",
       " 'On-demand home services provider',\n",
       " 'Loyalty rewards app',\n",
       " 'Virtual Reality platform',\n",
       " 'Digital Media publication for women',\n",
       " 'Fitness Mobile App',\n",
       " 'Farming rental equipment provider',\n",
       " 'On-Demand Beauty Services',\n",
       " 'Pregnancy & Baby Care etailer',\n",
       " 'Tech-Enabled Social Enterprise',\n",
       " 'Online Travel Search Engine',\n",
       " 'Marketing Research Company',\n",
       " 'supply chain automation platform',\n",
       " 'Parenting Mobile App',\n",
       " 'Tech enabled Fulfilment & Logistics Solutions',\n",
       " 'Sports Based Online Media portal',\n",
       " 'Enterprise Automation suite',\n",
       " 'On-demand Personal Assistant service',\n",
       " 'Luxury Fashion Marketplace',\n",
       " 'Vacation Trip Planning platform',\n",
       " 'Self-Checkout ECommerce App',\n",
       " 'Online Meat Ordering platform',\n",
       " 'Doctor & Hospital search Platform',\n",
       " 'Mobile OS creator',\n",
       " 'Electric Motorcycle Manufacturer',\n",
       " 'Pathology & Diagnostic Tests Portal',\n",
       " 'Offline Business Aggregator App',\n",
       " 'Turnkey Solar Solutions',\n",
       " 'Sports engagement platform',\n",
       " 'Real-Estate Workflow mobile app',\n",
       " 'ERP solutions provider',\n",
       " 'Intelligent Sales Assistant',\n",
       " 'Curated Platform for Developers',\n",
       " 'Hotel Management Solution',\n",
       " 'Online travel agent marketplace',\n",
       " 'Online Travel, Adventure & Activities Portal',\n",
       " 'IoT Based Energy Monitoring & Control',\n",
       " 'Automobile Classifieds Portal',\n",
       " 'Car Rental Software Solutions',\n",
       " 'Online Education Portal',\n",
       " 'Women Apparel & Lifestyle etailer',\n",
       " 'Startup Crowd-funding platform',\n",
       " 'Women Fashion Portal',\n",
       " 'Tech Enabler for Artists',\n",
       " 'Medical Automation platform',\n",
       " 'Decision Sciences Analytics Solutions',\n",
       " 'On Demand Laundry & Dry Cleaning Services',\n",
       " 'Mortgage Offering Platform',\n",
       " 'Expense Management Solution',\n",
       " 'Online Bike & Car Services provider',\n",
       " 'Data Analytics platform',\n",
       " 'Co-Working Space Platform',\n",
       " 'Drone operations management platform',\n",
       " 'Online Marketplace for Used Cars',\n",
       " 'Online Media',\n",
       " 'AR & VR platform',\n",
       " 'Online Media Platform',\n",
       " 'Online match-making app',\n",
       " 'DIY event registration and ticketing portal',\n",
       " 'Solution provider for pet needs',\n",
       " 'First Aid care app',\n",
       " 'Photo Sharing for Groups',\n",
       " 'Smart Parking Platform',\n",
       " 'B2B Mobile App for Pharmacies',\n",
       " 'Mobile Advertising App',\n",
       " 'Co-Living Spaces Aggregator',\n",
       " 'Online Food Ordering & Delivery Portal',\n",
       " 'Online Jewellery etailer',\n",
       " 'Live Online Coaching Classes',\n",
       " 'Online freight aggregator',\n",
       " 'Online Tax Filing Platform',\n",
       " 'IoT & SAAS Solutions for Transportation Industry',\n",
       " 'Online/App Based Car cleaning service provider',\n",
       " 'Blended Learning Delivery App for Schools & Corporates',\n",
       " 'Dentist Appointments booking platform',\n",
       " 'Healthcare Technology Solutions',\n",
       " 'Supply Chain Solutions Provider',\n",
       " 'Movie Ticket Booking platform',\n",
       " 'SAAS Based Retail Analytics Solutions',\n",
       " 'e-surveillance services provider',\n",
       " 'Small Business Loans Marketplace platform',\n",
       " 'online marketplace for driving schools',\n",
       " 'Doctor & Clinic Discovery portal',\n",
       " 'Real-time Mobile App Management Platform',\n",
       " 'Property Search Aggregator platform',\n",
       " 'IoT smart Logistics and Asset Management Company',\n",
       " 'Cashback & Coupons platform',\n",
       " 'Gadgets Repair & Service Booking platform',\n",
       " 'Cloud-based solutions provider',\n",
       " 'Personality Development Mobile App',\n",
       " 'Branded PG Accomodation booking platform',\n",
       " 'SAAS Based Media Marketing platform',\n",
       " 'Custom & Modular Furniture platform',\n",
       " 'Parenting Info & Social Network',\n",
       " 'Online Healthcare platform',\n",
       " 'Food Discovery Platform',\n",
       " 'Online Car Service Platform',\n",
       " 'Logistics and truck aggregator platform',\n",
       " 'Cyber Security Solution provider',\n",
       " 'B2B Marketplace for Handicrafts',\n",
       " 'Online Tea Etailer',\n",
       " 'Cloud-based construction',\n",
       " 'Parking Solutions mobile app',\n",
       " 'Online Marketplace for Wedding Venues and vendors',\n",
       " 'Indian Sweets & Snacks etailer',\n",
       " 'Visual and Interactive communications Solutions',\n",
       " 'B2B Wholesale Marketplace in India',\n",
       " 'IoT platform for Tyre Performance management & tracking',\n",
       " 'social messaging platform',\n",
       " 'Audit automation Solutions',\n",
       " 'Border Intrusion Alert Solutions',\n",
       " 'Maths Learning program',\n",
       " 'Online Job Portal',\n",
       " 'Mobile-based Social Platform for Sports',\n",
       " 'Platform to take businesses online',\n",
       " 'Online transport vehicle booking platform',\n",
       " 'ECommerce Marketing Software',\n",
       " 'Crowdfunding Platform',\n",
       " 'Agri Decision Support Solution for farmers',\n",
       " 'Loyalty program management solutions',\n",
       " 'Security-as-a-Service solution provider',\n",
       " 'Mobile Game Developer Studio',\n",
       " 'Health Tests Booking platform & ePharmacy',\n",
       " 'Hyper-local Handyman Service provider',\n",
       " 'English Online News portal',\n",
       " 'IoT solutions for home automation applications',\n",
       " 'Cloud based Virtual Servers',\n",
       " 'Used Furniture Marketplace',\n",
       " 'Smart Online address tags',\n",
       " 'Online Pet Products Store',\n",
       " 'Online Marriage Registration services',\n",
       " 'Healthcare Software System',\n",
       " 'Online Instant personal Loan provider',\n",
       " 'Lock screen Rewards mobile app',\n",
       " 'Entry-Level job Seekers platform',\n",
       " 'Live Music Streaming App',\n",
       " 'Transport and logistics mobile App',\n",
       " 'On-demand, self-drive bike rental platform',\n",
       " 'Mobile Contacts Management app',\n",
       " 'Clinical research and data analytics',\n",
       " 'Mobile App based Fashion Network',\n",
       " 'Mobile-only Retailers Engagement Solution',\n",
       " 'Venue, Events Booking platform',\n",
       " 'Pet Parenting mobile app',\n",
       " 'Self-Driven Car Services booking portal',\n",
       " 'Online Investment Advisory platform',\n",
       " 'Connected Transportation solutions',\n",
       " 'Online Car servicing Booking platform',\n",
       " 'Fashion Apparel eTailer',\n",
       " 'Beauty Products Retailer',\n",
       " 'Content Management & Productivity platform',\n",
       " 'Education & learning Tech platform',\n",
       " 'Online Doctor Consulting platform',\n",
       " 'Self-Branded Websites & Apps for Ecommerce',\n",
       " 'Cold Press Juice manufacturer & seller',\n",
       " 'Marketplace for International Freight',\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subvertical'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0dfaec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subvertical']=df['subvertical'].apply(lambda x:str(x).replace('\\\\\\\\xc2\\\\\\\\xa0',''))\n",
    "df['subvertical']=df['subvertical'].apply(lambda x:str(x).replace('\"Women\\\\\\\\\\'s Fashion Clothing Online Platform\"','Women Fashion Clothing Online Platform'))\n",
    "df['subvertical']=df['subvertical'].apply(lambda x:str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99',''))\n",
    "df['subvertical']=df['subvertical'].apply(lambda x:str(x).replace('\\xa0',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7d73bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  E-learning\n",
       "1                   App based shuttle service\n",
       "2       Retailer of baby and toddler products\n",
       "3                           Online Investment\n",
       "4                 Embroiled Clothes For Women\n",
       "                        ...                  \n",
       "3039                                        0\n",
       "3040                                        0\n",
       "3041                                        0\n",
       "3042                                        0\n",
       "3043                                        0\n",
       "Name: subvertical, Length: 3044, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subvertical']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5248ebf3",
   "metadata": {},
   "source": [
    "# location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af1ae199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bengaluru',\n",
       " 'Gurgaon',\n",
       " 'New Delhi',\n",
       " 'Mumbai',\n",
       " 'Chennai',\n",
       " 'Pune',\n",
       " 'Noida',\n",
       " 'Faridabad',\n",
       " 'San Francisco',\n",
       " 'San Jose,',\n",
       " 'Amritsar',\n",
       " 'Delhi',\n",
       " 'Kormangala',\n",
       " 'Tulangan',\n",
       " 'Hyderabad',\n",
       " 'Burnsville',\n",
       " 'Menlo Park',\n",
       " 'Gurugram',\n",
       " 'Palo Alto',\n",
       " 'Santa Monica',\n",
       " 'Singapore',\n",
       " 'Taramani',\n",
       " 'Andheri',\n",
       " 'Chembur',\n",
       " 'Nairobi',\n",
       " 'Haryana',\n",
       " 'New York',\n",
       " 'Karnataka',\n",
       " 'Mumbai/Bengaluru',\n",
       " 'Bhopal',\n",
       " 'Bengaluru and Gurugram',\n",
       " 'India/Singapore',\n",
       " 'Jaipur',\n",
       " 'India/US',\n",
       " 'Nagpur',\n",
       " 'Indore',\n",
       " 'New York, Bengaluru',\n",
       " 'California',\n",
       " 'India',\n",
       " 'Ahemadabad',\n",
       " 'Rourkela',\n",
       " 'Srinagar',\n",
       " 'Bhubaneswar',\n",
       " 'Chandigarh',\n",
       " 'Delhi & Cambridge',\n",
       " 'Kolkata',\n",
       " 'Coimbatore',\n",
       " 'Bangalore',\n",
       " 'Udaipur',\n",
       " 0,\n",
       " 'Ahemdabad',\n",
       " 'Ahmedabad',\n",
       " 'Surat',\n",
       " 'Goa',\n",
       " 'Uttar Pradesh',\n",
       " 'Gaya',\n",
       " 'Vadodara',\n",
       " 'Trivandrum',\n",
       " 'Missourie',\n",
       " 'Panaji',\n",
       " 'Gwalior',\n",
       " 'Karur',\n",
       " 'Udupi',\n",
       " 'Kochi',\n",
       " 'Agra',\n",
       " 'Bangalore/ Bangkok',\n",
       " 'Hubli',\n",
       " 'Kerala',\n",
       " 'Kozhikode',\n",
       " 'US',\n",
       " 'Siliguri',\n",
       " 'USA',\n",
       " 'Lucknow',\n",
       " 'Kanpur',\n",
       " 'Bangalore / SFO',\n",
       " 'London',\n",
       " 'Seattle / Bangalore',\n",
       " 'Pune/Seattle',\n",
       " 'Pune / Dubai',\n",
       " 'Varanasi',\n",
       " 'New Delhi / US',\n",
       " 'Mumbai / UK',\n",
       " 'Jodhpur',\n",
       " 'Hyderabad/USA',\n",
       " 'Boston',\n",
       " 'Bangalore / Palo Alto',\n",
       " 'Mumbai / NY',\n",
       " 'USA/India',\n",
       " 'Goa/Hyderabad',\n",
       " 'Noida / Singapore',\n",
       " 'Belgaum',\n",
       " 'Pune / US',\n",
       " 'Chennai/ Singapore',\n",
       " 'Pune / Singapore',\n",
       " 'Bangalore / San Mateo',\n",
       " 'New York/ India',\n",
       " 'US/India',\n",
       " 'Gurgaon / SFO',\n",
       " 'Bangalore / USA',\n",
       " 'New Delhi/ Houston',\n",
       " 'Mumbai / Global',\n",
       " 'India / US',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Noida',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Bangalore',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Gurgaon',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0New Delhi',\n",
       " '\\\\\\\\xc2\\\\\\\\xa0Mumbai',\n",
       " 'New Delhi / California',\n",
       " 'Dallas / Hyderabad']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f5f9ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location']=df['location'].apply(lambda x:str(x).replace('\\\\\\\\xc2\\\\\\\\xa0',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04ee22a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Bengaluru\n",
       "1         Gurgaon\n",
       "2       Bengaluru\n",
       "3       New Delhi\n",
       "4          Mumbai\n",
       "          ...    \n",
       "3039            0\n",
       "3040            0\n",
       "3041            0\n",
       "3042            0\n",
       "3043            0\n",
       "Name: location, Length: 3044, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1e4e4",
   "metadata": {},
   "source": [
    "# investors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e3303a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tiger Global Management',\n",
       " 'Susquehanna Growth Equity',\n",
       " 'Sequoia Capital',\n",
       " 'Vinod Khatumal',\n",
       " 'Sprout Venture Partners',\n",
       " 'Chiratae Ventures',\n",
       " 'Ant Financial',\n",
       " 'Sathguru Catalyzer Advisors',\n",
       " 'Ping An Global Voyager Fund',\n",
       " 'Mumbai Angels, Ravikanth Reddy',\n",
       " 'SAIF Partners, Spring Canter Investment Ltd.',\n",
       " 'Paytm, NPTK, Sabre Partners and Neoplux',\n",
       " 'Vertex Growth Fund',\n",
       " 0,\n",
       " 'Ruizheng Investment',\n",
       " 'Manipal Education and Medical Group (MEMG)',\n",
       " 'SoftBank Vision Fund',\n",
       " 'Sequoia, CapitalG, Accel',\n",
       " 'Sauce.vc, Rainforest Ventures',\n",
       " 'Prime Venture Partners, LetsVenture, PS1 Venture and GlobalLogic co-founder Rajul Garg',\n",
       " 'RB Investments',\n",
       " 'DG Daiwa Ventures, DG Incubation',\n",
       " 'Trifecta Capital Advisors',\n",
       " 'FinTech',\n",
       " 'Dream Incubator',\n",
       " 'Altimeter Capital, Sutter Hill Ventures',\n",
       " 'Startup Buddy',\n",
       " 'Amour Infrastructure',\n",
       " 'Ackermans & van Haaren, HealthQuad, Rebright Partners, Toppan Printing',\n",
       " 'Matrix Partners, Stellaris Venture Partners, Kalaari Capital',\n",
       " 'IAN Fund and DSG Consumer Partners',\n",
       " 'Vijay Shekhar Sharma',\n",
       " 'Lightbox',\n",
       " 'Altimeter Capital, DST Global',\n",
       " 'Ayushmann Khurana',\n",
       " 'Matrix Partners India, Sequoia India',\n",
       " 'SAIF Partners',\n",
       " 'TIW Private Equity',\n",
       " 'Exfinity Venture Partners',\n",
       " 'Breakthrough Energy Ventures',\n",
       " 'Endiya Partners',\n",
       " 'A91 Partners',\n",
       " 'Bennett Coleman and Company Ltd (BCCL)',\n",
       " 'India Quotient, Axilor Ventures',\n",
       " 'SC GG India Mobility Holdings LLC',\n",
       " 'Sequoia India',\n",
       " 'Azim Premji, Binny Bansal',\n",
       " 'Pine Labs Pte Ltd',\n",
       " 'Naspers',\n",
       " 'MS Dhoni',\n",
       " 'March Capital Partners',\n",
       " 'XL Innovate',\n",
       " 'Rashmi Daga (founder, FreshMenu), Raveen Sastry (co-founder, Myntra) and Mitesh Shah (finance chief, BookMyShow)',\n",
       " 'RPS Ventures',\n",
       " 'One97 Communications Ltd.',\n",
       " 'Growth DNA',\n",
       " 'Vir Sanghvi',\n",
       " 'WestBridge Capital',\n",
       " 'Lok Capital, IIFL Wealth',\n",
       " 'WaterBridge Ventures',\n",
       " 'Kapil Dev',\n",
       " 'DIG Investment Ab, Deshe Holdings, Samih Toukan and Hussam Khoury',\n",
       " 'Artha Venture',\n",
       " 'Qatar Investment Authority',\n",
       " 'Composite Capital Management, Sequoia Capital India, Tiger Global Management',\n",
       " 'Undisclosed',\n",
       " 'Ventureast',\n",
       " 'Blume Ventures',\n",
       " 'Binny Bansal',\n",
       " 'Multiple Angel Investors',\n",
       " 'General Atlantic',\n",
       " 'Anicut Capital',\n",
       " 'Goldman Sachs, Accel Partners and Qualcomm',\n",
       " 'Matrix Partners',\n",
       " 'Insight Partners',\n",
       " 'Triton Investment Advisors, Pidilite Industries director Ajay Parekh',\n",
       " 'Blume Ventures and RTP Global',\n",
       " 'Shell Foundation, DILA CAPITAL, Engie RDE Fund, EcoEnterprise Fund, EDFIMC (ElectriFI), Endeavor Catalyst Fund, CoCapital, Triodos, Alpha Mundi, and Lendahand',\n",
       " 'IAN Fund',\n",
       " 'Qiming Venture Partners',\n",
       " 'Nexus Venture Partners',\n",
       " 'Alteria Capital',\n",
       " 'Mumbai Angels',\n",
       " 'Tata Sons',\n",
       " 'C4D Partners',\n",
       " 'Indian Angel Network and other angel investors, Innov8 founder Ritesh Malik, Josh Talks founders Supriya Paul and Shobha Banga, and former Hero Corporate president Rohit Chanana',\n",
       " 'Goldman Sachs Investment Partners and Silicon Valley-based Accel, Wellington, Sequoia Capital, B Capital, LightStreet, Sands Capital and International Finance Corporation,',\n",
       " 'Sachin Bansal',\n",
       " 'Equanimity Venture Fund',\n",
       " 'Korea Investment Partners, Vertex Ventures',\n",
       " 'Sixth Sense Ventures',\n",
       " 'Eight Roads',\n",
       " 'Prasid Uno Family Trust',\n",
       " 'Unilever, Beehive Capital Advisor, ABCOM Investments, Parekh Marine Transport,',\n",
       " 'Orchid India, Hornbill Orchid India Fund, Chiratae Ventures (formerly IDG Ventures), 3one4 Capital, Lasmer NV',\n",
       " 'Unnamed angel investors',\n",
       " 'Lightspeed India Partners',\n",
       " 'Milestone',\n",
       " 'Supera Pte Ltd',\n",
       " 'Kalyan Krishnamurthy',\n",
       " 'Sequoia India, Tiger Global Management, Accel Partners',\n",
       " 'BAC Acquisitions, Unifi AIF, BRD Securities, Northern R Capital',\n",
       " 'New Atlantic Ventures',\n",
       " '021 Capita, Binny Bansal',\n",
       " 'India Quotient and LetsVenture\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s Angel Fund',\n",
       " 'Sequoia Capital and Temasek Holdings, EDBI, Burda Principal Investments, and Sofina',\n",
       " 'LetsVenture, PitchRight Venture, 91SpringBoard, AL Nour International Holdings and Mark V Investments',\n",
       " 'DiDi Chuxing',\n",
       " 'Sequoia India, Hillhouse Capital, Alphabet\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s growth investment arm Capital G and Axis Bank',\n",
       " 'Iron Pillar, Perceptive Advisors, Romulus Capital and Kalaari Capital',\n",
       " 'MASSIF, a Dutch government fund',\n",
       " 'Stellaris Venture Partners',\n",
       " 'Steadview Capital and Vy Capital.',\n",
       " 'Individual Investors',\n",
       " 'Omphalos Ventures India LLP',\n",
       " 'Info Edge, AET Fund, Akatsuki and Incubate Fund from Japan and Better Capital AngelList syndicate.',\n",
       " 'Venture Highway, GREE Ventures, Space Matrix, Individual Investors',\n",
       " 'Lead Angel Network',\n",
       " 'Norwest Venture Partners, CDC Group, the UK\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s Development Finance Institution and P Surendra Pai',\n",
       " 'Shunwei Capital, DST Partners and RPS Ventures',\n",
       " 'RB Investments, Singapore',\n",
       " 'Tiger Global',\n",
       " 'Mayfield Fund',\n",
       " 'Stevens Creek Ventures',\n",
       " 'Venture Catalysts',\n",
       " 'Sistema Asia Fund, VC Samsung NEXT, Chiratae Ventures, Inventus Capital, Blume Ventures and Innoven Capital.',\n",
       " 'Teachers Insurance and Annuity Association (TIAA)',\n",
       " 'Stellaris Venture Partners and Kalaari Capital, Rajan Anandan from Google, Dilip Khandwelwal from SAP Labs India, and Amrish Rau from PayU India',\n",
       " 'Lakestar and Jungle Ventures, Softbank\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s DeepCore.',\n",
       " 'Paragon Partners, Individual Investors',\n",
       " 'Bertelsmann India Investments',\n",
       " 'Prashant Jaiswal',\n",
       " 'Cooperative Oikocredit, Caspian and Hivos-Triodos Fund',\n",
       " 'Ravi Viswanathan',\n",
       " 'ZigExN',\n",
       " 'Credence Family Office',\n",
       " 'Fosun International',\n",
       " 'Sistema Asia Fund, Sistema JSFC and Tanncam Investment',\n",
       " 'DST Global and Lightspeed Venture Partners\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99 global fund.',\n",
       " 'Falcon Edge',\n",
       " 'Korea Investment Partners (KIP), Samsung and China-based CITIC Capital and others',\n",
       " 'Lighthouse',\n",
       " 'KDDI\\\\\\\\xc2\\\\\\\\xa0',\n",
       " 'Tencent, Kalaari Capital and Private equity firm Multiples Alternate Asset Management',\n",
       " 'Stellaris Ventures & Others',\n",
       " 'CLP Holdings Group, Innogy, \\\\\\\\xc3\\\\\\\\x98rstead, and Tenaska',\n",
       " 'InnoVen Capital',\n",
       " 'Shunwei Capital,Quotient, Mayfield & Others',\n",
       " 'Vertex Ventures Southeast Asia (SEA) and India and Sistema Asia Fund, Fosun RZ Capital, Ventureast, and Endiya Partners.\\\\\\\\n\\\\\\\\n',\n",
       " 'Farm To Fork, Arts Alliance, The Syndicate Fund, Sven Hensen, Zeroth and Artesian Venture Partners',\n",
       " 'Axilor, Sprout Venture Partners and others',\n",
       " 'Xiaomi and Sequoia Capital India',\n",
       " 'Y Combinator',\n",
       " 'Fung Strategic Holdings',\n",
       " 'MakeMyTrip Limited',\n",
       " 'Vertex Ventures',\n",
       " 'Sequoia Capital India Advisors, Accel Partners and G Raghunandan',\n",
       " 'Flipkart',\n",
       " 'Nexus Venture Partners, Prime Venture Partners and Others',\n",
       " 'AJ Ventures and Jain International Trade Organisation (JITO)',\n",
       " 'Ventureast, Orios Venture Partners and the IAN Fund',\n",
       " 'Nexus Venture Partners, MGV, Liquid 2 Ventures, Hack VC, Emergent Ventures and Y Combinator',\n",
       " 'Denlow Investment Trust and Beenext',\n",
       " 'CDC Group Plc',\n",
       " 'Hyundai, Edelweiss and Beenext, Dream Incubator, Sunjay Kapoor and Telama Investment',\n",
       " 'Xiaomi,PayU, Ribbit Capital and Omidyar Network',\n",
       " 'Saama Capital, SRI Capital, Beenext, and Pravega Ventures',\n",
       " 'Nexus Venture Partners, Omidyar Network and Shunwei Capital',\n",
       " 'Accel (formerly known as Accel Partners)',\n",
       " 'Ajay Relan and Vinay Mittal',\n",
       " 'MDI Ventures & Telkom Indonesia',\n",
       " 'Shunwei Capital, Tuscan Ventures, Ashish Goenka, VC firms India Quotient and Kae Capital',\n",
       " 'Info Edge (India) Ltd and Temasek',\n",
       " 'Info Edge (India) Ltd',\n",
       " 'Insignia Ventures Partners, Lightbridge Partners & Kairos',\n",
       " 'Avtar Monga, chief operating office at IDFC Bank, Aditya Malik & Others',\n",
       " 'ResponsAbility',\n",
       " 'Stellaris Venture Partners, Vy Capital, Raghunandan G, and Ramakant Sharma',\n",
       " 'Base of Pyramid Asia (BOPA) Pte Ltd',\n",
       " 'Rishi Vasudev, Excelsior Investments, Ritesh Vohra, Praveer Kumar, Prashant Gupta and Others',\n",
       " 'Brand Capital and Others',\n",
       " 'Siddharth Agarwal, Mahavir Sharma, Amit Singal, 100 Co-founders Lab and others.',\n",
       " 'Creation Investments, Falcon Edge, Matrix Partners India and Zodius Capital',\n",
       " 'Kingsway FCI Fund, KCK Global & Others',\n",
       " 'Omidyar Network & Others',\n",
       " 'TPG Growth, The Rise Fund & Others',\n",
       " 'PayU & Others',\n",
       " 'AngelList, Rahul Khanna, Rajeev Arora and Ram Ramsundar.',\n",
       " 'Metaform Ventures, Hemant Luthra, Micro venture capital firm GEMS Partners and Others',\n",
       " 'Gray Matters',\n",
       " 'Fairfax',\n",
       " 'Allcargo Logistics, Navneet Education and Mahavir Agency',\n",
       " 'BeeNext , WEH Ventures and Sprout Ventures',\n",
       " 'Ventureast and Exfinity',\n",
       " 'Bharat Innovation, IDFC-Parampara Capital, Arthavida Ventures, Jitendra Gupta & Others',\n",
       " 'MakeMyTrip',\n",
       " 'Lindwall Family Investments LLC (LFI)',\n",
       " 'Amazon Alexa Fund & Dentsu Ventures',\n",
       " 'IDG Ventures, Accel Partners, Kalaari Capital and Others',\n",
       " 'TPG, Norwest Venture Partners, Sequoia Capital & Matrix Partners',\n",
       " 'Kantilal Patel',\n",
       " 'Sabre Partners, Puneet Dalmia & Others',\n",
       " 'Aspire Logistics LLC',\n",
       " 'Bhairavi Jani, Alok Divatia, Namrata Kaul, Sohail Hashemi, Aijaz Saleem',\n",
       " 'Anil Advani, Pramod Jain, Amrendra Reddy and Manish Satnaliwala.',\n",
       " 'NB Ventures and Others',\n",
       " 'Oman India Joint Investment Fund (OIJIF)',\n",
       " 'Sequoia Capital India, SAIF Partners, Y Combinator and Venture Highway',\n",
       " 'CapitalG, SAIF Partners and LGT Impact Ventures',\n",
       " 'Mumbai Angels Network',\n",
       " 'Alpha Capital',\n",
       " 'Paragon Partners',\n",
       " 'Saama Capital and Sequoia Capital',\n",
       " 'Spiral Ventures, Subho Ray and Samir Kumar',\n",
       " 'LetsVenture, Rajan Anandan, Basab Pradhan, Vivek Khare and Bijoy George',\n",
       " 'Rannvijay Singha',\n",
       " 'Brand Capital',\n",
       " 'Helix Investments',\n",
       " 'Lighthouse Funds & Thuasne Participations',\n",
       " 'Hyperplane Venture Capital and several angel investors',\n",
       " 'Menterra Venture & Artha Initiatives',\n",
       " 'Shorooq Investments, LetsVenture & Others',\n",
       " 'Accel Partners, Sequoia India, Y Combinator and others.',\n",
       " 'Sequoia Capital, Accel Partners & Raghunandan Gangappa',\n",
       " 'SoftBank Vision Fund & Info Edge (India) Ltd',\n",
       " 'Diageo India',\n",
       " 'One 97 Communications',\n",
       " 'Accel Partners, IDG Venture, Endiya Partners, pi Ventures, VH Capital, Axilor Ventures and Binny Bansal',\n",
       " 'Undisclosed Existing Investors As Well As The Tamarind Family Trust',\n",
       " 'Speciale Invest & Others',\n",
       " 'Leo Capital',\n",
       " 'Shiva Gunapu & Others',\n",
       " 'Unknown High Net-Worth Individuals',\n",
       " 'B Capital, International Finance Corporation (IFC), Accel Partners and IDG Ventures',\n",
       " 'IL&FS Private Equity, Kae Capital & Others',\n",
       " 'Unitus Ventures, Behram Vakil and Jerxis Vandrevala',\n",
       " 'Rairah Corporation',\n",
       " 'Sunil Munjal, Harsh Mariwala, Dalip Pathak and Others',\n",
       " 'Prime Venture Partners, Stellaris Venture Partners and Mayur Abhaya Srisrimal',\n",
       " 'Kalaari Capital, Unilever Ventures and Blume Ventures',\n",
       " 'Credika and unnamed angel investors',\n",
       " 'LetsVenture',\n",
       " 'RS Shanbag',\n",
       " 'Insistor, Oikocredit',\n",
       " 'Ashish Kacholi, S Chand Group',\n",
       " 'Atul Gupta and Saurabh Rastogi',\n",
       " 'Amazon, Ashish Dhawan, Catamaran Ventures, NR Narayana Murthy.',\n",
       " 'Prashant Mehta, Mitali Pawar, Nikhil G and Bhavesh P, R Ranganathan, ONCOTRUST and Medintel Services Pvt. Ltd',\n",
       " 'Kalaari Capital, Omidyar Network and Accion Venture Labs',\n",
       " 'Amazon Inc. and Mastercard',\n",
       " 'Treebo',\n",
       " 'IndusAge Partners, Bill & Melinda Gates Foundation, Qualcomm Venture, ABB Technology Ventures, Omnivore, Blume Ventures, Venture Highway and BEENEXT',\n",
       " 'Accion Venture Lab, YourNest Venture Capital And Other Angel Investors',\n",
       " 'Exfinity Venture, Saha fund Partners, Arihant Patni of Patni Family Office, Anjali Bansal, Shardul Amarchand Mangaldas, Satish Khanna and Taparia family office.',\n",
       " 'Subhkam Ventures and Mohit Khadaria',\n",
       " 'Vishal Bali, Yogesh Misra, Thomas Assessments and others',\n",
       " 'ChrysCapital, Existing investors, Elevar Equity, LGT Impact, Omidyar Network and Kaizen Private Equity also participated in the round',\n",
       " 'Maheshwar Peri, founder and chairman of career information portal Careers360, and Jamshed Jeejeebhoy, director at Byramjee Jeejeebhoy Pvt. Ltd were among the angels',\n",
       " 'Accel Partners, Tiger Global And Others',\n",
       " 'Omidyar Network. Blume Ventures and Professor Shlomo Ben-Haim',\n",
       " 'Fireside Ventures',\n",
       " 'Matrix Partner, Amrish Rau, Investopad, Digital Currency Group, Hinduja Group, Lightspeed India, Eight Innovate, Amit Ranjan, Prashant Malik and others',\n",
       " 'Kae Capital Management',\n",
       " 'Fundamentum, SAIF Partners, Bessemer Venture Partners, RB investments & Others',\n",
       " 'SRI Capital, Waterbridge Ventures and ThinKuvate',\n",
       " 'BlueOrchard Finance Ltd, Hinduja Leyland Finance and IntelleGrow',\n",
       " 'Lok Capital',\n",
       " 'Mr. Manoj Prasad',\n",
       " 'Rajan Anandan, Madhusudhan Kannan, Jayant Kadambi, Puneet Gupta and Pradeep K Jaisingh',\n",
       " 'International Finance Corporation, Transamerica and others.',\n",
       " 'TR Capital',\n",
       " 'Shilpa Shetty Kundra',\n",
       " 'Pravega Ventures and Beenext',\n",
       " 'Line Ventures Corporation, Line Corp, Naver, Shinhan Bank and TS Investment',\n",
       " 'Biz Stone, Kunal Bahl, Rohit Bansal, Alagu Periyannan and Karthee Madasamy',\n",
       " 'Vidal Healthcare',\n",
       " 'Amazon',\n",
       " 'GEMS Advisory, Alok Mittal and Sachin Bhatia',\n",
       " 'Neoplux, OPPO, IDG Ventures India, Kalaari Capital, GREE Ventures and Summit Media',\n",
       " 'Omidyar Network, Nandan Nilekani, Blume Ventures, Helion Venture Partners',\n",
       " 'Sequoia Capital, Maverick Capital Ltd and HBM Healthcare Investments Ltd',\n",
       " 'Emery Capital, Blacksoil and Kalaari Capital',\n",
       " 'Bay Capital Investments and Others',\n",
       " 'SAR Group',\n",
       " 'Bessemer Venture Partners and Orios Venture Partners, JM Financials and MEMG',\n",
       " 'CBA Capital and others',\n",
       " 'Sequoia Capital, SAIF Partners and Kalaari capital',\n",
       " 'Baskar Subramanian, Saket Kumar, Gaurav Suri and Ankit Kesarwani',\n",
       " 'InfoEdge',\n",
       " 'Ranjan Pai, Apoorva Patni, Beenext Ventures,GrowX Ventures',\n",
       " 'HDFC Life, HDFC Asset Management',\n",
       " 'Vertex Ventures, Accel Partners and Saama Capital',\n",
       " 'Avendus Finance Pvt. Ltd',\n",
       " 'Aegon NV',\n",
       " 'State Street Global Advisors',\n",
       " 'Trifecta Capital',\n",
       " 'HR Fund',\n",
       " 'Actis, Altimeter Capital',\n",
       " 'Venkat Subramanian, Sudhakar Pennam, and other tech investors from Silicon Valley',\n",
       " 'Matrix Partners, Bhavish Aggarwal, Ankit Bhati, Binny Bansal, Kunal Shah and Manish Patel.',\n",
       " 'SoftBank, Tiger Global and Apoletto Managers.',\n",
       " '1Crowd, Ankur Capital',\n",
       " 'Amit Burman, SIDBI Venture Capital',\n",
       " 'Pi Ventures, Axilor Ventures',\n",
       " 'Micromax Informatics',\n",
       " 'Jessica Wong, Hiro Mashita, Xue Manzi and Yiyun Zhang.',\n",
       " 'Insight Venture Partners, Accel Partners and Tiger Global Management.',\n",
       " 'SucSEED Venture Partners',\n",
       " 'Axilor Ventures, Kumar Vembu',\n",
       " 'Initia Holdings,Vipin Agarwal and others.',\n",
       " 'Accion Venture Lab, Unicorn India Ventures and ISME ACE.',\n",
       " 'Ratan Tata',\n",
       " 'Amit Singhal and Unitus Seed Fund',\n",
       " 'Google, Kae Capital, IIFL, Singularity Ventures, GrowX, Tracxn Labs, Venture Catalyst, Patni family office and Axis Capital.',\n",
       " 'Alibaba, Helion Venture Partners, Bessemer Venture Partners, Ascent Capital',\n",
       " 'Omidyar Network',\n",
       " 'Man Capital LLP, Girnar Software, Others',\n",
       " 'Bhavesh Manglani, Suraj Saharan, Darshan Upadhyay, Sanjay Notani & Others',\n",
       " 'Montane Ventures',\n",
       " 'Sandeep Mathur',\n",
       " 'Meritech Capital Partners',\n",
       " 'Sistema Asia Fund',\n",
       " 'British and Indian Governments',\n",
       " 'Accel Partners, Sequoia Capital',\n",
       " 'Social Capital',\n",
       " 'Fullerton Financial Holdings Pte Ltd & Others',\n",
       " 'Bessemer Venture Partners, Stellaris Venture Partners, Axis Capital, Singapore, Jungle Venture Partners',\n",
       " 'Ashok Kumar Gajera',\n",
       " 'Tribe Impact Capital LLP',\n",
       " 'Michael & Susan Dell Foundation, LGT Impact Ventures',\n",
       " 'Kalpavriksh',\n",
       " 'Axis Capital Partners',\n",
       " 'Dewang Neralla, Mahesh Kothurkar,Atul Agarwal',\n",
       " 'S7 Group',\n",
       " 'Michael Patrick Hickey',\n",
       " 'Network 18',\n",
       " 'Sequoia and Jerry Yang',\n",
       " 'Mohammed Khan, Sameer Narayan & Others',\n",
       " 'Hinduja Leyland Finance, IntelleGrow',\n",
       " 'Ankur Capital',\n",
       " 'Lightspeed & Yuri Milner',\n",
       " 'Wargburg Pincus, Sequoia',\n",
       " 'Blume Ventures, HealthQuad and Fireside Ventures',\n",
       " 'PNC, Citi Ventures',\n",
       " 'Auxano Deals',\n",
       " 'Kris Gopalakrishnan, Pratithi Investment Trust, MEMG Family Office, S Gopal',\n",
       " 'Dr Devi Shetty',\n",
       " 'Startup Buddy,Amit Manocha and others',\n",
       " 'Tencent Holdings Ltd, Times Internet',\n",
       " 'Y Combinator, Khosla Ventures, Vy Capital and others',\n",
       " 'Unitus Seed Fund',\n",
       " 'Recruit Holdings, Sequoia Capital India, Accel Partners',\n",
       " 'Eight Roads Ventures India',\n",
       " 'Claris Capital, Mumbai Angels Network',\n",
       " 'Rohan Agila',\n",
       " 'Nederlandse Financierings-Maatschappij voor Ontwikkelingslanden N.V.',\n",
       " 'RuNet & Other',\n",
       " 'Amazon-Patni JV',\n",
       " 'responsAbility, Elevar Equity and Accel Partners',\n",
       " 'Morgan Stanley Private Equity Asia',\n",
       " 'Pankaj Chopra, Ankush Gupta',\n",
       " 'Tiger Global, Y Combinator',\n",
       " 'Indian fintech fund, Rainmatter',\n",
       " 'Sunil Kant Munjal, Hero Electronix\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s corporate financing arm, Electronic Development Fund',\n",
       " 'Goldman Sachs, hedge fund & Others',\n",
       " 'Polaris Fund',\n",
       " 'Xiaomi Singapore, Shunwei Capital',\n",
       " 'The Chennai Angels',\n",
       " 'LionRock Capital',\n",
       " 'Incubate Fund India, Anuj Agrawal',\n",
       " 'DMI Finance',\n",
       " 'Dr. Ranjan Pai',\n",
       " 'Unilever Ventures',\n",
       " 'LeapFrog Investments, Aspada Investment, Quona Capital',\n",
       " 'Avendus Finance',\n",
       " 'IFMR Capital',\n",
       " 'Chennai Angels, Lead Angels, LetsVenture',\n",
       " 'Pravega Ventures',\n",
       " 'RNT Capital',\n",
       " 'Ventureast, Endiya Partners, Eight Roads Ventures, Touchstone Equities, BVR Mohan Reddy',\n",
       " 'Shivani Singh, Rahul Maroli, Mitesh Shah, Venture Catalysts, Alfa Capital, Green Shots Capital, Real Time Ventures.',\n",
       " 'Accel Partners',\n",
       " 'Axilor Ventures, Newfort Capital',\n",
       " 'Undisclosed Investors',\n",
       " 'HDFC Bank, Axis Bank',\n",
       " 'Scale Minds',\n",
       " 'Google',\n",
       " 'Hines',\n",
       " 'NB Ventures',\n",
       " 'Apis Partner, Eight Roads Ventures, Bamboo Capital Partners',\n",
       " 'Eduardo Saverin',\n",
       " 'Somerset Indus Capital Ventures',\n",
       " 'IDG Ventures',\n",
       " 'Singapore Angel Network, Mumbai Angel',\n",
       " 'Village Capital',\n",
       " 'Aamir Khan',\n",
       " 'HT Media',\n",
       " 'Hyderabad Angels',\n",
       " 'Munesh Khanna',\n",
       " 'Canaan Partners',\n",
       " 'Rakesh Jhunjhunwala',\n",
       " 'Bessemer Venture Partners',\n",
       " 'Mohan Tanksale, Kiran Shetty, Darshak Shah, Mandar Mhatre',\n",
       " 'RoundGlass Partners',\n",
       " 'Accel Partners, Sequoia Capital, RB Investments',\n",
       " 'Mountain Pain Capital, Suncoast Investments',\n",
       " 'InsuResillience Investment Fund',\n",
       " 'Costanoa, Learn Capital, Jyoti Bansal',\n",
       " 'Swati Gupta, Purnima Khandelwal, Maheshwar Peri, Sanjay Singh',\n",
       " 'Axilor Ventures, E-City VEntures Atul Goel',\n",
       " '\"Kedaraa Capital, Ontario Teachers\\\\\\\\\\'\"',\n",
       " 'Ambarish Gupta, Aneesh Reddy, Bold Ventures, Vona Investments',\n",
       " 'Gaurav Gupta',\n",
       " 'Jones Lang LaSalle',\n",
       " 'Manish Poddar, Arun Garg, Parmeshwar Sharma',\n",
       " 'CIO Angel Network',\n",
       " 'Jayant Humbarwadi',\n",
       " 'Kae Capital Management, Nazara Technologies',\n",
       " 'IDG Ventures India',\n",
       " 'Alok Mittal, Deepak Jain, Ritesh Malik, Jim Schimdktke',\n",
       " 'Infosys co-founder Kris Gopalakrishnan',\n",
       " 'Matrix Partners India, Khosla Ventures',\n",
       " 'Titan Co Ltd, Tata Group\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s watch and jewellery retailing firm',\n",
       " 'Lumis Partners',\n",
       " 'Quona Capital Management',\n",
       " 'Pioneering Ventures, Syngenta AG',\n",
       " 'IDG Ventures, IDFC-Parampara Fund',\n",
       " 'Singtel, Innov8, Harmony Partners',\n",
       " 'Wipro Consumer Care',\n",
       " 'GAIL India Ltd',\n",
       " 'Rugmini Menon',\n",
       " 'Girish Mathrubootham, Apurva Chamaria, Rohit Chanana',\n",
       " 'Nishit Sharma, Alok Srivastava',\n",
       " 'SSCBS Innovation, Incubation Foundation (SIIF)',\n",
       " 'Z Nation Lab',\n",
       " 'Skycatcher Fund, Aravind Sanka',\n",
       " 'Notion Capital, IDG Ventures',\n",
       " '1Crowd',\n",
       " 'Vida Ventures, Dr. Aniruddha Malpani',\n",
       " 'Sabre Partners, MEMG CDC',\n",
       " 'Paytm',\n",
       " 'Global Institutional Investors',\n",
       " 'Axilor Ventures',\n",
       " 'Sandeep Aggarwal',\n",
       " 'Javelin StartupO Victory Fund',\n",
       " 'Amit Patni',\n",
       " 'Gaja Capital',\n",
       " 'NB Ventures, MediAssist',\n",
       " 'Matrix PArtners, Accel',\n",
       " 'Startup Buddy, Apurva Chamaria,Sachin Arora, Bharat Gupta, Amit Manocha',\n",
       " 'Tencent, Softbank Group',\n",
       " 'Digital Garage',\n",
       " 'Sprout Angels',\n",
       " 'Blume Ventures, IDG Ventures & Indian Angel Network',\n",
       " 'Globevestor',\n",
       " 'Sequoia India, Helion Venture Partners, Beenext',\n",
       " 'Carpediem Capital',\n",
       " 'Epsilon Venture Partners, Tara India Fund IV and others',\n",
       " 'Das Capital, Axan Partners, Das Capital and IT Farm',\n",
       " 'Das Capital, Simile Ventures',\n",
       " 'Daffodil Software',\n",
       " 'Firoze Irani, Vipul Parekh, Ananda Kallugadde, Rajesh K Murthy',\n",
       " 'Shailesh Haribhakti',\n",
       " 'Aequs Group',\n",
       " 'Orient BlackSwan',\n",
       " 'Rahul Agarwalla, Keshav Sanghi, Batlivala & Karani Securities',\n",
       " 'Multipoint Capital,',\n",
       " 'Saama Capital and DSG Consumer Partners',\n",
       " 'SAIF Partners, YCombinator, Venture Highway',\n",
       " 'KStart Capital',\n",
       " 'Wellington Management, DG Ventures India, True North',\n",
       " 'Vida Ventures, Snehal Mantri, Anshu Bahadur',\n",
       " 'Xiaomi Technologies, Shunwei Capital',\n",
       " 'Amicus Capital',\n",
       " 'Accel Partners, Zephyr Peacock',\n",
       " 'Experian',\n",
       " 'Nexus, GREE Ventures',\n",
       " 'SAIF Partners, Helion Ventures, FIL Capital Management',\n",
       " 'DSG Consumer Partners, Sequoia Capital, Saama Capital',\n",
       " 'Rockstart Accelerator',\n",
       " 'Indian Angel network, IAN Fund',\n",
       " 'Matrix Partners India, WaterBridge Ventures, Whiteboard Capital, Sarbvir Singh',\n",
       " 'Blume Ventures, Indian Angel Network',\n",
       " 'Greenfield Advisory',\n",
       " 'Abhishek Bhatewara, Vivek Shah, Haitong Securities, Suraj Saharan, Paras Arora',\n",
       " 'Hunch Ventures, Spiral Ventures, 500 Startups, Singapore Angel Network, Citrus Payments',\n",
       " 'Helion Venture Partners',\n",
       " 'Kotak Mahindra Bank',\n",
       " 'Incubate Fund, Sandesh Kirkire, Anand Kumar, Yogesh Chaudhary',\n",
       " 'ANI Technologies Pvt. Ltd',\n",
       " 'Mahindra & Mahindra and Infuse Ventures',\n",
       " 'TannCam Investment & Sistema Asia Fund',\n",
       " 'IL&FS, Trust Capital, Rosy Blue Securities, Radhakrishan Damani and Rakesh Jhunjhunwala',\n",
       " 'YourNest Angel Fund',\n",
       " 'Stellaris Venture Partners, Mayur Abhaya, Rohit MA',\n",
       " 'Accel Partners, Exfinity Ventures, Partech Ventures',\n",
       " 'SRI Capital, BeeNext, Pravega Ventures',\n",
       " 'Michael and Susan Dell Foundation, Anand Mahindra',\n",
       " 'Bertelsmann India, Mayfield Capital, Saama Capital, Darrin Capital',\n",
       " 'HIS Co. Ltd, MakeMyTrip',\n",
       " 'Sequoia Capital India, Artiman Ventures',\n",
       " 'International Finance Corporation (IFC), Inventus Capital Partners, Accel Partners, Kalaari Capital, and Nandan Nilekani,',\n",
       " 'V Balakrishnan.',\n",
       " 'SoftBank Group, Sequoia Capital India, Lightspeed Venture Partners, Greenoaks Capital, Hero Enterprise',\n",
       " 'RPG Enterprises',\n",
       " 'Triodos Investment Management,',\n",
       " 'Venture Highway, Alok Mittal, Mohit Agarwal, Anuj Gupta,',\n",
       " 'Warburg Pincus',\n",
       " 'Sachin Tendulkar, P.V SIndhu, Pullela Gopichand',\n",
       " 'Raman Roy, Arvind Uppal, Sonu Bhasin, G Ravishankar',\n",
       " 'WRV Capital, Qualcomm Ventures, Edelweiss Private Equity, Artiman Ventures',\n",
       " 'IAN Fund, Beenext, Indian Angel Network',\n",
       " 'Anand Chandrasekaran, Apurva Chamaria, Ritesh Malik, Ashish Toshniwal, Ajeet Khurana',\n",
       " 'China Lodging Group',\n",
       " 'Sequoia Capital India, SAIF Partners, Nexus Venture Partners and Blume Ventures,',\n",
       " 'Chennai Angels, Keiretsu Forum & Others',\n",
       " 'Rohit Nanda, Rajit Nanda, Smarak Bhuyan, Sashwat Brahma,',\n",
       " 'ECL Finance',\n",
       " 'Rising Stars, Manish Amin, Pallav Pandey, Chavi Jafa',\n",
       " 'DSG Consumer Partners, Saama Capital',\n",
       " 'Shamik Sharma, Aprameya Radhakrishna',\n",
       " 'Susquehanna Growth Equity LLC',\n",
       " 'Incofin Investment Management.',\n",
       " 'AdvantEdge',\n",
       " 'Sandway Investment Ltd, Pearl Brook Holdings, Silo Holdings and Al Nour',\n",
       " 'LG Chandrasekhar',\n",
       " 'InnoVen Capital India',\n",
       " 'AV Thomas Group',\n",
       " 'Vertex Ventures, Prime Venture Partners.',\n",
       " 'Zomato Media Pvt. Ltd',\n",
       " 'Beenext',\n",
       " 'Battery Road Digital Holdings LLC',\n",
       " 'Mehul Shah',\n",
       " 'Kae Capital',\n",
       " 'Rajan Anandan, Jamil Khatri, Ravi Iyer, Raghav Bahl',\n",
       " 'Aniruddha Malpani, Startup Oasis',\n",
       " 'IL&FS Investment Managers, Omidyar Network.',\n",
       " 'Capillary Technologies, Whiteboard Capital, YourNest Angel Fund, Rajul Garg',\n",
       " 'Blume Ventures, Goldbell Group, Anurag Srivastava, Shailesh Rao, Amiya Pathak, Rajesh Yohanan and Rahul Garg',\n",
       " 'Rivergate Capital,',\n",
       " 'Keiretsu Forum',\n",
       " 'Triton Investment Advisors',\n",
       " 'Kashyap Deorah, Anand Sankeshwar, Deepak Jain, Sadashiva NT, Arjun Mehta, Satish Kaul, Anindya Ghose',\n",
       " 'Kunal Shah, LetsVenture, Anupam Mittal, Hetal Sonpal',\n",
       " 'Narottam Thudi, Shireesh Palle',\n",
       " 'Cismat Cargo Services Pvt. Ltd.',\n",
       " 'Rajasthan Angel Investor Network',\n",
       " 'DSG Consumer Partners, Eight Roads Ventures India',\n",
       " 'SIDBI',\n",
       " 'JSW Ventures',\n",
       " 'Anuj Puri, Redcliffe Capital, Artha India Ventures, Siddharth Kothari, Apoorv Ranjan Sharma,',\n",
       " 'R. Jayakumar, Vaibhav Vohra, Aditya Vazirani, Rhea Vazirani, AVN Business Solutions, Dreamweaver Investments',\n",
       " 'Rahul Dev Kumar, Rajesh Mahajan, Ankit Sharma and others',\n",
       " 'Venugopal Dhoot, Ajay Bhatia, Tarun Khandelwal, Ganpat Singhvi, Mandhian family & Others',\n",
       " 'Factor[e] Ventures',\n",
       " 'Tom Varkey',\n",
       " 'Incubate Fund, Sanjay Shenoy, Mridul Upreti,',\n",
       " 'Softbank',\n",
       " 'Nazara Games',\n",
       " 'Tekne Capital Management',\n",
       " 'InCred Finance, Fullerton India Credit Company Ltd',\n",
       " 'InCred, Krishnakumar Natarajan, Ravi Bhardwaj',\n",
       " 'Green Visor Capital LP II, IA Venture Strategies Fund II LP, Boillot Family Trust, Russell M Byrne, The Oliver R. Grace, Jr. Millennium Trust, SF Capital Investments LP',\n",
       " 'Abhinav Gupta,',\n",
       " 'Undisclosed HNI\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s',\n",
       " 'iSquare Global,',\n",
       " 'Social Alpha, Rajan Anandan, Rajeev Ahuja, Kshitij Arora',\n",
       " 'Blume Ventures. Lenovo Capital and Incubator Group (LCIG)',\n",
       " 'Riverwood Capital, Sequoia Capital India, Nexus Venture Partners, Tenaya Capital',\n",
       " 'IIT Ropar, Imanpreet Singh Arora, Sidharth Rozario, Saurabh Abichandani, Shikhar Gupta,',\n",
       " 'Haresh Chawla',\n",
       " 'JS Capital Management, Social Capital, Horizons Ventures,',\n",
       " 'VAMM Ventures, Raksul, Dena',\n",
       " 'PBS Srinivas, Vinod Martin,',\n",
       " 'Sistema Asia Fund, C31 Ventures, Qualgro.',\n",
       " 'Accel Partners, IDG Ventures, Kalaari Capital,\\\\\\\\xc2\\\\\\\\xa0 UC-RNT fund',\n",
       " 'idal Health, growx ventures, Capier Investments, Globevestor & others',\n",
       " 'Small Industries Development Bank of India (SIDBI)',\n",
       " 'Ward Ferry Management and Karst Peak Capital,',\n",
       " 'Sequoia India, Sofina s.a., Zodius Capital, Kris Gopalakrishnan, Lakshmi Narayanan,',\n",
       " 'Reliance Corporate Advisory Services Ltd',\n",
       " 'Infuse Ventures, JLL',\n",
       " 'Asset Management (Asia) Ltd, Digital Garage Inc',\n",
       " 'Kalaari Capital, Nexus India Capital Advisors',\n",
       " 'International Finance Corporation, Rocketship, Accel Partners, Jungle Ventures, Shailesh Rao, Venture Highway',\n",
       " 'BCCL',\n",
       " 'Blume Ventures, Contrarian Capital India Partners, Emergent Ventures India, Pallav Nadhani, Ashish Gupta, Sharad Sharma, Sirion Labs',\n",
       " 'India Quotient, Shunwei Capital',\n",
       " 'Sreeram Iyer, Suvo Sarkar, Anita Gupta, Likemind Ventures',\n",
       " 'Mitsui & Co.',\n",
       " 'Dunamis Ventures Pte Ltd',\n",
       " 'Venture Catalysts, Sourav Ganguly, Ankit Aditya, Moksh Sports Ventures',\n",
       " 'Fireside Ventures, Apurva Salarpuria, Sidharth Pansari, Sprout Capital',\n",
       " 'SBI-FMO Fund, Bessemer Venture Partners, Catamaran Ventures',\n",
       " 'Corvus Ventures, MAPE Advisory Group',\n",
       " '500 Startups, Purvi Capital, Rajan Anandan, Abhishek Gupta',\n",
       " 'Indian Angel Network',\n",
       " 'Brigade Innovations LLP, TV Mohandas Pai, Suhail Rahman, Bobby Reddy, M George Oommen',\n",
       " 'BlackSoil Capital Pvt Ltd',\n",
       " 'Sequoia Capital, Grey Orange, Rajesh Ramaiah, Anshuman Das, Rishi Das',\n",
       " 'IDG Ventures India Advisors, Jungle Ventures',\n",
       " 'One97 Communication Ltd',\n",
       " 'Uber Technologies Inc, Amaya Capital LLP',\n",
       " 'Xelpmoc',\n",
       " 'ain Capital Ventures, Renaud Laplanche',\n",
       " 'Francesco Cara',\n",
       " 'ABI-Showatech (India) Ltd',\n",
       " 'Kae Capital, M&S Partners,',\n",
       " 'Subramani Somasundaram, Sundeep Sahni, Mayank Mittal & Others',\n",
       " 'Harmeet Bajaj, Pameela P, Fusiontech Ventures & Others',\n",
       " 'Sunil Kalra, Aditya Singh, Rishi Srivastava, Rajan Anandan',\n",
       " 'Blume Ventures, NB Ventures, Nspira',\n",
       " 'Tencent Holdings',\n",
       " 'Yuvraj Singh',\n",
       " 'Goldman Sachs',\n",
       " 'Indian Angel Network, Anand Mahindra',\n",
       " 'HBM Healthcare Investments, Maverick Capital Ventures, Sequoia India, Omidyar Network and Kae Capital',\n",
       " 'Amen Dhyllon',\n",
       " 'Grace Grace Techno Ventures LLP, Rajul Garg & Other undisclosed investors',\n",
       " 'TVS Motor Company',\n",
       " 'Emerging India',\n",
       " 'lockchain ecosystem Global Advisors, Horseferry',\n",
       " 'Blume Ventures, Indian Angel Network, Kunal Shah, Sandeep Tandon',\n",
       " 'Arun Patodia, Bharat Kedia',\n",
       " '500 Startups, IvyCap Ventures',\n",
       " 'Harsh Mahajan, Farhan Naqvi, Sreepathy Viswanathan',\n",
       " 'Sundaram Finance Holdings',\n",
       " 'SBI (Stand Up India Scheme)',\n",
       " 'Bodhtree Consulting Limited',\n",
       " 'Norwest Venture Partners',\n",
       " 'Mohan Alexander, R. Natarajan, Vikrant Varshney, Amit Sinha',\n",
       " 'Pawan Borle, Nirmal Singh, Manish Prasad, Vineet Varma, Nick Haulkoury, Abhai S. Rao',\n",
       " 'Dr Ramesh Ayyala, Satya Muthyala',\n",
       " 'Cao Yibin, Huang Wei, Madhusudan E,',\n",
       " 'Yes Bank',\n",
       " 'Unicorn India Ventures, Venky Krishnakumar, Suresh Shankar, Vivek Bhargava',\n",
       " 'Venture Catalysts, Alfa Capital, Green Shots Capital, Real Time Ventures',\n",
       " 'Artha India Ventures, Singularity Holdings, Rajan Anandan, Girish Mathrubootham',\n",
       " 'Transamerica',\n",
       " 'Nexus Venture Partners, Founders Fund',\n",
       " 'Nexus Venture Partners, Omidyar Network',\n",
       " 'Fairfax Holdings',\n",
       " 'Tekne Capital Management LLC',\n",
       " 'Sequoia India, NEA, Prime Venture Partners',\n",
       " 'Nexus Venture Partners, Mekin Maheshwari',\n",
       " 'Alphard Maritime Group',\n",
       " 'Cross Border Angels & Experts, Rajasthan Angel Innovators Network, The Chennai Angels',\n",
       " 'YouWeCan Ventures',\n",
       " 'BLIP Initiatives',\n",
       " 'Lightspeed India Partners, Endiya Partners, 3one4 Capital Advisors LLP, Startupxseed Ventures LLP',\n",
       " '91maker.com',\n",
       " 'IIFL Seed Ventures, Kae Capital, FJ Labs, Singularity Ventures, GrowX, Tracxn Labs, Axis Capital',\n",
       " 'Manipal Education and Medical Group (MEMG), SAR Group, The Grover Trust',\n",
       " 'iBhubs',\n",
       " 'UC-RNT Fund, Matrix Partners, alcon Edge Capital, DSG Consumer Partners',\n",
       " 'General Catalyst, Founder Collective',\n",
       " 'Endiya Partners, Ventureast',\n",
       " 'Mekin Maheshwari, Bharat Vijay, Krish Seshadri, Amar Arsikere',\n",
       " 'Kae Capital, India Quotient, IFMR, and MAS Financial Services Ltd',\n",
       " 'Mohit Srivastav, Kishore Ganji, Venkat Vallabhaneni, Rajeev Menon',\n",
       " 'Seedfund, RB International',\n",
       " 'Snow Leopard Ventures, Alto Partners',\n",
       " 'Gujarat Venture Finance Ltd',\n",
       " 'The Chennai Angels, Anthill Scale Ventures, Esvee Technologies Inc, Inc95 Consulting',\n",
       " 'Aparup Sengupta, Devendra Reddy,',\n",
       " 'Kalaari Capital, Udayan Goyal',\n",
       " 'SAP.iO, Unilazer Ventures',\n",
       " 'Abhinav Bindra, Gaurav Marya',\n",
       " 'Zeta',\n",
       " 'Vy Capital, SAIF Partners, Accel Partner, Bessemer Venture Partners',\n",
       " 'Clairvest Group',\n",
       " 'International Finance Corporation',\n",
       " 'Accel Partners, Nandan Nilekani,',\n",
       " 'Dutch government fund',\n",
       " 'Falcon Edge Capital,\\\\\\\\xc2\\\\\\\\xa0 Capital Advisers',\n",
       " 'Asuka Holdings, YouWeCan Ventures, Beenext, Beenos, M&S Partners',\n",
       " 'Nimit Panigrahi',\n",
       " 'Hinduja family',\n",
       " '50K Ventures',\n",
       " 'Rainmatter',\n",
       " 'Rainbow Digital Services Pvt. Ltd, ILearnFinance Academy Pvt. Ltd.',\n",
       " 'Indian Angels Network, LetsVenture',\n",
       " 'Deepak Nathani',\n",
       " 'Ajay Relan, LetsVenture',\n",
       " 'Vertex Ventures, C31 Ventures',\n",
       " 'Trifecta Capital Advisors LLP, Prathithi Investment Trust, RNT Capital, Gokul Rajaram, Aditya Agarwal, Ruchi Sanghvi & others',\n",
       " 'Satoshi Studios',\n",
       " 'Anand Chandrasekaran',\n",
       " 'Luxasia Group',\n",
       " 'GVFL, Unicorn India Ventures',\n",
       " 'Vellayan Subbiah, Jonathan Boutelle, Rajan Anandan,\\\\\\\\xc2\\\\\\\\xa0 Rahul Chawla, Salil Donde, Amit Ranjan, Govind Rajan & Others',\n",
       " 'Times Internet, GVFL',\n",
       " 'Varsha Rao, Surojit Chatterjee, Nirav Choksi & Others',\n",
       " 'DG Ventures India, Dewan Housing Finance Corp',\n",
       " 'Chirag Nikunj Sheth & Others',\n",
       " 'Aakrit Vaish, Swapan Rajdev, Sushill Jiwarajka',\n",
       " 'Impanix Capital',\n",
       " 'GEMs',\n",
       " 'Infibeam, CCavenue',\n",
       " 'Ideaspring Capital',\n",
       " 'SAP',\n",
       " 'Innovations East',\n",
       " 'Rocketship',\n",
       " 'Jungle Ventures',\n",
       " 'Ayesha Takia Azmi, Abu Farhan Azmi',\n",
       " 'Dr. Ritesh Malik',\n",
       " 'SoftBank Group',\n",
       " 'Dheeraj Pandey, Rajesh Yohannan, Akash Garg',\n",
       " 'Ankur Capital, Hyderabad Angels',\n",
       " 'Gokaldas Exports Ltd',\n",
       " 'JLL, 1Crowd',\n",
       " 'Eagle10 Ventures',\n",
       " 'Lightspeed Venture Partners, Vy Capital,',\n",
       " 'Ratan Tata, Nandan Nilekani, Uday Kotak, Vijay Shekhar Sharma, Kiran Mazumdar-Shaw, Rajiv C Mody',\n",
       " 'Blue Orchard',\n",
       " 'Lahiri Music\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s family office',\n",
       " 'PV Sahad, Sandeep Shroff, Rahul Gupta',\n",
       " 'Soma Capital, Great Oaks Ventures, 122 West Ventures',\n",
       " 'Nasper, Accel India, SAIF Partners, Bessemer Venture Partners, Harmony Partners, Norwest Venture Partners',\n",
       " 'Rohto Pharmaceutical',\n",
       " 'Lightspeed India Partners, Waterbridge Ventures',\n",
       " 'Mathew Cyriac, Florintree Advisors,',\n",
       " 'Bertelsmann India',\n",
       " 'Matrix Partners India',\n",
       " 'Quadria Capital Advisors',\n",
       " 'Rohitash Gupta',\n",
       " 'Unicorn India Ventures & Others',\n",
       " 'Aspada Investments',\n",
       " 'Stellaris Venture Partners, Helion Venture Partners, Powerhouse Ventures, Gokul Rajaram, Girish Mathrubootham, Aneesh Reddy, Vispi Daver',\n",
       " 'Kalaari Capital, Norwest Venture Partners',\n",
       " 'Keyur Joshi, Pavan Bakeri',\n",
       " 'Koen Bouwers, Lomesh Agarwal, Jeroen Mensen, Pablo van den Bosch & Others',\n",
       " 'Deepak Kulkarni, Sandeep Pangal',\n",
       " 'Zephyr Peacock India',\n",
       " 'FreakOut Group, Blume Ventures, Herb Madan, WaterBridge Ventures',\n",
       " 'Mahindra Partners, Eight Roads Ventures, F-Prime Capital Partners',\n",
       " 'Accel Partners, Shunwei Capital',\n",
       " 'Ishwar Singh,Farhaan Shabbir',\n",
       " 'Bessemer Venture Partners, Orios Venture Partners, Trifecta Capital,',\n",
       " 'Labruyere Eberl\\\\\\\\xc3\\\\\\\\xa9',\n",
       " 'Lightspeed India Partners, Blume Ventures, CyberAgent Ventures, GrowX Ventures, IMJ Investment Partners',\n",
       " 'Rajan Anandan, L.D Sharma, Saurabh Arora',\n",
       " 'Mahindra and Mahindra Financial Services',\n",
       " 'Accel Partners, Nandan Nilekani\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s NRJN Trust, Mistletoe, Qualcomm Ventures, M&S Partners',\n",
       " 'Philippe Bouchet',\n",
       " 'Sushil Kumar, Sandeep Singh',\n",
       " 'Ivycap Ventures Advisors, Singularity Ventures and Ravi Dhariwal',\n",
       " 'Mayfield, Nishant Rao, Dileep Nath',\n",
       " 'DHI Group Inc, Prime Venture Partners, Beenext, Beenos, Digital Garage, BizReach',\n",
       " 'Blume Ventures, Contrarian Capital, 91springboard, Emergent Ventures, Abstract Ventures, Anthill Ventures, Axilor Ventures',\n",
       " 'MAPE Advisory Group, R Ramaraj, Corvus Ventures',\n",
       " 'Redcliffe Capital',\n",
       " 'Urrshila Kerkar,',\n",
       " 'SIMI Pacific Pte',\n",
       " 'Tolaram Inc, Mountain Pine Capital',\n",
       " 'Benori Ventures LLP',\n",
       " 'Jacqueline Fernandez',\n",
       " 'Nibhrant Shah, Anandbir Singh, Anirudh Sheth, Pratik Singhi, Vikram Mehta, Murali Nair',\n",
       " 'Gaurav Kachru, Sundeep Singh Sahni, Jatin Aneja, Arun Malhotra',\n",
       " 'IndiaNivesh Venture Capital Fund',\n",
       " 'SIDBI Venture Capital Ltd, Kalaari Capital',\n",
       " 'Ankit Nagori',\n",
       " 'Ravi Garikipati, Surot Chatterjee, Ashish Agrawal, LG Chandrasekhar, Sashi Reddi',\n",
       " 'Ligthbox Ventures II, Lightbox Expansion Fund, Sequoia Capital India, RuNet South Asia, RB Investments',\n",
       " 'SoftBank Vision Fund, Lightspeed Venture Partners, Sequoia Capital India Advisors, Greenoaks Capital Partners',\n",
       " 'WGG International',\n",
       " 'pi Ventures, Axilor Ventures, 500 Startups, Binny Bansal',\n",
       " 'Arun Tadanki, Aditya Verma',\n",
       " 'Times Internet,Matrix Partners',\n",
       " 'DAH Beteiligungs GmbH',\n",
       " 'S. Xavier Britto',\n",
       " 'Orios Ventures Partners, Team Builder Ventures, Omidyar Networks',\n",
       " 'Agnus Capital, Khattar Holdings',\n",
       " 'GardX International',\n",
       " 'Cross Border Angels & Experts',\n",
       " 'Poshika Financial Ecosystem',\n",
       " 'SoftBank Group Corp',\n",
       " 'Calcutta Angels Network (CAN), Augment Ventures',\n",
       " 'Vishwadeep Bajaj, Harsh Kundra, Nandkumar Rane, LN Buddharaju, Anupam Tyagi',\n",
       " 'Ventureast, Endiya Partners, Eight Roads Ventures, F-Prime Capital Partners',\n",
       " 'Lightspeed Venture Partners',\n",
       " 'Langoor',\n",
       " 'Quona Capital',\n",
       " 'Chandigarh Angels Network, Social Alpha and other unnamed angel investors',\n",
       " 'Bhupen Shah, Jayesh Parekh, Sanjay Sathe',\n",
       " 'Sandeep Aggarwal, Gautam Chhaochharia, R Balachandar',\n",
       " 'Bennett, Coleman and Company Ltd',\n",
       " 'Undisclosed angel investors',\n",
       " 'Alibaba',\n",
       " 'Atul Nishar',\n",
       " 'Aneesh Seth, Tushar Mittal',\n",
       " 'SIDBI Venture Capital Fund',\n",
       " 'Star India Pvt Ltd',\n",
       " 'IDFC Parampara Early Stage Opportunities Fund',\n",
       " 'National Science and Technology Entrepreneurship Development Board',\n",
       " 'IDG Ventures India, Michael & Susan Dell Foundation, Draper Associates, Unitus Seed Fund',\n",
       " 'Private Sector Banks (Debt Funding)',\n",
       " 'IDG ventures, Axilor Ventures, Emergent Ventures, Indian Angel Network',\n",
       " 'Kae Capital, SEGNEL Ventures',\n",
       " 'Deepak Gurnani',\n",
       " 'Times Internet Ltd',\n",
       " 'Singapore Angel Network',\n",
       " 'Asuka, Pravega Ventures, BEENEXT',\n",
       " 'Cyber Carrier',\n",
       " 'Florintree, Mathew Cyriac, Chidambaram Palaniappan, Bharat Sheth',\n",
       " 'IDG Ventures, Blume Ventures, Saha Fund,',\n",
       " 'Puneet Gupta, Nimitt Desai & Others',\n",
       " 'GREE Ventures, Kalaari Capital and IDG Ventures India, Summit Media, Atul Goel, and Gurpreet Singh',\n",
       " 'Sujeet Kumar, Bhupender Singh, Yashish Dhaiya',\n",
       " 'Microsoft, eBay, Tencent Holdings',\n",
       " 'Kalaari Capital, Rakesh and Rajesh Jhunjhunwala',\n",
       " 'L\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99Occitane',\n",
       " 'Shripad Nadkarni, Nandu Nandkishore',\n",
       " 'Ravi Saxena, Sandeep Raju,',\n",
       " 'Sequoia Capital, Kinzon Capital',\n",
       " 'FTV Capital, Zodius Capital',\n",
       " 'Ojas Ventures',\n",
       " 'Mahavir Sharma, Vishal Jain, Rohit Sethi, Gaurav Luniya',\n",
       " 'Carlyle Group, Tiger Global',\n",
       " 'Vikas Bajaj, Amit Kharbanda,',\n",
       " '3One4 Capital',\n",
       " 'Ankit Gupta, Puneet Motihar',\n",
       " 'Verlinvest',\n",
       " 'Mayfield India, 3one4 Capital, Sistema Asia Fund, Neoplux Technology Fund',\n",
       " 'Vinod Martin, Hemant Kaul, Prof. Ram Kumar Kakani & Others',\n",
       " 'JSW Ventures, VenturEast',\n",
       " 'Meher Roy, Nikhil Arora, Meet Kanodia, Krit Sankalp, Nitish Singh, Risabh Gupta',\n",
       " 'Om Chaudhry',\n",
       " 'Malini Patel, Stelcore Management Services, Anjani Prasad',\n",
       " 'Samridhi Fund',\n",
       " 'Intex Technologies',\n",
       " 'Satveer Thakral, LetsVenture, Mumbai Angels',\n",
       " 'B Capital Group, Ignition Partners, Greycroft, e.ventures,\\\\\\\\xc2\\\\\\\\xa0 Eight Roads Ventures',\n",
       " 'Satya D Sinha, Gyanendra Singh',\n",
       " 'IFMR Capital Finance',\n",
       " 'Jaarvis Accelerator',\n",
       " 'Batlivala & Karani Securities, Venture Works',\n",
       " 'RB Investments, SAIF Partners, Bessemer Venture Partners',\n",
       " 'Earlsfield Capital',\n",
       " 'pi Ventures, Blume Ventures',\n",
       " 'Temasek Holdings',\n",
       " 'Japan Vyas, Tarun Adlakha',\n",
       " 'Facebook FB Start programme',\n",
       " 'RB Investments, Sequoia Capital',\n",
       " 'Ganesh Natarajan',\n",
       " 'Sistema Asia Fund, Amereus Group, Helion Ventures',\n",
       " 'Al Dhaheri family',\n",
       " 'ThinQbate',\n",
       " 'Accel Partners, IDG Ventures, Endiya Partners, pi Ventures, VH Capital, Axilor Partners',\n",
       " 'Vertex Ventures, Lumis Partners',\n",
       " 'Anil Jain & other HNIs',\n",
       " 'Kleiner Perkins, Goldman Sachs, Pine Brook',\n",
       " 'Mohit Joshi & Others',\n",
       " 'Mahalingam K, Girish Mathrubootham',\n",
       " 'Infibeam',\n",
       " 'Vikram Sud',\n",
       " 'Vijay Shekhar Sharma, Rajan Anandan, Kunal Shah, Girish Mathrubootham, Punit Soni, Anand Chandrasekaran, Sunil Kalra, Utsav Somani, Vishal Gondal, Vikram Limaye',\n",
       " 'PayU, Ribbit Capital, Omidyar Network',\n",
       " 'Quake Capital',\n",
       " 'Shunwei Capital',\n",
       " 'Kalaari Capital Partners, Qualcomm, 3ONE4 Capital Advisors, UC-RNT',\n",
       " 'SRI Capital',\n",
       " 'Aprameya Radhakrishna, Deepak Natraj, Girish Mathrubootham, Mahesh Murthy, Pallav Nadhani, Pavan Ongole, Sandeep Mathur, Vijay Shekhar Sharma & Others',\n",
       " 'Kalaari Capital, SAIF Partners, Steadview Capital, Sequoia Capital',\n",
       " 'Konglo Ventures, White Unicorn Ventures, LetsVenture',\n",
       " 'BookMyShow',\n",
       " 'Facebook FBStart',\n",
       " 'Bennett, Coleman and Co. Ltd (BCCL)',\n",
       " 'Softbank Ventures Korea, IMM Investment',\n",
       " 'Indian Angel Network (IAN), BEENEXT, The Chennai Angels, Sunil Munjal',\n",
       " 'Kunal Shah, Sandeep Tandon, Nitin Saluja, Gagan Goyal',\n",
       " 'Pankaj Rungta, Yogesh Agarwal',\n",
       " 'Ishan Manaktala',\n",
       " 'Chandigarh Angels, Ashish Gupta, Rohit, Ashish Chand, Sunil Singh & Others',\n",
       " 'Brand Capital, Paragon Trust',\n",
       " 'Sands Capital, IFC, Accel Partners, Flipkart, Sanjiv Rangrass',\n",
       " 'TV Mohandas Pai, V Balakrishnan, PV Srinivasan',\n",
       " 'K2 Capital',\n",
       " 'Anand Chandrasekaran, Rajiv Mehta, Ramakant Sharma',\n",
       " 'Vishal Malik',\n",
       " 'DanGold Investment Corp',\n",
       " 'Marico Innovation Foundation (MIF), Villgro',\n",
       " 'India Nivesh Growth Fund, Sixth Sense, TCI Ventures',\n",
       " 'Jasper Infotech Pvt Ltd',\n",
       " 'Alibaba Pictures',\n",
       " 'Mayfield India, Trifecta Capital',\n",
       " 'Vedanta Capital, William Campbell, Toos N Daruvala',\n",
       " 'Aavya Ventures',\n",
       " 'Vinod Martin, Evan Lim, Kanchan Ghoshal, Ram Kumar Kakani',\n",
       " 'Ronnie Screwvala',\n",
       " 'Zishaan Hayath, Karan Chellani, Mohit Satyan',\n",
       " 'IDG Ventures, Endiya Partners',\n",
       " 'Lohia Group, Andre Hoffman',\n",
       " 'Deutsche Telekom Strategic Investments & Others',\n",
       " 'Vividhity Ventures',\n",
       " 'Blume Ventures, Girish Mathrubootham, Aprameya Radhakrishna',\n",
       " 'Nexus Venture Partners, Blume Ventures',\n",
       " 'Axilor Ventures, Parampara Early Stage Opportunities Fund & Others',\n",
       " 'Harsh V. Pant, Ratheesh Raveendran',\n",
       " 'Nexus Venture Partners, Innoven Capital',\n",
       " 'Quarizon',\n",
       " 'Menterra Social Impact Fund, Unitus Seed Fund',\n",
       " 'Tencent,\\\\\\\\xc2\\\\\\\\xa0 ru-Net, RSI Fund, Thrive Capital',\n",
       " 'India Quotient and others',\n",
       " 'Ajith Nair, Anish K',\n",
       " 'Amajit Gupta, Praveen Dubey, J.P. Bhatt',\n",
       " 'Rajasthan Venture Capital Fund',\n",
       " 'Mumbai Angels Network, Fireside Ventures, Singapore Angel Network',\n",
       " 'Singularity Ventures',\n",
       " 'Indian Angel Network, Native Angels Network',\n",
       " 'Bessemer Venture Partners, Stellaris Venture Partners, Jungle Venture Partners, Axis Capital',\n",
       " 'IvyCap Ventures',\n",
       " 'Umang Moondra',\n",
       " 'Singapore based investor',\n",
       " 'YourNest Fund II',\n",
       " 'CapitalG, Sequoia India',\n",
       " 'India Educational Investment Fund',\n",
       " 'Indochine International',\n",
       " 'Iron Pillar and IIFL, Blume Ventures, Omidyar Network',\n",
       " 'GMO Japan, Neelesh Bhatnagar',\n",
       " 'East Ventures & Others',\n",
       " 'Sharad Sharma, Rajan Anandan,\\\\\\\\xc2\\\\\\\\xa0 Amit Ranjan, Alok Mittal & others',\n",
       " 'Senovo, Unternehmertum Venture Capital, Alexander Bruehl',\n",
       " 'ABM Knowledgeware',\n",
       " 'V Aanand R',\n",
       " 'Rajesh Yohannan, Puthen & Cole',\n",
       " 'Sanjay Mehta & Others ( The Ten Minute Million)',\n",
       " 'The Ten Minute Million',\n",
       " 'Chandigarh Angel Network (CAN)',\n",
       " 'SQue Capital, Grace Capital Ventures, Soham Vencaps',\n",
       " 'DSG Consumer Partners, American Express Ventures, Cyber Carrier VC, AdvantEdge Partners',\n",
       " 'Songhyun Investment',\n",
       " 'GEMS Advisory, Quarizon',\n",
       " 'Franchise India',\n",
       " 'Lakshmi Vilas Bank & undisclosed HNIs',\n",
       " 'Grace Capital Ventures',\n",
       " 'Ajith Sukumaran, Currae Healthtech Fund',\n",
       " 'Eros Labs',\n",
       " 'The Chennai Angels, LetsVenture',\n",
       " 'Investors from Mumbai Angels & LetsVenture',\n",
       " 'Mohan Kumar, V. Balakrishnan',\n",
       " 'Edelweiss Private Equity',\n",
       " 'Venk Krishnan, MJ Aravind, Vikram Kotak, Jayant Davar,\\\\\\\\xc2\\\\\\\\xa0 Ramkumar Nishtal, Arjun Sharmaa',\n",
       " 'Calcutta Angel Network, Appliyifi',\n",
       " 'PayU',\n",
       " 'Kalaari Capital',\n",
       " 'Max Ventures and Industries',\n",
       " 'Unicorn India Ventures',\n",
       " 'Verlinvest SA',\n",
       " 'Axilor, undisclosed investors',\n",
       " 'Siddhartha Gupta, Ashvin Chadha',\n",
       " 'India Quotient, Rajul Garg, Rajesh Yabaji, Chanakya Hridaya, Ramasubramaniam B, Vishwanathan, Nobel House, Sunstone Capital',\n",
       " 'Zodius Technology Opportunities Fund, Matrix Partners',\n",
       " 'FiNC, GHV',\n",
       " 'Lead Angels Network, Anbu Pandian, Prabhakar MR & Others',\n",
       " 'V. Krishna Prasad, Bhupen Shah & Others',\n",
       " 'Swastika Investmart Ltd',\n",
       " 'Digital Financial Service Lab',\n",
       " 'WRV Capital and IndusAge Partners, Infosys Innovation Fund',\n",
       " 'Emerald Media, Premji Invest',\n",
       " 'Sequoia Capital India, North Base Media, Aarin Capital, 3one4 Capital, Axilor Ventures, Kunal Shah, Sandeep Tandon',\n",
       " 'Epsilon Venture Partners',\n",
       " 'KTB Network, SAIF Partners, BEENEXT, Digital Garage',\n",
       " 'Ajith Nair',\n",
       " 'Dr. Apoorv Ranjan Sharma, Anil Jain, Anuj Golecha, Krishna Jhunjhunwala, Anirudh Damani',\n",
       " 'Indian Angel Network, Let\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s Venture',\n",
       " 'Fireside Ventures & Others',\n",
       " 'HCS Venture capital fund',\n",
       " 'Taxmann',\n",
       " 'Kaushal Agarwal, Harminder Sahani, KK Mehra, Pranay Jivrajka, Navjot Saini',\n",
       " 'Ivy League Alumni Angel Network',\n",
       " 'Incubate Fund, Lead Angels Group & Others',\n",
       " 'Pradyumna Dalmia, S. Somasegar & Others',\n",
       " 'Ajay Relan',\n",
       " 'The Chennai Angels, Ritesh Mehta, Aruna Ganesh Ram',\n",
       " 'Sachin Bansal, Binny Bansal',\n",
       " 'Nandan Nilekani',\n",
       " 'Lead Angels, Mumbai Angels, LetsVenture, Girish Mathrubootham, Anbu Pandian',\n",
       " 'CoCreate Ventures',\n",
       " 'RB Investments,\\\\\\\\xc2\\\\\\\\xa0 Kaleden Holdings',\n",
       " 'Kedar Lele, GHV Accelerator',\n",
       " 'Sequoia Capital India, Accel Partners',\n",
       " 'Calcutta Angels Network, LetsVenture, Anupam Mittal, Currae Healthtech Fund',\n",
       " 'Raman Roy, Ashish Gupta, Yogesh Andlay, Vaibhav Jain',\n",
       " '3one4 Capital, Mumbai Angels, Aarin Capital',\n",
       " 'Unilazer Ventures',\n",
       " 'Gati Ltd',\n",
       " 'Aavishkaar Venture Management',\n",
       " 'Ameera Shah, Vivek Bhargava',\n",
       " 'Chandigarh Angels Network',\n",
       " 'A M Sikander',\n",
       " 'IDG Ventures, Accel Partners',\n",
       " 'Justin Kan, Qasar Younis, Paul Bucche, Susa Ventures, Kima Ventures, Axan Venture, SCM Holdings',\n",
       " 'India Quotient',\n",
       " 'ADAG Reliance Private Equity',\n",
       " 'YourNest Angel Fund, iSON',\n",
       " 'Gleevoaz Ventures',\n",
       " 'Arun Seth, T.V. Mohandas Pai, Anand Chandrasekaran, Deepak Ghaisas',\n",
       " 'Kalaari Capital, IDG Ventures India',\n",
       " 'Sequoia India, BEENEXT, Helion Ventures',\n",
       " ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['investor'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc492ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\xc2\\\\\\\\xa0',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace(', \\\\\\\\xc3\\\\\\\\x98',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\n\\\\\\\\n',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\"Kedaraa Capital, Ontario Teachers\\\\\\\\\\'\"','Kedaraa Capital, Ontario Teachers'))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\xc3\\\\\\\\xa9',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99O',''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9dd36b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Tiger Global Management\n",
       "1               Susquehanna Growth Equity\n",
       "2                         Sequoia Capital\n",
       "3                          Vinod Khatumal\n",
       "4                 Sprout Venture Partners\n",
       "                      ...                \n",
       "3039          Asia Pacific Internet Group\n",
       "3040                       KARSEMVEN Fund\n",
       "3041       Exfinity Fund, GrowX Ventures.\n",
       "3042                           MakeMyTrip\n",
       "3043    UK based Group of Angel Investors\n",
       "Name: investor, Length: 3044, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['investor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee81e3",
   "metadata": {},
   "source": [
    "# investment_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8fbe9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Private Equity Round',\n",
       " 'Series C',\n",
       " 'Series B',\n",
       " 'Pre-series A',\n",
       " 'Seed Round',\n",
       " 'Series A',\n",
       " 'Series D',\n",
       " 'Seed',\n",
       " 'Series F',\n",
       " 'Series E',\n",
       " 'Debt Funding',\n",
       " 'Series G',\n",
       " 'Series H',\n",
       " 'Venture',\n",
       " 'Seed Funding',\n",
       " 0,\n",
       " 'Funding Round',\n",
       " 'Corporate Round',\n",
       " 'Maiden Round',\n",
       " 'pre-series A',\n",
       " 'Seed Funding Round',\n",
       " 'Single Venture',\n",
       " 'Venture Round',\n",
       " 'Pre-Series A',\n",
       " 'Angel',\n",
       " 'Series J',\n",
       " 'Angel Round',\n",
       " 'pre-Series A',\n",
       " 'Venture - Series Unknown',\n",
       " 'Bridge Round',\n",
       " 'Private Equity',\n",
       " 'Debt and Preference capital',\n",
       " 'Inhouse Funding',\n",
       " 'Seed/ Angel Funding',\n",
       " 'Debt',\n",
       " 'Pre Series A',\n",
       " 'Equity',\n",
       " 'Debt-Funding',\n",
       " 'Mezzanine',\n",
       " 'Series B (Extension)',\n",
       " 'Equity Based Funding',\n",
       " 'Private Funding',\n",
       " 'Seed / Angel Funding',\n",
       " 'Seed/Angel Funding',\n",
       " 'Seed funding',\n",
       " 'Seed / Angle Funding',\n",
       " 'Angel / Seed Funding',\n",
       " 'Private',\n",
       " 'Structured Debt',\n",
       " 'Term Loan',\n",
       " 'PrivateEquity',\n",
       " 'Angel Funding',\n",
       " 'Seed\\\\\\\\nFunding',\n",
       " 'Private\\\\\\\\nEquity',\n",
       " 'Crowd funding',\n",
       " 'Crowd Funding']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['investment_type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f5f2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['investment_type']=df['investment_type'].apply(lambda x:str(x).replace('\\\\\\\\n',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5446ca52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Private Equity Round\n",
       "1                   Series C\n",
       "2                   Series B\n",
       "3               Pre-series A\n",
       "4                 Seed Round\n",
       "                ...         \n",
       "3039          Private Equity\n",
       "3040          Private Equity\n",
       "3041          Private Equity\n",
       "3042          Private Equity\n",
       "3043            Seed Funding\n",
       "Name: investment_type, Length: 3044, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['investment_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f6c98",
   "metadata": {},
   "source": [
    "# vacant values removal sensibly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5806e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d73a10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3043 entries, 0 to 3043\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             3043 non-null   datetime64[ns]\n",
      " 1   startup          3043 non-null   object        \n",
      " 2   vertical         3043 non-null   object        \n",
      " 3   subvertical      3043 non-null   object        \n",
      " 4   location         3043 non-null   object        \n",
      " 5   investor         3043 non-null   object        \n",
      " 6   investment_type  3043 non-null   object        \n",
      " 7   amount           3043 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(6)\n",
      "memory usage: 214.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "34bbb2c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23060\\2158884128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'investor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'&'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "sorted(set(df['investor'].str.split(',').str.split('&').sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ce62018c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hevo Data', 'Smart Karma', 'iCrushiFlush'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['investor']=='IDG Ventures India']['startup'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ec38f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>startup</th>\n",
       "      <th>vertical</th>\n",
       "      <th>subvertical</th>\n",
       "      <th>location</th>\n",
       "      <th>investor</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>Private Equity Round</td>\n",
       "      <td>1630.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Susquehanna Growth Equity</td>\n",
       "      <td>Series C</td>\n",
       "      <td>65.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Series B</td>\n",
       "      <td>149.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>Pre-series A</td>\n",
       "      <td>24.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>14.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Uniphore</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>Speech Recognition</td>\n",
       "      <td>Taramani</td>\n",
       "      <td>March Capital Partners</td>\n",
       "      <td>Series C</td>\n",
       "      <td>310.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>Daalchini Technologies</td>\n",
       "      <td>Food and Beverage</td>\n",
       "      <td>Digital Vending Machine</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Artha Venture</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>4.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>Education</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Qatar Investment Authority</td>\n",
       "      <td>Private Equity Round</td>\n",
       "      <td>1222.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>Moglix</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Industrial Tools and Equipments</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Composite Capital Management, Sequoia Capital ...</td>\n",
       "      <td>Series D</td>\n",
       "      <td>489.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>Ezyhaul</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Series B</td>\n",
       "      <td>130.432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                 startup                 vertical  \\\n",
       "0  2020-09-01                  Byju's                  Ed-Tech   \n",
       "1  2020-01-13                  Shuttl           Transportation   \n",
       "2  2020-09-01               MamaEarth                eCommerce   \n",
       "3  2020-02-01         wealthbucket.in                  FinTech   \n",
       "4  2020-02-01                  Fashor      Fashion and Apparel   \n",
       "..        ...                     ...                      ...   \n",
       "65 2019-01-07                Uniphore  Artificial Intelligence   \n",
       "66 2019-04-07  Daalchini Technologies        Food and Beverage   \n",
       "67 2019-10-07                  Byju's                  Ed-Tech   \n",
       "68 2019-11-07                  Moglix                eCommerce   \n",
       "69 2019-10-07                 Ezyhaul                     Tech   \n",
       "\n",
       "                              subvertical   location  \\\n",
       "0                              E-learning  Bengaluru   \n",
       "1               App based shuttle service    Gurgaon   \n",
       "2   Retailer of baby and toddler products  Bengaluru   \n",
       "3                       Online Investment  New Delhi   \n",
       "4             Embroiled Clothes For Women     Mumbai   \n",
       "..                                    ...        ...   \n",
       "65                     Speech Recognition   Taramani   \n",
       "66                Digital Vending Machine  New Delhi   \n",
       "67                              Education  Bengaluru   \n",
       "68        Industrial Tools and Equipments  Singapore   \n",
       "69                              Logistics  Singapore   \n",
       "\n",
       "                                             investor       investment_type  \\\n",
       "0                             Tiger Global Management  Private Equity Round   \n",
       "1                           Susquehanna Growth Equity              Series C   \n",
       "2                                     Sequoia Capital              Series B   \n",
       "3                                      Vinod Khatumal          Pre-series A   \n",
       "4                             Sprout Venture Partners            Seed Round   \n",
       "..                                                ...                   ...   \n",
       "65                             March Capital Partners              Series C   \n",
       "66                                      Artha Venture            Seed Round   \n",
       "67                         Qatar Investment Authority  Private Equity Round   \n",
       "68  Composite Capital Management, Sequoia Capital ...              Series D   \n",
       "69                                        Undisclosed              Series B   \n",
       "\n",
       "      amount  \n",
       "0   1630.400  \n",
       "1     65.611  \n",
       "2    149.661  \n",
       "3     24.456  \n",
       "4     14.674  \n",
       "..       ...  \n",
       "65   310.428  \n",
       "66     4.076  \n",
       "67  1222.800  \n",
       "68   489.120  \n",
       "69   130.432  \n",
       "\n",
       "[70 rows x 8 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e7167911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Composite Capital Management, Sequoia Capital India, Tiger Global Management'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[68].investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4d359bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Tiger Global Management\n",
       "1               Susquehanna Growth Equity\n",
       "2                         Sequoia Capital\n",
       "3                          Vinod Khatumal\n",
       "4                 Sprout Venture Partners\n",
       "                      ...                \n",
       "3039          Asia Pacific Internet Group\n",
       "3040                       KARSEMVEN Fund\n",
       "3041       Exfinity Fund, GrowX Ventures.\n",
       "3042                           MakeMyTrip\n",
       "3043    UK based Group of Angel Investors\n",
       "Name: investor, Length: 3043, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['investor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4961cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c525c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d222ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleandata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dec77290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>investor</th>\n",
       "      <th>date</th>\n",
       "      <th>startup</th>\n",
       "      <th>vertical</th>\n",
       "      <th>subvertical</th>\n",
       "      <th>location</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>1630.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Susquehanna Growth Equity LLC</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Series C</td>\n",
       "      <td>65.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Series B</td>\n",
       "      <td>149.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>24.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>14.674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column                       investor        date          startup  \\\n",
       "0       0        Tiger Global Management  2020-01-09           Byju's   \n",
       "1       1  Susquehanna Growth Equity LLC  2020-01-13           Shuttl   \n",
       "2       2                Sequoia Capital  2020-01-09        MamaEarth   \n",
       "3       3                 Vinod Khatumal  2020-01-02  wealthbucket.in   \n",
       "4       4        Sprout Venture Partners  2020-01-02           Fashor   \n",
       "\n",
       "              vertical                            subvertical   location  \\\n",
       "0              Ed-Tech                             E-learning  Bengaluru   \n",
       "1       Transportation              App based shuttle service    Gurgaon   \n",
       "2            eCommerce  Retailer of baby and toddler products  Bengaluru   \n",
       "3              FinTech                      Online Investment  New Delhi   \n",
       "4  Fashion and Apparel            Embroiled Clothes For Women     Mumbai   \n",
       "\n",
       "  investment_type    amount  \n",
       "0  Private Equity  1630.400  \n",
       "1        Series C    65.611  \n",
       "2        Series B   149.661  \n",
       "3    Pre-Series A    24.456  \n",
       "4      Seed Round    14.674  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27591299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6111, 9)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ae43216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6111 entries, 0 to 6110\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Column           6111 non-null   int64  \n",
      " 1   investor         6111 non-null   object \n",
      " 2   date             6111 non-null   object \n",
      " 3   startup          6111 non-null   object \n",
      " 4   vertical         6111 non-null   object \n",
      " 5   subvertical      6111 non-null   object \n",
      " 6   location         6111 non-null   object \n",
      " 7   investment_type  6111 non-null   object \n",
      " 8   amount           6111 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 429.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e9b7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=pd.to_datetime(df['date'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7fced8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6111 entries, 0 to 6110\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Column           6111 non-null   int64         \n",
      " 1   investor         6111 non-null   object        \n",
      " 2   date             6111 non-null   datetime64[ns]\n",
      " 3   startup          6111 non-null   object        \n",
      " 4   vertical         6111 non-null   object        \n",
      " 5   subvertical      6111 non-null   object        \n",
      " 6   location         6111 non-null   object        \n",
      " 7   investment_type  6111 non-null   object        \n",
      " 8   amount           6111 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(6)\n",
      "memory usage: 429.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18b6580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Column'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "126ff8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6111 entries, 0 to 6110\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   investor         6111 non-null   object        \n",
      " 1   date             6111 non-null   datetime64[ns]\n",
      " 2   startup          6111 non-null   object        \n",
      " 3   vertical         6111 non-null   object        \n",
      " 4   subvertical      6111 non-null   object        \n",
      " 5   location         6111 non-null   object        \n",
      " 6   investment_type  6111 non-null   object        \n",
      " 7   amount           6111 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(6)\n",
      "memory usage: 382.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16898dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\xa0',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a67b523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investor</th>\n",
       "      <th>date</th>\n",
       "      <th>startup</th>\n",
       "      <th>vertical</th>\n",
       "      <th>subvertical</th>\n",
       "      <th>location</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>1630.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Susquehanna Growth Equity LLC</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Series C</td>\n",
       "      <td>65.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Series B</td>\n",
       "      <td>149.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>24.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>14.674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        investor       date          startup  \\\n",
       "0        Tiger Global Management 2020-01-09           Byju's   \n",
       "1  Susquehanna Growth Equity LLC 2020-01-13           Shuttl   \n",
       "2                Sequoia Capital 2020-01-09        MamaEarth   \n",
       "3                 Vinod Khatumal 2020-01-02  wealthbucket.in   \n",
       "4        Sprout Venture Partners 2020-01-02           Fashor   \n",
       "\n",
       "              vertical                            subvertical   location  \\\n",
       "0              Ed-Tech                             E-learning  Bengaluru   \n",
       "1       Transportation              App based shuttle service    Gurgaon   \n",
       "2            eCommerce  Retailer of baby and toddler products  Bengaluru   \n",
       "3              FinTech                      Online Investment  New Delhi   \n",
       "4  Fashion and Apparel            Embroiled Clothes For Women     Mumbai   \n",
       "\n",
       "  investment_type    amount  \n",
       "0  Private Equity  1630.400  \n",
       "1        Series C    65.611  \n",
       "2        Series B   149.661  \n",
       "3    Pre-Series A    24.456  \n",
       "4      Seed Round    14.674  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "950e10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['date','startup','vertical','subvertical','location','investor','investment_type','amount']\n",
    "df=df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e805edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>startup</th>\n",
       "      <th>vertical</th>\n",
       "      <th>subvertical</th>\n",
       "      <th>location</th>\n",
       "      <th>investor</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>1630.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Susquehanna Growth Equity LLC</td>\n",
       "      <td>Series C</td>\n",
       "      <td>65.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Series B</td>\n",
       "      <td>149.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>24.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>14.674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date          startup             vertical  \\\n",
       "0 2020-01-09           Byju's              Ed-Tech   \n",
       "1 2020-01-13           Shuttl       Transportation   \n",
       "2 2020-01-09        MamaEarth            eCommerce   \n",
       "3 2020-01-02  wealthbucket.in              FinTech   \n",
       "4 2020-01-02           Fashor  Fashion and Apparel   \n",
       "\n",
       "                             subvertical   location  \\\n",
       "0                             E-learning  Bengaluru   \n",
       "1              App based shuttle service    Gurgaon   \n",
       "2  Retailer of baby and toddler products  Bengaluru   \n",
       "3                      Online Investment  New Delhi   \n",
       "4            Embroiled Clothes For Women     Mumbai   \n",
       "\n",
       "                        investor investment_type    amount  \n",
       "0        Tiger Global Management  Private Equity  1630.400  \n",
       "1  Susquehanna Growth Equity LLC        Series C    65.611  \n",
       "2                Sequoia Capital        Series B   149.661  \n",
       "3                 Vinod Khatumal    Pre-Series A    24.456  \n",
       "4        Sprout Venture Partners      Seed Round    14.674  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c79eeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['021 Capita',\n",
       " '100 Co-founders Lab',\n",
       " '122 West Ventures',\n",
       " '1Crowd',\n",
       " '1Crowd (through crowd funding)',\n",
       " '3one4 Capital',\n",
       " '3one4 Capital Advisors LLP',\n",
       " '500 Startups',\n",
       " '50K Ventures',\n",
       " '91SpringBoard',\n",
       " '91maker.com',\n",
       " 'A M Sik',\n",
       " 'A91 Partners',\n",
       " 'AB Kinnevik',\n",
       " 'ABB Technology Ventures',\n",
       " 'ABCOM Investments',\n",
       " 'ABI-Showatech (India) Ltd',\n",
       " 'ABM Knowledgeware',\n",
       " 'ADAG Reliance Private Equity',\n",
       " 'AECAL',\n",
       " 'AET Fund',\n",
       " 'AJ Ventures',\n",
       " 'AL Nour International Holdings',\n",
       " 'ANI Technologies Pvt. Ltd',\n",
       " 'APIS Partners',\n",
       " 'ASK Pravi',\n",
       " 'ASP Consulting',\n",
       " 'AV Thomas Group',\n",
       " 'AVG Group',\n",
       " 'AVN Business Solutions',\n",
       " 'Aakrit Vaish',\n",
       " 'Aamir Khan',\n",
       " 'Aarin Capital',\n",
       " 'Aarti Group',\n",
       " 'Aaruha Technology Fund',\n",
       " 'Aavishkaar',\n",
       " 'Aavishkaar Venture Management',\n",
       " 'Aavya Ventures',\n",
       " 'Abaran Deep',\n",
       " 'Abhai S. Rao',\n",
       " 'Abhay Singhal',\n",
       " 'Abhijit Avasthi',\n",
       " 'Abhijit Bh',\n",
       " 'Abhinav Bindra',\n",
       " 'Abhinav Gupta',\n",
       " 'Abhinav Mathur',\n",
       " 'Abhinav Patodia',\n",
       " 'Abhinav Sinha',\n",
       " 'Abhishek Acharya',\n",
       " 'Abhishek Agarwal',\n",
       " 'Abhishek Bhatewara',\n",
       " 'Abhishek Goyal',\n",
       " 'Abhishek Gupta',\n",
       " 'Abhishek Jain',\n",
       " 'Abraaj Group',\n",
       " 'Abstract Ventures',\n",
       " 'Abu Farhan Azmi',\n",
       " 'Accel Partners',\n",
       " 'Accion',\n",
       " 'Accion Venture Labs',\n",
       " 'Ackermans',\n",
       " 'Actis',\n",
       " 'Acumen Fund',\n",
       " 'Adam DAngelo',\n",
       " 'Adi Saravanan',\n",
       " 'Adil Allana',\n",
       " 'Aditya Agarwal',\n",
       " 'Aditya Dev Sood',\n",
       " 'Aditya Malik',\n",
       " 'Aditya Singh',\n",
       " 'Aditya Vazirani',\n",
       " 'Aditya Verma',\n",
       " 'Aditya Vij',\n",
       " 'AdvantEdge Partners',\n",
       " 'Adveq Management',\n",
       " 'Aegon NV',\n",
       " 'Aequs Group',\n",
       " 'Afsal Salu',\n",
       " 'Agarwal Movers Group',\n",
       " 'Agnus Capital',\n",
       " 'Aijaz Saleem',\n",
       " 'Ajai Chowdhry',\n",
       " 'Ajay Bhatia',\n",
       " 'Ajay Data',\n",
       " 'Ajay Lakhotia',\n",
       " 'Ajay Modani',\n",
       " 'Ajay Nanavati',\n",
       " 'Ajay Piramal',\n",
       " 'Ajay Relan',\n",
       " 'Ajay Sarupria',\n",
       " 'Ajeet Khurana',\n",
       " 'Ajeet Khurana Jinesh Shah',\n",
       " 'Ajit Surana',\n",
       " 'Ajith Nair',\n",
       " 'Ajith Sukumaran',\n",
       " 'Ajmera Group of Companies',\n",
       " 'Akash Bhavsar',\n",
       " 'Akash Garg',\n",
       " 'Akatsuki',\n",
       " 'Akusa Holdings',\n",
       " 'Al Dhaheri family',\n",
       " 'Al Nour',\n",
       " 'Alagu Periyannan',\n",
       " 'Alex',\n",
       " 'Alex Chua',\n",
       " 'Alex Kuruvilla',\n",
       " 'Alfa Capital',\n",
       " 'Alibaba',\n",
       " 'Alibaba Group',\n",
       " 'Alibaba Pictures',\n",
       " 'Allcargo Logistics',\n",
       " 'Allen Blue',\n",
       " 'Alok Bajpai',\n",
       " 'Alok Divatia',\n",
       " 'Alok Goel',\n",
       " 'Alok Mittal',\n",
       " 'Alok Rawat',\n",
       " 'Alok Sharma',\n",
       " 'Alok Srivastava',\n",
       " 'Alpha Capital',\n",
       " 'Alphabet growth investment arm Capital G',\n",
       " 'Alphard Maritime Group',\n",
       " 'Alteria Capital',\n",
       " 'Altimeter Capital',\n",
       " 'Alto Partners',\n",
       " 'Amadeus Capital',\n",
       " 'Amajit Gupta',\n",
       " 'Amanpreet Bajaj',\n",
       " 'Amar Arsikere',\n",
       " 'Amarpreet Sawhney',\n",
       " 'Amaya Capital LLP',\n",
       " 'Amazon',\n",
       " 'Amazon Alexa Fund',\n",
       " 'Amazon Inc.',\n",
       " 'Amazon-Patni JV',\n",
       " 'Ambarish Gupta',\n",
       " 'Ambarish Ray',\n",
       " 'Ambi Parameswaran',\n",
       " 'Ambiga Dhiraj',\n",
       " 'Ambit Pragma',\n",
       " 'Ameera Shah',\n",
       " 'Amen Dhyllon',\n",
       " 'Amereus Group',\n",
       " 'American Express Ventures',\n",
       " 'Amicus Capital',\n",
       " 'Amit Agrawal',\n",
       " 'Amit Banati',\n",
       " 'Amit Banka',\n",
       " 'Amit Bhatiani',\n",
       " 'Amit Burman',\n",
       " 'Amit Choudhary',\n",
       " 'Amit Dey',\n",
       " 'Amit Gupta',\n",
       " 'Amit Jindal',\n",
       " 'Amit Khanna',\n",
       " 'Amit Khanna (LetsVenture)',\n",
       " 'Amit Kharb',\n",
       " 'Amit Manocha',\n",
       " 'Amit Nagar',\n",
       " 'Amit Nanavati',\n",
       " 'Amit Patni',\n",
       " 'Amit Ranjan',\n",
       " 'Amit Rathore',\n",
       " 'Amit S',\n",
       " 'Amit Singhal',\n",
       " 'Amit Sinha',\n",
       " 'Amit Tyagi',\n",
       " 'Amitpal Bhutani',\n",
       " 'Amiya Pathak',\n",
       " 'Amod Malviya',\n",
       " 'Amour Infrastructure',\n",
       " 'Amrendra Reddy',\n",
       " 'Amrish Kumar',\n",
       " 'Amrish Rau',\n",
       " 'Amrish Rau from PayU India',\n",
       " 'An',\n",
       " 'Ananth Narayanan',\n",
       " 'Anbu P',\n",
       " 'Andre Hoffman',\n",
       " 'Aneesh Reddy',\n",
       " 'Aneesh Seth',\n",
       " 'Angel investors',\n",
       " 'AngelList',\n",
       " 'AngelPrime',\n",
       " 'Angie Mahtaney',\n",
       " 'Anglian Omega Network',\n",
       " 'Anicut Capital',\n",
       " 'Anil Advani',\n",
       " 'Anil Chopra',\n",
       " 'Anil Gelra',\n",
       " 'Anil Jaggia',\n",
       " 'Anil Jain',\n",
       " 'Anil Matai',\n",
       " 'Anil Menon',\n",
       " 'Anindya Ghose',\n",
       " 'Anirudh Damani',\n",
       " 'Anirudh Rastogi',\n",
       " 'Anirudh Sheth',\n",
       " 'Anish K',\n",
       " 'Anisha Mittal',\n",
       " 'Anita Dongre',\n",
       " 'Anita Gupta',\n",
       " 'Anita Hassan',\n",
       " 'Anjali Bansal',\n",
       " 'Anjani Prasad',\n",
       " 'Ankit Aditya',\n",
       " 'Ankit Bhati',\n",
       " 'Ankit Gupta',\n",
       " 'Ankit Kesarwani',\n",
       " 'Ankit Maheshwari',\n",
       " 'Ankit Nagori',\n",
       " 'Ankit Sharma',\n",
       " 'Ankur Capital',\n",
       " 'Ankur Gupta',\n",
       " 'Ankur Singla',\n",
       " 'Ankur Warikoo',\n",
       " 'Ankush Gupta',\n",
       " 'Ankush Mehta',\n",
       " 'Ankush Nijhawan',\n",
       " 'Ankush Saigal',\n",
       " 'Annuity Association (TIAA)',\n",
       " 'Anoop Goyal',\n",
       " 'Anoop Hingorani',\n",
       " 'Anshoo Gaur',\n",
       " 'Anshu Bahadur',\n",
       " 'Anshu Sharma',\n",
       " 'Anshul Jindal',\n",
       " 'Anshuman Das',\n",
       " 'Ant Financial',\n",
       " 'Anthil Ventures',\n",
       " 'Anthill Scale Ventures',\n",
       " 'Anubhav Verma',\n",
       " 'Anuj Agrawal',\n",
       " 'Anuj Golecha',\n",
       " 'Anuj Gupta',\n",
       " 'Anuj Puri',\n",
       " 'Anuj Sanghi',\n",
       " 'Anuj Srivastava',\n",
       " 'Anupam Mittal',\n",
       " 'Anupam Tyagi',\n",
       " 'Anurag Chauhan',\n",
       " 'Anurag Gupta',\n",
       " 'Anurag Srivastava',\n",
       " 'Aparup Sengupta',\n",
       " 'Apoletto',\n",
       " 'Apoletto Managers',\n",
       " 'Apoorva Patni',\n",
       " 'Appliyifi',\n",
       " 'Aprameya',\n",
       " 'Aprameya Radhakrishnan',\n",
       " 'Apurva Chamaria',\n",
       " 'Apurva Salapuria',\n",
       " 'Aqeel Ahmed',\n",
       " 'Aramex Ventures Llc',\n",
       " 'Arathi Krishna',\n",
       " 'Aravind Sanka',\n",
       " 'Arena Ventures',\n",
       " 'Arihant Patni of Patni Family Office',\n",
       " 'Arjun H',\n",
       " 'Arjun Malhotra',\n",
       " 'Arjun Mehta',\n",
       " 'Arjun Sharmaa',\n",
       " 'Arkas Industries',\n",
       " 'Arpan Nagdeve',\n",
       " 'Artesian Venture Partners',\n",
       " 'Artha India Ventures',\n",
       " 'Artha Initiatives',\n",
       " 'Artha Venture',\n",
       " 'Arthavida Ventures',\n",
       " 'Artiman Ventures',\n",
       " 'Arts Alliance',\n",
       " 'Arun Ch',\n",
       " 'Arun Garg',\n",
       " 'Arun Khanna',\n",
       " 'Arun Malhotra',\n",
       " 'Arun Patodia',\n",
       " 'Arun Sarin',\n",
       " 'Arun Seth',\n",
       " 'Arun Tadanki',\n",
       " 'Arun Venkatachalam',\n",
       " 'Aruna Ganesh Ram',\n",
       " 'Arvind Jha',\n",
       " 'Arvind Uppal',\n",
       " 'Ascent Capital',\n",
       " 'Aseem Sood',\n",
       " 'Aseem Vadehra',\n",
       " 'Ash Bhardwaj',\n",
       " 'Asha Jadeja Motwani',\n",
       " 'Ashim Mehra',\n",
       " 'Ashish Agrawal',\n",
       " 'Ashish Ch',\n",
       " 'Ashish Dev Kapur',\n",
       " 'Ashish Dhawan',\n",
       " 'Ashish Goenka',\n",
       " 'Ashish Gupta',\n",
       " 'Ashish Hemrajani',\n",
       " 'Ashish Jhalani',\n",
       " 'Ashish Kacholi',\n",
       " 'Ashish Lakhanpal',\n",
       " 'Ashish Mahajan',\n",
       " 'Ashish Todi',\n",
       " 'Ashish Toshniwal',\n",
       " 'Ashish Tulsian',\n",
       " 'Ashneer Grover',\n",
       " 'Ashok Agarwal',\n",
       " 'Ashok Kumar Gajera',\n",
       " 'Ashutosh Lawania',\n",
       " 'Ashvin Chadha',\n",
       " 'Asian Healthcare fund',\n",
       " 'AskMe',\n",
       " 'Aspada',\n",
       " 'Aspada Advisors',\n",
       " 'Aspada Investment Advisors',\n",
       " 'Aspada Ventures',\n",
       " 'Aspire Logistics LLC',\n",
       " 'Aspire Systems',\n",
       " 'Asset Management (Asia) Ltd',\n",
       " 'Astarc Ventures',\n",
       " 'Asuka',\n",
       " 'Asuka Holdings',\n",
       " 'Atul Agarwal',\n",
       " 'Atul Goel',\n",
       " 'Atul Gupta',\n",
       " 'Atul Ingle',\n",
       " 'Atul Jain',\n",
       " 'Atul Jalan',\n",
       " 'Atul Nishar',\n",
       " 'Atul Phadnis',\n",
       " 'Atulya Mittal',\n",
       " 'Augment Ventures',\n",
       " 'Auxano Deals',\n",
       " 'Avendus Finance Pvt. Ltd',\n",
       " 'Avnish Mehra',\n",
       " 'Avtar Monga',\n",
       " 'Axan Partners',\n",
       " 'Axan Venture',\n",
       " 'Axiata Digital',\n",
       " 'Axilor',\n",
       " 'Axilor Ventures',\n",
       " 'Axis Bank',\n",
       " 'Axis Capital',\n",
       " 'Axon Partners',\n",
       " 'Ayesha Takia Azmi',\n",
       " 'Ayushmann Khurana',\n",
       " 'Azim Premji',\n",
       " 'Azmul Haque',\n",
       " 'B Capital',\n",
       " 'B Capital Group',\n",
       " 'B M Gupta',\n",
       " 'B S Nagesh',\n",
       " 'BAC Acquisitions',\n",
       " 'BCCL',\n",
       " 'BLIP Initiatives',\n",
       " 'BRD Securities',\n",
       " 'BVR Mohan Reddy',\n",
       " 'Badal Malick',\n",
       " 'Baillie Gifford',\n",
       " 'Balaji Prabhakar',\n",
       " 'Balamurali Krishna',\n",
       " 'Balamurugan Mani',\n",
       " 'Balasubramanian Krishnamurthy',\n",
       " 'Bamboo Capital Partners',\n",
       " 'Bank to the Future',\n",
       " 'Barkawi Holdings GmbH',\n",
       " 'Basab Pradhan',\n",
       " 'Base of Pyramid Asia (BOPA) Pte Ltd',\n",
       " 'Baskar Subramanian',\n",
       " 'Batlivala',\n",
       " 'Battery Road Digital Holdings LLC',\n",
       " 'Bay Capital Investments',\n",
       " 'Bedrock Ventures',\n",
       " 'Beehive Capital Advisor',\n",
       " 'Beenext Ventures',\n",
       " 'Beenextan investment fund',\n",
       " 'Beenos',\n",
       " 'Beenos Asia',\n",
       " 'Beerud Sheth',\n",
       " 'Behram Vakil',\n",
       " 'Bennett',\n",
       " 'Bennett Coleman',\n",
       " 'Benori Ventures LLP',\n",
       " 'Berggruen Holdings',\n",
       " 'Bertelsmann India Investments',\n",
       " 'Bessemer Venture Partners',\n",
       " 'Best Foodworks',\n",
       " 'BetOnIndia Technology Pvt Ltd',\n",
       " 'Better Capital AngelList syndicate.',\n",
       " 'Betty Moore Foundation',\n",
       " 'Bhairavi Jani',\n",
       " 'Bhanu Vikram Parsotam',\n",
       " 'Bharanidharan Viswanathan',\n",
       " 'Bharat Gupta',\n",
       " 'Bharat Innovation',\n",
       " 'Bharat Kedia',\n",
       " 'Bharat Sheth',\n",
       " 'Bharat Vijay',\n",
       " 'Bharath',\n",
       " 'Bharti Enterprises',\n",
       " 'Bhavdeep Reddy',\n",
       " 'Bhavesh Manglani',\n",
       " 'Bhavesh P',\n",
       " 'Bhavin Turakhia',\n",
       " 'Bhavish Aggarwal',\n",
       " 'Bhupen Shah',\n",
       " 'Bhupender Singh',\n",
       " 'Big Data Investments B.V',\n",
       " 'Bijou Kurien',\n",
       " 'Bijoy George',\n",
       " 'Bill',\n",
       " 'Binny Bansal',\n",
       " 'BitChemy Ventures',\n",
       " 'Bitkemy Ventures',\n",
       " 'Biz Stone',\n",
       " 'BizReach',\n",
       " 'BlackJag Partners',\n",
       " 'BlackSoil Capital Pvt Ltd',\n",
       " 'Blacksoil',\n",
       " 'Blackstone Valley Group',\n",
       " 'Blinc Advisors',\n",
       " 'Blue Cloud Ventures',\n",
       " 'Blue Fog Capital',\n",
       " 'BlueOrchard Finance Ltd',\n",
       " 'Blume Ventures',\n",
       " 'Bobby Reddy',\n",
       " 'Bodhtree Consulting Limited',\n",
       " 'Boillot Family Trust',\n",
       " 'Bold Ventures',\n",
       " 'Boman Irani',\n",
       " 'BookMyShow',\n",
       " 'Boost VC',\n",
       " 'Br',\n",
       " 'BrahmaX Ventures',\n",
       " 'Bravia Capital',\n",
       " 'Breakthrough Energy Ventures',\n",
       " 'Bren Corporation',\n",
       " 'Brian Acton',\n",
       " 'Brigade Innovations LLP',\n",
       " 'British',\n",
       " 'Broadbean Capital services',\n",
       " 'Burda Principal Investments',\n",
       " 'Business Acceleration (CIBA)',\n",
       " 'ByteDance',\n",
       " 'C31 Ventures',\n",
       " 'C4D Partners',\n",
       " 'CASHurDRIVE Marketing Pvt Ltd',\n",
       " 'CBA Capital',\n",
       " 'CCavenue',\n",
       " 'CCube Angels',\n",
       " 'CDC Group Plc',\n",
       " 'CIO Angel Network (CAN)',\n",
       " 'CLP Holdings Group',\n",
       " 'CLSA Capital Partners ARIA IV Funds',\n",
       " 'CMYK Health Boutique Pvt Ltd',\n",
       " 'CP Bothra',\n",
       " 'CRV',\n",
       " 'CSC Upshot',\n",
       " 'Calcutta Angels Network (CAN)',\n",
       " 'Cameron Jones',\n",
       " 'Canaan Partners',\n",
       " 'Cao Yibin',\n",
       " 'Capier Investments',\n",
       " 'Capillary Technologies',\n",
       " 'Capital',\n",
       " 'Capital Advisers',\n",
       " 'CapitalG',\n",
       " 'Capricorn Investment Group',\n",
       " 'CareerNet Consulting Pvt. Ltd',\n",
       " 'Carlyle Group',\n",
       " 'Carpediem Capital',\n",
       " 'Carrick Capital Partners',\n",
       " 'Caspian',\n",
       " 'Cataraman Ventures',\n",
       " 'Centre for Innovation Incubation',\n",
       " 'CerraCap',\n",
       " 'Ch',\n",
       " 'Chan Zuckerberg Initiative',\n",
       " 'Chanakya Hridaya',\n",
       " 'Chandigarh Angels Network',\n",
       " 'Chatsworth Management',\n",
       " 'Chavi Jafa',\n",
       " 'Cheetah Mobile',\n",
       " 'Cherry Tin',\n",
       " 'Chetan Bhagat',\n",
       " 'Chicago Capital Ventures',\n",
       " 'Chidambaram Palaniappan',\n",
       " 'China Lodging Group',\n",
       " 'China-based CITIC Capital',\n",
       " 'Chirag Nikunj Sheth',\n",
       " 'Chiratae Ventures (formerly IDG Ventures)',\n",
       " 'ChrysCapital',\n",
       " 'Cipher-Plexus Capital Advisors',\n",
       " 'Cisco Investments',\n",
       " 'Cisco Ventures',\n",
       " 'Cismat Cargo Services Pvt. Ltd.',\n",
       " 'Citi Ventures',\n",
       " 'Citrus Payments',\n",
       " 'Clairvest Group',\n",
       " 'Claris Capital',\n",
       " 'Co',\n",
       " 'Co Pvt Ltd',\n",
       " 'Co. Ltd',\n",
       " 'Co. Ltd (BCCL)',\n",
       " 'CoCreate Ventures',\n",
       " 'Coatue Management',\n",
       " 'Cole',\n",
       " 'Coleman',\n",
       " 'Collaborative Licensing Ventures LLP',\n",
       " 'Commonfloor',\n",
       " 'Company Ltd (BCCL)',\n",
       " 'Composite Capital Management',\n",
       " 'Concur Technologies',\n",
       " 'Constellation Technology Ventures (Exelon Corporation)',\n",
       " 'Contrarian Capital',\n",
       " 'Contrarian Vriddhi Fund',\n",
       " 'Cooperative Oikocredit',\n",
       " 'Corvus Ventures',\n",
       " 'Costanoa',\n",
       " 'Cota Capital',\n",
       " 'Creation Investments Capital Management',\n",
       " 'Credence Family Office',\n",
       " 'Credika',\n",
       " 'Cross Border Angels',\n",
       " 'Ctrip.com International Ltd',\n",
       " 'CureFit',\n",
       " 'Currae Healthtech Fund',\n",
       " 'Cyber Carrier',\n",
       " 'CyberAgent Ventures',\n",
       " 'DAH Beteiligungs GmbH',\n",
       " 'DG Daiwa Ventures',\n",
       " 'DG Incubation',\n",
       " 'DG Ventures India',\n",
       " 'DHI Group Inc',\n",
       " 'DIG Investment Ab',\n",
       " 'DMG information Asia Pacific',\n",
       " 'DMI Finance',\n",
       " 'DSG Consumer Partners',\n",
       " 'DST Global',\n",
       " 'DST Partners',\n",
       " 'DTDC Express Ltd',\n",
       " 'Daffodil Software',\n",
       " 'Dalip Pathak',\n",
       " 'Daljit Singh',\n",
       " 'Daman Soni',\n",
       " 'DanGold Investment Corp',\n",
       " 'Darius P',\n",
       " 'Darrin Capital',\n",
       " 'Darshak Shah',\n",
       " 'Darshan Upadhyay',\n",
       " 'Das Capital',\n",
       " 'Daud Ali',\n",
       " 'DeVry Inc',\n",
       " 'Deep Kalra',\n",
       " 'Deepak Chokhani',\n",
       " 'Deepak Ghaisas',\n",
       " 'Deepak Gupta',\n",
       " 'Deepak Gurnani',\n",
       " 'Deepak Jain',\n",
       " 'Deepak Kulkarni',\n",
       " 'Deepak Nathani',\n",
       " 'Deepak Natraj',\n",
       " 'Deepak Shahdadpuri',\n",
       " 'Deepak Sharma',\n",
       " 'Deepak Singh',\n",
       " 'Deepinder Goyal',\n",
       " 'Delhivery',\n",
       " 'Delta Partners',\n",
       " 'Dena',\n",
       " 'Denlow Investment Trust',\n",
       " 'Dentsu Ventures',\n",
       " 'Deobrat Singh',\n",
       " 'Deshe Holdings',\n",
       " 'Deshp',\n",
       " 'Deutsche Telekom Strategic Investments',\n",
       " 'Devdeep Singh',\n",
       " 'Development finance institution Belgian Investment Company',\n",
       " 'Devendra Rane',\n",
       " 'Devendra Reddy',\n",
       " 'Devesh Rai G',\n",
       " 'Devidas Desai',\n",
       " 'Dewan Housing Finance Corp',\n",
       " 'Dewang Neralla',\n",
       " 'Dexter Angel Circle',\n",
       " 'Dheeraj Jain',\n",
       " 'Dheeraj Mehta',\n",
       " 'Dheeraj P',\n",
       " 'Dhiraj Rajaram',\n",
       " 'Dhruv Chitgopekar',\n",
       " 'DiDi Chuxing',\n",
       " 'Diageo India',\n",
       " 'Diaz Nesamoney',\n",
       " 'Didi Kuaidi',\n",
       " 'Digital Currency Group',\n",
       " 'Digital Financial Service Lab',\n",
       " 'Digital Garage Inc',\n",
       " 'Dileep Bhatt',\n",
       " 'Dileep Nath',\n",
       " 'Dilip Kh',\n",
       " 'Dinesh Agarwal',\n",
       " 'Dinesh Kundu',\n",
       " 'Dinesh Mittal',\n",
       " 'Dinesh R. Challa',\n",
       " 'Dino Morea',\n",
       " 'Divyesh Shah',\n",
       " 'Doreswamy N',\n",
       " 'Dr David Cheriton',\n",
       " 'Dr Devi Shetty',\n",
       " 'Dr N',\n",
       " 'Dr Paresh Doshi',\n",
       " 'Dr Ramesh Ayyala',\n",
       " 'Dr V Ravinder',\n",
       " 'Dr. Abhishek P',\n",
       " 'Dr. Aniruddha Malpani',\n",
       " 'Dr. Apoorv Ranjan Sharma',\n",
       " 'Dr. Goutam Challagalla',\n",
       " 'Dr. Pooja G',\n",
       " 'Dr. Pramath Raj Sinha',\n",
       " 'Dr. Prasad Kaipa',\n",
       " 'Dr. Rameshwar Kumar',\n",
       " 'Dr. Ranjan Pai',\n",
       " 'Dr. Ritesh Malik',\n",
       " 'Dr. Sridhar Ramaswamy',\n",
       " 'Dragoneer Investment Group',\n",
       " 'Draper Associates',\n",
       " 'Draper Fisher Jurvetson',\n",
       " 'Draphant Consultants',\n",
       " 'Dream Incubator',\n",
       " 'Dreamweaver Investments',\n",
       " 'Dunamis Ventures Pte Ltd',\n",
       " 'Dutch government fund',\n",
       " 'E-City VEntures Atul Goel',\n",
       " 'E.ON',\n",
       " 'ECL Finance',\n",
       " 'EDBI',\n",
       " 'EVC Ventures',\n",
       " 'Eagle10 Ventures',\n",
       " 'Earlsfield Capital',\n",
       " 'East Ventures',\n",
       " 'Edelweiss',\n",
       " 'Eduardo Saverin',\n",
       " 'Eight Innovate',\n",
       " 'Eight Roads',\n",
       " 'Eight Roads Ventures India',\n",
       " 'Electronic Development Fund',\n",
       " 'Elevar Equity',\n",
       " 'Elevate Sports',\n",
       " 'Elliot Stechman',\n",
       " 'Emerald Media',\n",
       " 'Emergent Ventures India',\n",
       " 'Emerging India',\n",
       " 'Emery Capital',\n",
       " 'Empire Angels',\n",
       " 'Enablers platform',\n",
       " 'Endiya Partners',\n",
       " 'Ennovent Impact Investment Holding',\n",
       " 'Entrepreneurship (CIIE)',\n",
       " 'Epsilon Venture Partners',\n",
       " 'Equanimity Venture Fund',\n",
       " 'Equentia Natural Resource',\n",
       " 'Equity Crest',\n",
       " 'Eros Labs',\n",
       " 'Esvee Technologies Inc',\n",
       " 'Eureka Forbes Ltd',\n",
       " 'European investment fund',\n",
       " 'Evan Lim',\n",
       " 'Excelsior Investments',\n",
       " 'Exfinity Venture Partners',\n",
       " 'Existing investors',\n",
       " 'Experian',\n",
       " 'Experts',\n",
       " 'Extreme Venture Partners William Bissell',\n",
       " 'F-Prime Capital Partners',\n",
       " 'FAO Ventures',\n",
       " 'FF Angel',\n",
       " 'FIH Mobile Ltd',\n",
       " 'FIL Capital Management',\n",
       " 'FJ Labs',\n",
       " 'FS',\n",
       " 'FS Investment Managers',\n",
       " 'FS Private Equity',\n",
       " 'FTV Capital',\n",
       " 'Facebook FB Start programme',\n",
       " 'Factor[e] Ventures',\n",
       " 'Faering Capital',\n",
       " 'Fairfax',\n",
       " 'Fairfax Holdings',\n",
       " 'Falcon Edge',\n",
       " 'Faraz Khan',\n",
       " 'Farhaan Shabbir',\n",
       " 'Farhan Naqvi',\n",
       " 'Farm To Fork',\n",
       " 'Farooq Adam',\n",
       " 'Farooq Adam Mukadam',\n",
       " 'Farooq Oomerbhoy',\n",
       " 'Fauzan Rahim',\n",
       " 'Fenqile',\n",
       " 'FiNC',\n",
       " 'Fidelity Biosciences',\n",
       " 'Fidelity Growth Partners',\n",
       " 'FinTech',\n",
       " 'Finance',\n",
       " 'Fireside Ventures',\n",
       " 'Firoze Irani',\n",
       " 'Flipkart',\n",
       " 'Florida based Angel investor',\n",
       " 'Florintree Advisors',\n",
       " 'Ford Smart Mobility Llc',\n",
       " 'Fork Media',\n",
       " 'Fortisure Ventures',\n",
       " 'Forum Synergies PE Fund',\n",
       " 'Fosun International',\n",
       " 'Fosun RZ Capital',\n",
       " 'Foundation Capital',\n",
       " 'Founder Collective',\n",
       " 'Founders Fund',\n",
       " 'Foxconn',\n",
       " 'Foxconn Technology Group',\n",
       " 'Francesco Cara',\n",
       " 'Franchise India',\n",
       " 'Franklin Templeton International Services Pvt. Ltd',\n",
       " 'FreakOut Group',\n",
       " 'Fred Khosravi',\n",
       " 'FreshMenu)',\n",
       " 'Frontline Strategy',\n",
       " 'Fullerton Financial Holdings Pte Ltd',\n",
       " 'Fullerton India Credit Company Ltd',\n",
       " 'Fundamentum',\n",
       " 'Funders Club',\n",
       " 'Funding through 1Crowd platform',\n",
       " 'Fundnel',\n",
       " 'Fung Strategic Holdings',\n",
       " 'Fusion Tech Ventures',\n",
       " 'Future Fund',\n",
       " 'G Raghun',\n",
       " 'G Ravishankar',\n",
       " 'GAIL India Ltd',\n",
       " 'GAIN',\n",
       " 'GBIM Technologies Pvt Ltd',\n",
       " 'GEMS Advisory',\n",
       " 'GEMS group',\n",
       " 'GEMs',\n",
       " 'GFC',\n",
       " 'GHV',\n",
       " 'GHV Accelerator',\n",
       " 'GIC',\n",
       " 'GIC ventures',\n",
       " 'GMO Japan',\n",
       " 'GMO Payment Gateway',\n",
       " 'GPA group',\n",
       " 'GREE Ventures',\n",
       " 'GREX',\n",
       " 'GROUPE SOS',\n",
       " 'GSF',\n",
       " 'GVFL',\n",
       " 'Gabriel Investments',\n",
       " 'Gagan Dugal',\n",
       " 'Gagan Goyal',\n",
       " 'Gagan Hasteer',\n",
       " 'Gaja Capital',\n",
       " 'Ganapathy Venugopal.',\n",
       " 'Ganayantrika Systems',\n",
       " 'Ganesh Narasimhan',\n",
       " 'Ganesh Natarajan',\n",
       " 'Ganpat Singhvi',\n",
       " 'GardX International',\n",
       " 'Gati Ltd',\n",
       " 'Gaurav Agarwal',\n",
       " 'Gaurav Bhalotia',\n",
       " 'Gaurav Bhatnagar',\n",
       " 'Gaurav Bhogle',\n",
       " 'Gaurav Dalmia',\n",
       " 'Gaurav Gupta',\n",
       " 'Gaurav Kachru',\n",
       " 'Gaurav Lochan',\n",
       " 'Gaurav Luniya',\n",
       " 'Gaurav Marya',\n",
       " 'Gaurav Munjal',\n",
       " 'Gaurav Sharma',\n",
       " 'Gaurav Singhvi',\n",
       " 'Gaurav Suri',\n",
       " 'Gaurav Vats',\n",
       " 'Gautam Chhaochharia',\n",
       " 'Gautam G',\n",
       " 'Gautam Ivatury',\n",
       " 'Gautam Sinha',\n",
       " 'General Atlantic',\n",
       " 'General Catalyst',\n",
       " 'Geniee',\n",
       " 'Girish Mathrubootham',\n",
       " 'Girish Reddy',\n",
       " 'Girnar Software',\n",
       " 'Gleevoaz Ventures',\n",
       " 'Global Founders Capital',\n",
       " 'Global Institutional Investors',\n",
       " 'GlobalLogic co-founder Rajul Garg',\n",
       " 'Globeinvestor',\n",
       " 'Globevestor Angel Fund',\n",
       " 'Goa',\n",
       " 'Gokaldas Exports Ltd',\n",
       " 'Gokul Jaykrishna',\n",
       " 'Gokul Rajaram',\n",
       " 'Goldbell Group',\n",
       " 'Goldman Sachs',\n",
       " 'Google',\n",
       " 'Google Capital',\n",
       " 'Gopal Aggarwal',\n",
       " 'Gopal Srinivasan',\n",
       " 'Gordon',\n",
       " 'Govind Rajan',\n",
       " 'Grace Capital Ventures',\n",
       " 'Grace Grace Techno Ventures LLP',\n",
       " 'Grasshoppers',\n",
       " 'Gray Matters',\n",
       " 'Gray Matters Capital',\n",
       " 'Great Oaks Ventures',\n",
       " 'Green House Ventures (GHV)',\n",
       " 'Green Shots Capital',\n",
       " 'Green Visor Capital LP II',\n",
       " 'Greenfield Advisory',\n",
       " 'Greenoaks Capital Partners',\n",
       " 'Grex.in',\n",
       " 'Grey Orange',\n",
       " 'Grey Orange Robotics',\n",
       " 'Greycroft Partners',\n",
       " 'Group',\n",
       " 'Group of Angel Investors',\n",
       " 'Group of Angel Investors from US/India',\n",
       " 'Group of HNI investors',\n",
       " 'Group of Investors',\n",
       " 'Group of other Angel investors',\n",
       " 'Group of undisclosed Angel Investors',\n",
       " 'GrowX',\n",
       " 'GrowX Ventures',\n",
       " 'Growth DNA',\n",
       " 'GrowthStory',\n",
       " 'Gujarat Venture Finance Limited (GVFL)',\n",
       " 'Gujarat based angel investors',\n",
       " 'Gulpreet Kohli',\n",
       " 'Gund Investment',\n",
       " 'Gurmeet Chahal',\n",
       " 'Gurpreet Singh',\n",
       " 'Guy Oseary',\n",
       " 'Gyanendra Singh',\n",
       " 'H C Jain',\n",
       " 'HAX Accelerator',\n",
       " 'HBM Healthcare Investments Ltd',\n",
       " 'HCS Venture capital fund',\n",
       " 'HDFC',\n",
       " 'HDFC Asset Management',\n",
       " 'HDFC Bank',\n",
       " 'HDFC Life',\n",
       " 'HIS Co. Ltd',\n",
       " 'HNIs',\n",
       " 'HR Fund',\n",
       " 'HR Technology fund',\n",
       " 'HT Digital Media Holdings Ltd',\n",
       " 'HT Media',\n",
       " 'HT Media Ltd',\n",
       " 'Hack VC',\n",
       " 'Haitong Securities',\n",
       " 'Hampton Capital',\n",
       " 'Hamraj Kumar',\n",
       " 'Haresh Chawla',\n",
       " 'Hari Krishna',\n",
       " 'Harinder Takhar',\n",
       " 'Harmeet Bajaj',\n",
       " 'Harminder Sahani',\n",
       " 'Harmony Partners',\n",
       " 'Harpreet Singh Grover',\n",
       " 'Harsh Kundra',\n",
       " 'Harsh Mahajan',\n",
       " 'Harsh Mariwala',\n",
       " 'Harsh V. Pant',\n",
       " 'Harsh Vardhan Hada',\n",
       " 'Harvard Angels',\n",
       " 'HealthQuad Advisors Private Limited',\n",
       " 'Helion Advisors',\n",
       " 'Helion Venture Partners',\n",
       " 'Helix Investments',\n",
       " 'Hemang Sahani',\n",
       " 'Hemant Kanakia',\n",
       " 'Hemant Kaul',\n",
       " 'Hemant Luthra',\n",
       " 'Hemant Sahni',\n",
       " 'Herb Madan',\n",
       " 'Hercules Capital',\n",
       " 'Hermes Group',\n",
       " 'Hero Electronix corporate financing arm',\n",
       " 'Hero Enterprise',\n",
       " 'Hero MotoCorp',\n",
       " 'Hetal Sonpal',\n",
       " 'High Networth Individuals (No details)',\n",
       " 'High Networth Individuals (undisclosed)',\n",
       " 'High Networth Individuals from India',\n",
       " 'Hillhouse Capital',\n",
       " 'Himanshu Aggarwal',\n",
       " 'Himanshu Aggrawal',\n",
       " 'Hinduja Group',\n",
       " 'Hinduja Leyl',\n",
       " 'Hinduja family',\n",
       " 'Hines',\n",
       " 'Hiro Mashita',\n",
       " 'Hirokazu',\n",
       " 'Hitesh Gupta',\n",
       " 'Hitesh Oberoi',\n",
       " 'Hitesh Windlass',\n",
       " 'Hitouch AG',\n",
       " 'Hivos-Triodos Fund',\n",
       " 'Holostik Group',\n",
       " 'Holtzbrink Ventures',\n",
       " 'Horizons Ventures',\n",
       " 'Hornbill Orchid India Fund',\n",
       " 'Horseferry',\n",
       " 'Hrishi Oberoi',\n",
       " 'Hrishikesh Par',\n",
       " 'Huang Wei',\n",
       " 'Hunch Ventures',\n",
       " 'Hussam Khoury',\n",
       " 'Huzaifa Khorakiwala',\n",
       " 'Hyderabad Angels',\n",
       " 'Hyderabad based investor',\n",
       " 'Hyperplane Venture Capital',\n",
       " 'Hyundai',\n",
       " 'IA Venture Strategies Fund II LP',\n",
       " 'IAN Fund',\n",
       " 'ID Enablers Pvt Ltd',\n",
       " 'IDFC SPICE Fund',\n",
       " 'IDFC-Parampara Capital',\n",
       " 'IDG',\n",
       " 'IDG Ventures',\n",
       " 'IDG Ventures India',\n",
       " 'IFC',\n",
       " 'IFC Everstone Group',\n",
       " 'IFMR',\n",
       " 'IFMR Capital Finance',\n",
       " 'IIFL',\n",
       " 'IIFL Seed Ventures',\n",
       " 'IIFL Wealth',\n",
       " 'IIT Ropar',\n",
       " 'IL',\n",
       " 'ILearnFinance Academy Pvt. Ltd.',\n",
       " 'IMJ Investment Partners',\n",
       " 'IMM Investment',\n",
       " 'ISME ACE.',\n",
       " 'IT Farm',\n",
       " 'ITW Digital',\n",
       " 'Ibibo Group',\n",
       " 'Idea Wave Labs',\n",
       " 'Ideaspring Capital',\n",
       " 'Ideation Initiative Pvt. Ltd',\n",
       " 'Idein Ventures',\n",
       " 'Ignition Partners',\n",
       " 'Imanpreet Singh Arora',\n",
       " 'Impanix Capital',\n",
       " 'InCred',\n",
       " 'InCred Finance',\n",
       " 'InMobi',\n",
       " 'Inara Capital',\n",
       " 'Inc',\n",
       " 'Inc95 Consulting',\n",
       " 'Incofin Investment Management.',\n",
       " 'Incubate Fund',\n",
       " 'Incubate Fund India',\n",
       " 'Incubate Fund from Japan',\n",
       " 'Incubation Foundation (SIIF)',\n",
       " 'Incubator Group (LCIG)',\n",
       " 'India',\n",
       " 'India Alternatives',\n",
       " 'India Educational Investment Fund',\n",
       " 'India Innovation Fund India Venture Partners',\n",
       " 'India Internet Fund',\n",
       " 'India Nivesh Growth Fund',\n",
       " 'India Quotient',\n",
       " 'India Value Fund Advisors',\n",
       " 'India Ventures',\n",
       " 'IndiaMart',\n",
       " 'Indian Angel Network',\n",
       " 'Indian Governments',\n",
       " 'Indian HNIs',\n",
       " 'Indian fintech fund',\n",
       " 'IndianIdeas.com',\n",
       " 'Individual Investors',\n",
       " 'Indochine International',\n",
       " 'Indus Age Partners',\n",
       " 'Industries',\n",
       " 'Infibeam',\n",
       " 'Infina Finance Pvt. Ltd',\n",
       " 'Inflexionpoint',\n",
       " 'Info Edge (India) Ltd',\n",
       " 'InfoEdge',\n",
       " 'Infocomm Development Authority of Singapore',\n",
       " 'Infocomm Investments',\n",
       " 'Infosys',\n",
       " 'Infosys Innovation Fund',\n",
       " 'Infosys co-founder Kris Gopalakrishnan',\n",
       " 'Infuse Ventures',\n",
       " 'Ingram Content Group',\n",
       " 'Initia Holdings',\n",
       " 'Innogyrstead',\n",
       " 'Innov8',\n",
       " 'Innov8 founder Ritesh Malik',\n",
       " ...]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(df['investor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ec168816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aakrit Vaish', 'Swapan Rajdev', 'Sushill Jiwarajka'], dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['startup']=='ION Energy']['investor'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f90f2707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6100, 8)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0545392c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               0\n",
       "startup            0\n",
       "vertical           0\n",
       "subvertical        0\n",
       "location           0\n",
       "investor           0\n",
       "investment_type    0\n",
       "amount             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6ce58cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4f6708d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bengaluru',\n",
       " 'Gurgaon',\n",
       " 'New Delhi',\n",
       " 'Mumbai',\n",
       " 'Chennai',\n",
       " 'Pune',\n",
       " 'Noida',\n",
       " 'Faridabad',\n",
       " 'San Francisco',\n",
       " 'San Jose,',\n",
       " 'Amritsar',\n",
       " 'Delhi',\n",
       " 'Kormangala',\n",
       " 'Hyderabad',\n",
       " 'Burnsville',\n",
       " 'Menlo Park',\n",
       " 'Gurugram',\n",
       " 'Palo Alto',\n",
       " 'Santa Monica',\n",
       " 'Singapore',\n",
       " 'Taramani',\n",
       " 'Andheri',\n",
       " 'Chembur',\n",
       " 'Haryana',\n",
       " 'New York',\n",
       " 'Karnataka',\n",
       " 'Mumbai/Bengaluru',\n",
       " 'Bhopal',\n",
       " 'Bengaluru and Gurugram',\n",
       " 'India/Singapore',\n",
       " 'Jaipur',\n",
       " 'India/US',\n",
       " 'Nagpur',\n",
       " 'Indore',\n",
       " 'New York, Bengaluru',\n",
       " 'California',\n",
       " 'India',\n",
       " 'Rourkela',\n",
       " 'Srinagar',\n",
       " 'Bhubaneswar',\n",
       " 'Chandigarh',\n",
       " 'Delhi & Cambridge',\n",
       " 'Kolkata',\n",
       " 'Coimbatore',\n",
       " 'Bangalore',\n",
       " 'Udaipur',\n",
       " 'Ahemdabad',\n",
       " 'Ahmedabad',\n",
       " 'Ahemadabad',\n",
       " 'Surat',\n",
       " 'Goa',\n",
       " 'Uttar Pradesh',\n",
       " 'Gaya',\n",
       " 'Vadodara',\n",
       " 'Trivandrum',\n",
       " 'Missourie',\n",
       " 'Panaji',\n",
       " 'Gwalior',\n",
       " 'Karur',\n",
       " 'Udupi',\n",
       " 'Kochi',\n",
       " 'Agra',\n",
       " 'Bangalore/ Bangkok',\n",
       " 'Hubli',\n",
       " 'Kerala',\n",
       " 'Kozhikode',\n",
       " 'US',\n",
       " 'Siliguri',\n",
       " 'USA',\n",
       " 'Lucknow',\n",
       " 'Kanpur',\n",
       " 'Bangalore / SFO',\n",
       " 'London',\n",
       " 'Seattle / Bangalore',\n",
       " 'Pune/Seattle',\n",
       " 'Pune / Dubai',\n",
       " 'Varanasi',\n",
       " 'New Delhi / US',\n",
       " 'Mumbai / UK',\n",
       " 'Jodhpur',\n",
       " 'Hyderabad/USA',\n",
       " 'Boston',\n",
       " 'Bangalore / Palo Alto',\n",
       " 'Mumbai / NY',\n",
       " 'USA/India',\n",
       " 'Goa/Hyderabad',\n",
       " 'Noida / Singapore',\n",
       " 'Belgaum',\n",
       " 'Pune / US',\n",
       " 'Chennai/ Singapore',\n",
       " 'Pune / Singapore',\n",
       " 'Bangalore / San Mateo',\n",
       " 'New York/ India',\n",
       " 'US/India',\n",
       " 'Gurgaon / SFO',\n",
       " 'Bangalore / USA',\n",
       " 'New Delhi/ Houston',\n",
       " 'Mumbai / Global',\n",
       " 'India / US',\n",
       " 'New Delhi / California']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_investors = df['location'].str.split('/', expand=True).stack().str.strip().reset_index(level=1, drop=True).rename('location')\n",
    "df_result = df_investors.to_frame().join(df.drop('location', axis=1))\n",
    "\n",
    "investor_companies = df_result.groupby('location')['startup'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd67bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb5523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c6961b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b763a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370730da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08860d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31685004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4522d40",
   "metadata": {},
   "source": [
    "# old code for expanding or stiping investor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee3127bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_investors = df['investor'].str.split(',|and', expand=True).stack().str.strip().reset_index(level=1, drop=True).rename('investor')\n",
    "df_result = df_investors.to_frame().join(df.drop('investor', axis=1))\n",
    "\n",
    "investor_companies = df_result.groupby('investor')['startup'].apply(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e4bba75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investor</th>\n",
       "      <th>date</th>\n",
       "      <th>startup</th>\n",
       "      <th>vertical</th>\n",
       "      <th>subvertical</th>\n",
       "      <th>location</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>1630.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Susquehanna Growth Equity LLC</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Series C</td>\n",
       "      <td>65.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Series B</td>\n",
       "      <td>149.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>24.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>14.674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        investor       date          startup  \\\n",
       "0        Tiger Global Management 2020-01-09           Byju's   \n",
       "1  Susquehanna Growth Equity LLC 2020-01-13           Shuttl   \n",
       "2                Sequoia Capital 2020-01-09        MamaEarth   \n",
       "3                 Vinod Khatumal 2020-01-02  wealthbucket.in   \n",
       "4        Sprout Venture Partners 2020-01-02           Fashor   \n",
       "\n",
       "              vertical                            subvertical   location  \\\n",
       "0              Ed-Tech                             E-learning  Bengaluru   \n",
       "1       Transportation              App based shuttle service    Gurgaon   \n",
       "2            eCommerce  Retailer of baby and toddler products  Bengaluru   \n",
       "3              FinTech                      Online Investment  New Delhi   \n",
       "4  Fashion and Apparel            Embroiled Clothes For Women     Mumbai   \n",
       "\n",
       "  investment_type    amount  \n",
       "0  Private Equity  1630.400  \n",
       "1        Series C    65.611  \n",
       "2        Series B   149.661  \n",
       "3    Pre-Series A    24.456  \n",
       "4      Seed Round    14.674  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "323b16ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Tiger Global Management\n",
       "1       Susquehanna Growth Equity LLC\n",
       "2                     Sequoia Capital\n",
       "3                      Vinod Khatumal\n",
       "4             Sprout Venture Partners\n",
       "                    ...              \n",
       "5924                 Ashish Dev Kapur\n",
       "5925                       Rainmatter\n",
       "5926                      The HR Fund\n",
       "5927        Bessemer Venture Partners\n",
       "5928                    SAIF Partners\n",
       "Name: investor, Length: 5859, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4237a31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "investor\n",
       "& Co                                             [TestBook]\n",
       "& Others                             [Remitr, iDreamCareer]\n",
       "& other Angel investors.                      [PosterGully]\n",
       "021 Capita                                        [Increff]\n",
       "100 Co-founders Lab                              [MoEngage]\n",
       "                                            ...            \n",
       "Â LetsVenture                     [NightStay, The BlueBook]\n",
       "Â NexusÂ Ventures                               [StayZilla]\n",
       "Â RBÂ Investments                   [FabHotels, Capricoast]\n",
       "Â StellarisÂ VentureÂ Partners                 [Wydr, Wydr]\n",
       "Â ZodiusÂ TechnologyÂ Fund           [Pepperfry, Pepperfry]\n",
       "Name: startup, Length: 2951, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investor_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc1dc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['date','startup','vertical','subvertical','location','investor','investment_type','amount']\n",
    "df_result=df_result[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c451eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>startup</th>\n",
       "      <th>vertical</th>\n",
       "      <th>subvertical</th>\n",
       "      <th>location</th>\n",
       "      <th>investor</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>1630.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Susquehanna Growth Equity LLC</td>\n",
       "      <td>Series C</td>\n",
       "      <td>65.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Series B</td>\n",
       "      <td>149.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>24.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>14.674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date          startup             vertical  \\\n",
       "0 2020-01-09           Byju's              Ed-Tech   \n",
       "1 2020-01-13           Shuttl       Transportation   \n",
       "2 2020-01-09        MamaEarth            eCommerce   \n",
       "3 2020-01-02  wealthbucket.in              FinTech   \n",
       "4 2020-01-02           Fashor  Fashion and Apparel   \n",
       "\n",
       "                             subvertical   location  \\\n",
       "0                             E-learning  Bengaluru   \n",
       "1              App based shuttle service    Gurgaon   \n",
       "2  Retailer of baby and toddler products  Bengaluru   \n",
       "3                      Online Investment  New Delhi   \n",
       "4            Embroiled Clothes For Women     Mumbai   \n",
       "\n",
       "                        investor investment_type    amount  \n",
       "0        Tiger Global Management  Private Equity  1630.400  \n",
       "1  Susquehanna Growth Equity LLC        Series C    65.611  \n",
       "2                Sequoia Capital        Series B   149.661  \n",
       "3                 Vinod Khatumal    Pre-Series A    24.456  \n",
       "4        Sprout Venture Partners      Seed Round    14.674  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0263074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Freshworks', 'happay', 'Capillary', 'Grabhouse'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result['investor']=='Sequoia']['startup'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06e3dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3be33ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5859, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d941acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d24cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e736796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25d03b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No</th>\n",
       "      <th>Date dd/mm/yyyy</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry Vertical</th>\n",
       "      <th>SubVertical</th>\n",
       "      <th>City  Location</th>\n",
       "      <th>Investors Name</th>\n",
       "      <th>InvestmentnType</th>\n",
       "      <th>Amount in USD</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>Private Equity Round</td>\n",
       "      <td>20,00,00,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13/01/2020</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Susquehanna Growth Equity</td>\n",
       "      <td>Series C</td>\n",
       "      <td>80,48,394</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Series B</td>\n",
       "      <td>1,83,58,860</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>Pre-series A</td>\n",
       "      <td>30,00,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>18,00,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr No Date dd/mm/yyyy     Startup Name    Industry Vertical  \\\n",
       "0      1      2020-09-01           Byju's              Ed-Tech   \n",
       "1      2      13/01/2020           Shuttl       Transportation   \n",
       "2      3      2020-09-01        MamaEarth            eCommerce   \n",
       "3      4      02/01/2020  wealthbucket.in              FinTech   \n",
       "4      5      02/01/2020           Fashor  Fashion and Apparel   \n",
       "\n",
       "                             SubVertical City  Location  \\\n",
       "0                             E-learning      Bengaluru   \n",
       "1              App based shuttle service        Gurgaon   \n",
       "2  Retailer of baby and toddler products      Bengaluru   \n",
       "3                      Online Investment      New Delhi   \n",
       "4            Embroiled Clothes For Women         Mumbai   \n",
       "\n",
       "              Investors Name       InvestmentnType Amount in USD Remarks  \n",
       "0    Tiger Global Management  Private Equity Round  20,00,00,000     NaN  \n",
       "1  Susquehanna Growth Equity              Series C     80,48,394     NaN  \n",
       "2            Sequoia Capital              Series B   1,83,58,860     NaN  \n",
       "3             Vinod Khatumal          Pre-series A     30,00,000     NaN  \n",
       "4    Sprout Venture Partners            Seed Round     18,00,000     NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e96ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3044, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea8f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Sr No','Remarks'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b1f1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'Date dd/mm/yyyy':'date',\n",
    "    'Startup Name':'startup',\n",
    "    'Industry Vertical':'vertical',\n",
    "    'SubVertical':'subvertical',\n",
    "    'City  Location':'location',\n",
    "    'Investors Name':'investor',\n",
    "    'InvestmentnType':'investment_type',\n",
    "    'Amount in USD':'amount'\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98f6185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 0\n",
       "startup              0\n",
       "vertical           171\n",
       "subvertical        936\n",
       "location           180\n",
       "investor            24\n",
       "investment_type      4\n",
       "amount             960\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21f6ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount']=df['amount'].str.replace(',','')\n",
    "df['amount']=df['amount'].str.replace('undisclosed','0')\n",
    "df['amount']=df['amount'].str.replace('unknown','0')\n",
    "df['amount']=df['amount'].str.replace('Undisclosed','0')\n",
    "df['amount']=df['amount'].replace('14342000+','14342000')\n",
    "df['amount']=df['amount'].replace(to_replace=r'\\\\+',value='',regex=True)\n",
    "df['amount']=df['amount'].str.replace(\"xc2xa0\",'')\n",
    "df['amount']=df['amount'].str.replace('N/A','0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22054faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount']=df['amount'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b79914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount']=df['amount'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac7f2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doll_inr(dollar):\n",
    "    inr=dollar*81.52\n",
    "    return inr/10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63affcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount']=round(df['amount'].apply(doll_inr),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75233d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=df['date'].str.replace('05/072018','05/07/2018')\n",
    "df['date']=df['date'].replace('\\\\\\\\xc2\\\\\\\\xa010/7/2015','10/7/2015')\n",
    "df['date']=df['date'].str.replace('22/01//2015','22/01/2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7089b927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/01/2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/11/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/10/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/08/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/02/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/03/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/02/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/01/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/08/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/07/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/06/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/05/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/03/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/02/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/12/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/09/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/07/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04.2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/04/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/03/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/02/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/01.2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/01/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
     ]
    }
   ],
   "source": [
    "df['date']=pd.to_datetime(df['date'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc52d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 1\n",
       "startup              0\n",
       "vertical           171\n",
       "subvertical        936\n",
       "location           180\n",
       "investor            24\n",
       "investment_type      4\n",
       "amount               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "356e71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=df['date'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "255f57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['startup']=df['startup'].apply(lambda x: str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9335dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace('\\xa0',''))\n",
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace('\\\\\\\\xc2\\\\\\\\xa0',''))\n",
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace(' \\\\xe2\\\\x80\\\\x93',''))\n",
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace('\\\\\\\\n',' '))\n",
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99',''))\n",
    "df['vertical']=df['vertical'].apply(lambda x:str(x).replace('Chain of Tea Caf\\\\\\\\xc3\\\\\\\\xa9\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s','Chain of Tea Cafes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5867d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subvertical']=df['subvertical'].apply(lambda x:str(x).replace('\\\\\\\\xc2\\\\\\\\xa0',''))\n",
    "df['subvertical']=df['subvertical'].apply(lambda x:str(x).replace('\"Women\\\\\\\\\\'s Fashion Clothing Online Platform\"','Women Fashion Clothing Online Platform'))\n",
    "df['subvertical']=df['subvertical'].apply(lambda x:str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99',''))\n",
    "df['subvertical']=df['subvertical'].apply(lambda x:str(x).replace('\\xa0',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4f675bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location']=df['location'].apply(lambda x:str(x).replace('\\\\\\\\xc2\\\\\\\\xa0',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bc3123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\xa0',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99s',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\xc2\\\\\\\\xa0',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace(', \\\\\\\\xc3\\\\\\\\x98',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\n\\\\\\\\n',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\"Kedaraa Capital, Ontario Teachers\\\\\\\\\\'\"','Kedaraa Capital, Ontario Teachers'))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\xc3\\\\\\\\xa9',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('\\\\\\\\xe2\\\\\\\\x80\\\\\\\\x99O',''))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('and',','))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('And',','))\n",
    "df['investor']=df['investor'].apply(lambda x:str(x).replace('&',','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6c56874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['investment_type']=df['investment_type'].apply(lambda x:str(x).replace('\\\\\\\\n',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "258714dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>startup</th>\n",
       "      <th>vertical</th>\n",
       "      <th>subvertical</th>\n",
       "      <th>location</th>\n",
       "      <th>investor</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>Byju's</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Tiger Global Management</td>\n",
       "      <td>Private Equity Round</td>\n",
       "      <td>1630.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>Shuttl</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>App based shuttle service</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Susquehanna Growth Equity</td>\n",
       "      <td>Series C</td>\n",
       "      <td>65.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>MamaEarth</td>\n",
       "      <td>eCommerce</td>\n",
       "      <td>Retailer of baby and toddler products</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Series B</td>\n",
       "      <td>149.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>wealthbucket.in</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Online Investment</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Vinod Khatumal</td>\n",
       "      <td>Pre-series A</td>\n",
       "      <td>24.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Fashor</td>\n",
       "      <td>Fashion and Apparel</td>\n",
       "      <td>Embroiled Clothes For Women</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sprout Venture Partners</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>14.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>Printvenue</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Asia Pacific Internet Group</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>36.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>Graphene</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>KARSEMVEN Fund</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>6.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>Mad Street Den</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Exfinity Fund, GrowX Ventures.</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>12.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>Simplotel</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>MakeMyTrip</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>couponmachine.in</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>UK based Group of Angel Investors</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>1.141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3044 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date           startup             vertical  \\\n",
       "0    2020-09-01            Byju's              Ed-Tech   \n",
       "1    2020-01-13            Shuttl       Transportation   \n",
       "2    2020-09-01         MamaEarth            eCommerce   \n",
       "3    2020-02-01   wealthbucket.in              FinTech   \n",
       "4    2020-02-01            Fashor  Fashion and Apparel   \n",
       "...         ...               ...                  ...   \n",
       "3039 2015-01-29        Printvenue                  nan   \n",
       "3040 2015-01-29          Graphene                  nan   \n",
       "3041 2015-01-30    Mad Street Den                  nan   \n",
       "3042 2015-01-30         Simplotel                  nan   \n",
       "3043 2015-01-31  couponmachine.in                  nan   \n",
       "\n",
       "                                subvertical   location  \\\n",
       "0                                E-learning  Bengaluru   \n",
       "1                 App based shuttle service    Gurgaon   \n",
       "2     Retailer of baby and toddler products  Bengaluru   \n",
       "3                         Online Investment  New Delhi   \n",
       "4               Embroiled Clothes For Women     Mumbai   \n",
       "...                                     ...        ...   \n",
       "3039                                    nan        nan   \n",
       "3040                                    nan        nan   \n",
       "3041                                    nan        nan   \n",
       "3042                                    nan        nan   \n",
       "3043                                    nan        nan   \n",
       "\n",
       "                               investor       investment_type    amount  \n",
       "0               Tiger Global Management  Private Equity Round  1630.400  \n",
       "1             Susquehanna Growth Equity              Series C    65.611  \n",
       "2                       Sequoia Capital              Series B   149.661  \n",
       "3                        Vinod Khatumal          Pre-series A    24.456  \n",
       "4               Sprout Venture Partners            Seed Round    14.674  \n",
       "...                                 ...                   ...       ...  \n",
       "3039        Asia Pacific Internet Group        Private Equity    36.684  \n",
       "3040                     KARSEMVEN Fund        Private Equity     6.725  \n",
       "3041     Exfinity Fund, GrowX Ventures.        Private Equity    12.228  \n",
       "3042                         MakeMyTrip        Private Equity     0.000  \n",
       "3043  UK based Group of Angel Investors          Seed Funding     1.141  \n",
       "\n",
       "[3044 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af3d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
